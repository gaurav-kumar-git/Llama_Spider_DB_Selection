{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c999f2fd-56f0-4ae9-949c-4803f663a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: accelerate in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: bitsandbytes in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: sentencepiece in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: datasets in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: huggingface_hub in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.32.3)\n",
      "Requirement already satisfied: tqdm in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: psutil in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: sympy in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: six>=1.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate bitsandbytes sentencepiece pandas datasets huggingface_hub tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc106017-bfb9-40d0-8409-ff72140b945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets version: 8.1.5\n",
      "ipywidgets location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/ipywidgets/__init__.py\n",
      "tqdm version: 4.67.1\n",
      "tqdm location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/tqdm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "  import ipywidgets\n",
    "  print(f\"ipywidgets version: {ipywidgets.__version__}\")\n",
    "  print(f\"ipywidgets location: {ipywidgets.__file__}\")\n",
    "\n",
    "  import tqdm\n",
    "  print(f\"tqdm version: {tqdm.__version__}\")\n",
    "  print(f\"tqdm location: {tqdm.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48f920e-9675-4ae6-ac4a-e221b3e0175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm imported successfully from .auto\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5729fded4c43109ccbbfea7f830c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minimal Auto Test:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple tqdm .auto loop completed\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(\"tqdm imported successfully from .auto\")\n",
    "my_list = list(range(3))\n",
    "for i in tqdm(my_list, desc=\"Minimal Auto Test\"):\n",
    "    time.sleep(0.2)\n",
    "print(\"Simple tqdm .auto loop completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51bd609-5bef-4bae-9977-8909136a2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8aed063-c3c2-49b9-ba1c-3ec07ec68adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0\n",
      "CUDA available: True\n",
      "CUDA version PyTorch compiled with: 11.8\n",
      "Number of GPUs available to PyTorch: 8\n",
      "  GPU 0: NVIDIA A100-SXM4-80GB\n",
      "  GPU 1: NVIDIA A100-SXM4-80GB\n",
      "  GPU 2: NVIDIA A100-SXM4-80GB\n",
      "  GPU 3: NVIDIA A100-SXM4-80GB\n",
      "  GPU 4: NVIDIA A100-SXM4-80GB\n",
      "  GPU 5: NVIDIA A100-SXM4-80GB\n",
      "  GPU 6: NVIDIA A100-SXM4-80GB\n",
      "  GPU 7: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch compiled with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs available to PyTorch: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"ERROR: PyTorch cannot see the GPUs! Check installation and CUDA compatibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba6d845-eeb6-4dc3-8936-00a0686991c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac563a7e-b468-4b6e-9b89-ea76a46e229b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f0cf0a45f24c309048c78a14205680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful or already authenticated.\n",
      "\n",
      "--- Cell 2: Hugging Face Login Attempt Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Hugging Face Hub Authentication ---\n",
    "# You MUST have requested access to Llama 2 models via Meta's form on Hugging Face\n",
    "# AND have your request approved.\n",
    "\n",
    "# Option 1: If you've stored your token as an environment variable on the server\n",
    "# HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "# if HF_TOKEN:\n",
    "#     print(\"Logging into Hugging Face Hub using token from environment variable...\")\n",
    "#     login(token=HF_TOKEN)\n",
    "# else:\n",
    "#     print(\"HF_TOKEN environment variable not set. Attempting widget login if in interactive environment, or manual CLI login might be needed.\")\n",
    "#     login() # Will prompt if in an environment that supports it\n",
    "\n",
    "# Option 2: Paste token directly (less secure, use with caution)\n",
    "# HF_TOKEN = \"YOUR_HF_READ_TOKEN_HERE\"\n",
    "# login(token=HF_TOKEN)\n",
    "\n",
    "# Option 3: Use huggingface-cli login in a server terminal beforehand (Recommended)\n",
    "# If already logged in via CLI, this cell might not be strictly necessary,\n",
    "# but running login() can confirm status or refresh credentials.\n",
    "try:\n",
    "    login() # Will use cached token or prompt if needed\n",
    "    print(\"Hugging Face login successful or already authenticated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Hugging Face login failed: {e}. Ensure you are authenticated to download Llama 2.\")\n",
    "\n",
    "print(\"\\n--- Cell 2: Hugging Face Login Attempt Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339f0694-4129-4a0a-9bec-150838594c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Model: meta-llama/Llama-2-70b-chat-hf\n",
      "BitsAndBytesConfig: load_in_4bit=True, compute_dtype=torch.bfloat16\n",
      "System and User prompt templates defined.\n",
      "Hugging Face model cache directory set to: /raid/infolab/gaurav/Llama_Spider_A100_Project/experiments_70b_llama/.hf_model_cache_70b\n",
      "\n",
      "--- Cell 3: Model and Prompt Configuration Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Model and Tokenizer Configuration ---\n",
    "import os\n",
    "\n",
    "# 3.1. Specify the Llama 2 70B Chat Model\n",
    "MODEL_NAME = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "print(f\"Target Model: {MODEL_NAME}\")\n",
    "\n",
    "# 3.2. Configure 4-bit Quantization (essential for 70B, even on A100s for single/few GPU use)\n",
    "# A100s support bfloat16, which is excellent for mixed-precision.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",        # nf4 is a good default\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Use bfloat16 for computation on A100s\n",
    "    bnb_4bit_use_double_quant=True,   # Can save a bit more memory\n",
    ")\n",
    "print(f\"BitsAndBytesConfig: load_in_4bit={bnb_config.load_in_4bit}, compute_dtype={bnb_config.bnb_4bit_compute_dtype}\")\n",
    "\n",
    "# 3.3. Define Prompt Templates\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert data analyst. Your task is to determine if a given natural language query \"\n",
    "    \"can be answered *solely* based on the provided database schema. \"\n",
    "    \"Do not attempt to answer the query itself. Your entire response must be only the word 'Yes' or the word 'No'.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Database Schema:\n",
    "---\n",
    "{schema_string}\n",
    "---\n",
    "Natural Language Query: \"{nl_query}\"\n",
    "---\n",
    "Can the query be answered using *only* the provided schema and its potential contents? Answer with either \"Yes\" or \"No\".\n",
    "\"\"\"\n",
    "print(\"System and User prompt templates defined.\")\n",
    "\n",
    "# 3.4. Define Cache Directory for Hugging Face downloads (optional, but good for managing large models)\n",
    "# Create it within your project directory on the A100 server.\n",
    "HF_MODEL_CACHE_DIR = os.path.join(os.getcwd(), \".hf_model_cache_70b\") # Assumes current dir is project root\n",
    "os.makedirs(HF_MODEL_CACHE_DIR, exist_ok=True)\n",
    "print(f\"Hugging Face model cache directory set to: {HF_MODEL_CACHE_DIR}\")\n",
    "\n",
    "print(\"\\n--- Cell 3: Model and Prompt Configuration Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd45122-14da-4134-8b16-2732bbe33a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for meta-llama/Llama-2-70b-chat-hf...\n",
      "Set tokenizer.pad_token to tokenizer.eos_token ('</s>')\n",
      "Tokenizer loaded successfully.\n",
      "Found single token for 'Yes': ID 3869\n",
      "Found single token for 'No': ID 1939\n",
      "GLOBAL YES_TOKEN_ID: 3869 ('Yes')\n",
      "GLOBAL NO_TOKEN_ID: 1939 ('No')\n",
      "\n",
      "--- Cell 4: Tokenizer Loading and Yes/No Token ID Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Load Tokenizer and Define Yes/No Token Logic ---\n",
    "\n",
    "# 4.1. Load Tokenizer\n",
    "print(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=HF_MODEL_CACHE_DIR)\n",
    "    # Set pad token if not already set (Llama tokenizers often don't have one)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        print(f\"Set tokenizer.pad_token to tokenizer.eos_token ('{tokenizer.eos_token}')\")\n",
    "    print(\"Tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load tokenizer for {MODEL_NAME}: {e}\")\n",
    "\n",
    "\n",
    "# 4.2. Define Helper Function to get Yes/No Token IDs\n",
    "def get_yes_no_token_ids(tokenizer_arg):\n",
    "    \"\"\"Determines token IDs for 'Yes'/'No', preferring those with a leading space.\"\"\"\n",
    "    # Try with leading space first for chat models\n",
    "    yes_variants = [\" Yes\", \"Yes\"]\n",
    "    no_variants = [\" No\", \"No\"]\n",
    "    \n",
    "    final_yes_id = None\n",
    "    final_no_id = None\n",
    "\n",
    "    for variant in yes_variants:\n",
    "        token_ids = tokenizer_arg.encode(variant, add_special_tokens=False)\n",
    "        if len(token_ids) == 1:\n",
    "            final_yes_id = token_ids[0]\n",
    "            print(f\"Found single token for '{variant}': ID {final_yes_id}\")\n",
    "            break\n",
    "            \n",
    "    for variant in no_variants:\n",
    "        token_ids = tokenizer_arg.encode(variant, add_special_tokens=False)\n",
    "        if len(token_ids) == 1:\n",
    "            final_no_id = token_ids[0]\n",
    "            print(f\"Found single token for '{variant}': ID {final_no_id}\")\n",
    "            break\n",
    "\n",
    "    if final_yes_id is None or final_no_id is None:\n",
    "        print(f\"ERROR: Could not determine reliable single token IDs for 'Yes'/'No' or variants.\")\n",
    "        # You might want to print detailed tokenization attempts here if this error occurs\n",
    "        raise ValueError(\"Unstable tokenization for 'Yes'/'No'. Cannot proceed.\")\n",
    "    \n",
    "    return final_yes_id, final_no_id\n",
    "\n",
    "# 4.3. Define Global YES_TOKEN_ID and NO_TOKEN_ID\n",
    "try:\n",
    "    YES_TOKEN_ID, NO_TOKEN_ID = get_yes_no_token_ids(tokenizer)\n",
    "    print(f\"GLOBAL YES_TOKEN_ID: {YES_TOKEN_ID} ('{tokenizer.decode([YES_TOKEN_ID]).strip()}')\")\n",
    "    print(f\"GLOBAL NO_TOKEN_ID: {NO_TOKEN_ID} ('{tokenizer.decode([NO_TOKEN_ID]).strip()}')\")\n",
    "except ValueError as e:\n",
    "    raise RuntimeError(f\"Failed to set YES/NO token IDs: {e}\")\n",
    "\n",
    "print(\"\\n--- Cell 4: Tokenizer Loading and Yes/No Token ID Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "546dc473-9b23-4b0d-aff2-a1064c893deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: meta-llama/Llama-2-70b-chat-hf with 4-bit quantization. This will take significant time and memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59294123a4784e4e86c1092d9ac17a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully!\n",
      "Time taken to load model: 44.49 seconds.\n",
      "Model device map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 2, 'model.layers.25': 2, 'model.layers.26': 2, 'model.layers.27': 2, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.layers.32': 3, 'model.layers.33': 3, 'model.layers.34': 3, 'model.layers.35': 3, 'model.layers.36': 3, 'model.layers.37': 3, 'model.layers.38': 4, 'model.layers.39': 4, 'model.layers.40': 4, 'model.layers.41': 4, 'model.layers.42': 4, 'model.layers.43': 4, 'model.layers.44': 4, 'model.layers.45': 4, 'model.layers.46': 4, 'model.layers.47': 4, 'model.layers.48': 5, 'model.layers.49': 5, 'model.layers.50': 5, 'model.layers.51': 5, 'model.layers.52': 5, 'model.layers.53': 5, 'model.layers.54': 5, 'model.layers.55': 5, 'model.layers.56': 5, 'model.layers.57': 5, 'model.layers.58': 6, 'model.layers.59': 6, 'model.layers.60': 6, 'model.layers.61': 6, 'model.layers.62': 6, 'model.layers.63': 6, 'model.layers.64': 6, 'model.layers.65': 6, 'model.layers.66': 6, 'model.layers.67': 6, 'model.layers.68': 7, 'model.layers.69': 7, 'model.layers.70': 7, 'model.layers.71': 7, 'model.layers.72': 7, 'model.layers.73': 7, 'model.layers.74': 7, 'model.layers.75': 7, 'model.layers.76': 7, 'model.layers.77': 7, 'model.layers.78': 7, 'model.layers.79': 7, 'model.norm': 7, 'model.rotary_emb': 7, 'lm_head': 7}\n",
      "Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\n",
      "\n",
      "--- Cell 5: Llama 2 70B Model Loading Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Llama 2 70B Model ---\n",
    "# This is a memory-intensive step. `device_map=\"auto\"` will attempt to distribute\n",
    "# the model across available GPUs if one is insufficient.\n",
    "# Ensure CUDA_VISIBLE_DEVICES is set in your shell if you want to restrict which GPUs are used.\n",
    "import gc\n",
    "print(f\"Loading model: {MODEL_NAME} with 4-bit quantization. This will take significant time and memory...\")\n",
    "model_load_start_time = time.time()\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,    # Apply 4-bit quantization\n",
    "        torch_dtype=torch.bfloat16,        # Use bfloat16 on A100s\n",
    "        device_map=\"auto\",                 # Distribute model across available GPUs automatically\n",
    "        trust_remote_code=True,            # Often needed for newer models\n",
    "        cache_dir=HF_MODEL_CACHE_DIR\n",
    "    )\n",
    "    model_load_end_time = time.time()\n",
    "    print(\"\\nModel loaded successfully!\")\n",
    "    print(f\"Time taken to load model: {model_load_end_time - model_load_start_time:.2f} seconds.\")\n",
    "    print(f\"Model device map: {model.hf_device_map}\") # Shows how layers are distributed\n",
    "    # For a 70B model, this should show parts on different GPUs if more than one is used.\n",
    "    \n",
    "    # Perform a quick memory cleanup after loading large model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise RuntimeError(f\"Failed to load model {MODEL_NAME}: {e}. Check VRAM, CUDA setup, and Hugging Face authentication.\")\n",
    "\n",
    "print(\"\\n--- Cell 5: Llama 2 70B Model Loading Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2688f1be-afae-4ce5-8991-2686bbfac0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m new_max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m  \u001b[38;5;66;03m# Let's try allowing up to 256 new tokens\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43minputs\u001b[49m,\n\u001b[1;32m      9\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39mnew_max_tokens, \u001b[38;5;66;03m# MODIFIED\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     12\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m     13\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;66;03m# Important for some models when batching or using attention_mask\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m response_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m assistant_response_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED PART ---\n",
    "# Increase max_new_tokens to allow for longer output\n",
    "# You can adjust this value. The model will also stop if it generates an EOS token.\n",
    "new_max_tokens = 256  # Let's try allowing up to 256 new tokens\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=new_max_tokens, # MODIFIED\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id # Important for some models when batching or using attention_mask\n",
    "    )\n",
    "\n",
    "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "assistant_response_start = -1\n",
    "# Try to find the common end-of-instruction marker for chat models\n",
    "# For Llama-2 style:\n",
    "if \" [/INST] \" in response_text:\n",
    "    assistant_response_start = response_text.rfind(\" [/INST] \") + len(\" [/INST] \")\n",
    "# For other potential chatML-like structures:\n",
    "elif \"<|assistant|>\\n\" in response_text: # Anthropic/Claude style or similar\n",
    "    assistant_response_start = response_text.rfind(\"<|assistant|>\\n\") + len(\"<|assistant|>\\n\")\n",
    "elif \"<|im_start|>assistant\\n\" in response_text: # Newer ChatML\n",
    "    assistant_response_start = response_text.rfind(\"<|im_start|>assistant\\n\") + len(\"<|im_start|>assistant\\n\")\n",
    "\n",
    "\n",
    "if assistant_response_start != -1:\n",
    "    clean_response = response_text[assistant_response_start:].strip()\n",
    "else:\n",
    "    # Fallback: if the prompt was simple and no clear marker,\n",
    "    # try to remove the original prompt from the start of the response text.\n",
    "    # This is less robust.\n",
    "    formatted_prompt_without_generation_cue = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    if response_text.startswith(formatted_prompt_without_generation_cue):\n",
    "        clean_response = response_text[len(formatted_prompt_without_generation_cue):].strip()\n",
    "    else:\n",
    "        # Last resort: very basic split if we can't find a good marker.\n",
    "        # This assumes the model *only* added new text.\n",
    "        prompt_tokens_count = inputs.input_ids.shape[1]\n",
    "        generated_tokens = outputs[0][prompt_tokens_count:]\n",
    "        clean_response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        if not clean_response: # If the above still fails, show the raw output\n",
    "             clean_response = \"Could not reliably clean the prompt. Raw output (minus special tokens):\\n\" + response_text\n",
    "\n",
    "\n",
    "print(f\"\\nModel Response (cleaned, potentially longer): {clean_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fae66bb-f328-4814-9e23-cbc376eca2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started. Looking for zip file at: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip\n",
      "Zip file found at /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip.\n",
      "Attempting to unzip /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip to /raid/infolab/gaurav/Llama_Spider_A100_Project/...\n",
      "Successfully unzipped files to /raid/infolab/gaurav/Llama_Spider_A100_Project/\n",
      "Contents of /raid/infolab/gaurav/Llama_Spider_A100_Project/:\n",
      "  - experiments_70b_llama\n",
      "  - .gitignore\n",
      "  - backup_to_github.sh\n",
      "  - Miniconda3-latest-Linux-x86_64.sh\n",
      "  - spider_subset_data.zip\n",
      "  - randomQ_allDBs_run1\n",
      "  - .ipynb_checkpoints\n",
      "  - .git\n",
      "  - miniconda3\n",
      "  - spider_subset_data\n",
      "  - __MACOSX\n",
      "\n",
      "Verifying extracted file paths...\n",
      "SUCCESS: dev.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "SUCCESS: tables.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n",
      "\n",
      "--- Ready to load data ---\n",
      "Path to dev.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "Path to tables.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "SERVER_ZIP_FILE_PATH = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip'\n",
    "EXTRACTION_DESTINATION_DIR_ON_SERVER = '/raid/infolab/gaurav/Llama_Spider_A100_Project/'\n",
    "\n",
    "DEV_JSON_PATH = None\n",
    "TABLES_JSON_PATH = None\n",
    "\n",
    "def unzip_data(zip_filepath, dest_dir):\n",
    "    \"\"\"\n",
    "    Unzips a zip file to a specified destination directory.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to unzip {zip_filepath} to {dest_dir}...\")\n",
    "    try:\n",
    "        \n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "        print(f\"Successfully unzipped files to {dest_dir}\")\n",
    "\n",
    "        print(f\"Contents of {dest_dir}:\")\n",
    "        for item in os.listdir(dest_dir):\n",
    "            print(f\"  - {item}\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: {zip_filepath} is not a valid zip file or is corrupted.\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Zip file not found at {zip_filepath}. Please ensure the path is correct.\")\n",
    "        return False\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied to write to {dest_dir} or read {zip_filepath}.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during unzipping: {e}\")\n",
    "        return False\n",
    "\n",
    "print(f\"Script started. Looking for zip file at: {SERVER_ZIP_FILE_PATH}\")\n",
    "\n",
    "if os.path.exists(SERVER_ZIP_FILE_PATH):\n",
    "    print(f\"Zip file found at {SERVER_ZIP_FILE_PATH}.\")\n",
    "    if unzip_data(SERVER_ZIP_FILE_PATH, EXTRACTION_DESTINATION_DIR_ON_SERVER):\n",
    "        \n",
    "        EXPECTED_EXTRACTED_FOLDER_NAME = 'spider_subset_data' # This is the folder INSIDE the zip\n",
    "\n",
    "        DEV_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'dev.json')\n",
    "        TABLES_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'tables.json')\n",
    "\n",
    "        print(\"\\nVerifying extracted file paths...\")\n",
    "        if os.path.exists(DEV_JSON_PATH):\n",
    "            print(f\"SUCCESS: dev.json path is valid: {DEV_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: dev.json NOT FOUND at expected path: {DEV_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "\n",
    "        if os.path.exists(TABLES_JSON_PATH):\n",
    "            print(f\"SUCCESS: tables.json path is valid: {TABLES_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: tables.json NOT FOUND at expected path: {TABLES_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Unzipping failed on the server. Cannot define data paths.\")\n",
    "else:\n",
    "    print(f\"ERROR: Zip file NOT FOUND at {SERVER_ZIP_FILE_PATH} on the server.\")\n",
    "    print(\"Please ensure the 'scp' command was successful and the path is correct.\")\n",
    "\n",
    "\n",
    "if DEV_JSON_PATH and TABLES_JSON_PATH and os.path.exists(DEV_JSON_PATH) and os.path.exists(TABLES_JSON_PATH):\n",
    "    print(\"\\n--- Ready to load data ---\")\n",
    "    print(f\"Path to dev.json: {DEV_JSON_PATH}\")\n",
    "    print(f\"Path to tables.json: {TABLES_JSON_PATH}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n--- Data paths are not correctly set up. Cannot proceed with data loading. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9b93479-df37-4b4b-9f80-44c9222dba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 queries from dev.json\n",
      "Loaded 166 database schemas from tables.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(f\"ERROR: File not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "dev_data = load_json_data(DEV_JSON_PATH)\n",
    "tables_data = load_json_data(TABLES_JSON_PATH)\n",
    "\n",
    "if dev_data and tables_data:\n",
    "    print(f\"Loaded {len(dev_data)} queries from dev.json\")\n",
    "    print(f\"Loaded {len(tables_data)} database schemas from tables.json\")\n",
    "else:\n",
    "    print(\"Failed to load Spider data. Please check paths and upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c304d6-7712-4138-9d36-cbab1a8e225d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Preparing Database Schema SQL Strings (Dictionary Output) ---\n",
      "Loaded schema data for 166 databases from '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json'.\n",
      "Successfully populated `all_db_schemas_sql_strings` dictionary with 166 entries.\n",
      "\n",
      "--- Verification of all_db_schemas_sql_strings ---\n",
      "Type: <class 'dict'>\n",
      "Number of schemas processed: 166\n",
      "Sample - DB ID: perpetrator\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# import os # Not strictly needed for this dictionary creation unless used in paths\n",
    "# import traceback # Only needed if you keep the full traceback print in except\n",
    "\n",
    "# --- Helper Functions (These are the same as you provided) ---\n",
    "def load_schemas(tables_json_path):\n",
    "    \"\"\"Loads schemas from tables.json into a dictionary keyed by db_id.\"\"\"\n",
    "    with open(tables_json_path, 'r') as f:\n",
    "        schemas_list = json.load(f)\n",
    "    schemas_dict = {db_info['db_id']: db_info for db_info in schemas_list}\n",
    "    return schemas_dict\n",
    "\n",
    "def map_spider_type_to_sql_type(spider_type, is_pk_or_fk=False):\n",
    "    \"\"\"Maps Spider's generic types to SQLite data types.\"\"\"\n",
    "    spider_type = spider_type.lower()\n",
    "    if spider_type == \"text\":\n",
    "        return \"TEXT\"\n",
    "    elif spider_type == \"number\":\n",
    "        return \"INTEGER\" if is_pk_or_fk else \"REAL\"\n",
    "    elif spider_type == \"time\":\n",
    "        return \"DATETIME\"\n",
    "    elif spider_type == \"boolean\":\n",
    "        return \"BOOLEAN\"\n",
    "    elif spider_type == \"others\":\n",
    "        return \"BLOB\"\n",
    "    else:\n",
    "        return \"TEXT\"\n",
    "\n",
    "def escape_sql_identifier(name):\n",
    "    \"\"\"Escapes SQL identifiers (table/column names) if they contain spaces or are keywords.\"\"\"\n",
    "    if \" \" in name or name.lower() in {\"select\", \"from\", \"where\", \"table\", \"primary\", \"key\", \"foreign\", \"index\", \"order\", \"group\"}:\n",
    "        return f'\"{name}\"'\n",
    "    return name\n",
    "\n",
    "def generate_create_table_sql_for_db(db_id, all_schemas_data): # Parameter name changed for consistency\n",
    "    \"\"\"\n",
    "    Generates SQL CREATE TABLE statements for a given db_id from the Spider schema.\n",
    "    'all_schemas_data' is the dictionary produced by load_schemas.\n",
    "    \"\"\"\n",
    "    if db_id not in all_schemas_data:\n",
    "        return f\"-- Database ID '{db_id}' not found in schemas.\"\n",
    "\n",
    "    db_schema = all_schemas_data[db_id] # Get the specific schema info for this db_id\n",
    "    sql_statements = []\n",
    "    column_info_by_index = {}\n",
    "    for i, (table_idx, col_name_original) in enumerate(db_schema['column_names_original']):\n",
    "        if col_name_original == \"*\":\n",
    "            continue\n",
    "        column_info_by_index[i] = {\n",
    "            \"original_name\": col_name_original,\n",
    "            \"table_index\": table_idx,\n",
    "            \"original_table_name\": db_schema['table_names_original'][table_idx],\n",
    "            \"type\": db_schema['column_types'][i]\n",
    "        }\n",
    "    for table_idx, table_name_original in enumerate(db_schema['table_names_original']):\n",
    "        escaped_table_name = escape_sql_identifier(table_name_original)\n",
    "        column_definitions = []\n",
    "        table_constraints = []\n",
    "        current_table_columns = []\n",
    "        for col_global_idx, (tbl_idx_for_col, col_name_orig) in enumerate(db_schema['column_names_original']):\n",
    "            if col_name_orig == \"*\":\n",
    "                continue\n",
    "            if tbl_idx_for_col == table_idx:\n",
    "                current_table_columns.append({\n",
    "                    \"global_idx\": col_global_idx,\n",
    "                    \"name\": col_name_orig,\n",
    "                    \"type\": db_schema['column_types'][col_global_idx]\n",
    "                })\n",
    "        pk_column_indices_for_table = [\n",
    "            pk_idx for pk_idx in db_schema['primary_keys']\n",
    "            if column_info_by_index.get(pk_idx) and column_info_by_index[pk_idx]['table_index'] == table_idx\n",
    "        ]\n",
    "        pk_column_names_for_table = [column_info_by_index[idx]['original_name'] for idx in pk_column_indices_for_table]\n",
    "        for col_data in current_table_columns:\n",
    "            col_name_original = col_data['name']\n",
    "            spider_type = col_data['type']\n",
    "            col_global_idx = col_data['global_idx']\n",
    "            is_pk_col = col_global_idx in pk_column_indices_for_table\n",
    "            is_fk_col = any(fk_pair[0] == col_global_idx for fk_pair in db_schema['foreign_keys'])\n",
    "            sql_type = map_spider_type_to_sql_type(spider_type, is_pk_or_fk=(is_pk_col or is_fk_col))\n",
    "            escaped_col_name = escape_sql_identifier(col_name_original)\n",
    "            col_def_str = f\"{escaped_col_name} {sql_type}\"\n",
    "            if is_pk_col and len(pk_column_names_for_table) == 1:\n",
    "                col_def_str += \" PRIMARY KEY\"\n",
    "            column_definitions.append(col_def_str)\n",
    "        if len(pk_column_names_for_table) > 1:\n",
    "            escaped_pk_cols = [escape_sql_identifier(name) for name in pk_column_names_for_table]\n",
    "            table_constraints.append(f\"PRIMARY KEY ({', '.join(escaped_pk_cols)})\")\n",
    "        for fk_col_idx, referenced_col_idx in db_schema['foreign_keys']:\n",
    "            if column_info_by_index.get(fk_col_idx) and \\\n",
    "               column_info_by_index.get(referenced_col_idx) and \\\n",
    "               column_info_by_index[fk_col_idx]['table_index'] == table_idx:\n",
    "                fk_column_name = column_info_by_index[fk_col_idx]['original_name']\n",
    "                referenced_table_name = column_info_by_index[referenced_col_idx]['original_table_name']\n",
    "                referenced_column_name = column_info_by_index[referenced_col_idx]['original_name']\n",
    "                escaped_fk_col = escape_sql_identifier(fk_column_name)\n",
    "                escaped_ref_table = escape_sql_identifier(referenced_table_name)\n",
    "                escaped_ref_col = escape_sql_identifier(referenced_column_name)\n",
    "                table_constraints.append(\n",
    "                    f\"FOREIGN KEY ({escaped_fk_col}) REFERENCES {escaped_ref_table} ({escaped_ref_col})\"\n",
    "                )\n",
    "        all_parts = column_definitions + table_constraints\n",
    "        create_table_statement = f\"CREATE TABLE {escaped_table_name} (\\n  \"\n",
    "        create_table_statement += \",\\n  \".join(all_parts)\n",
    "        create_table_statement += \"\\n);\"\n",
    "        sql_statements.append(create_table_statement)\n",
    "    return \"\\n\\n\".join(sql_statements)\n",
    "# --- End of Helper Functions ---\n",
    "\n",
    "\n",
    "# --- MODIFIED \"Main Execution\" for \"Cell 1\" to produce the dictionary ---\n",
    "# This code will be run when you execute the Jupyter cell.\n",
    "# The output variable needed by your experiment is `all_db_schemas_sql_strings`.\n",
    "\n",
    "all_db_schemas_sql_strings = {} # This is the dictionary your experiment needs\n",
    "\n",
    "# Define the path to your tables.json\n",
    "spider_tables_json_path = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json'\n",
    "\n",
    "print(\"--- Cell 1: Preparing Database Schema SQL Strings (Dictionary Output) ---\")\n",
    "try:\n",
    "    # 1. Load all schema structures from tables.json\n",
    "    # `all_db_schemas_data_loaded` will be a dictionary: {db_id: schema_info_dict, ...}\n",
    "    all_db_schemas_data_loaded = load_schemas(spider_tables_json_path) # Renamed to avoid confusion with function parameter\n",
    "    print(f\"Loaded schema data for {len(all_db_schemas_data_loaded)} databases from '{spider_tables_json_path}'.\")\n",
    "\n",
    "    # 2. Iterate through each loaded schema and generate its SQL string, storing it in the dictionary\n",
    "    if all_db_schemas_data_loaded:\n",
    "        for db_id in all_db_schemas_data_loaded: # Iterate through keys (db_ids)\n",
    "            # Call generate_create_table_sql_for_db, passing the full loaded data\n",
    "            # and the current db_id.\n",
    "            sql_string_for_db = generate_create_table_sql_for_db(db_id, all_db_schemas_data_loaded)\n",
    "\n",
    "            # Store the raw SQL string in the dictionary.\n",
    "            # We only store it if it's a successful generation (doesn't start with the error message)\n",
    "            if sql_string_for_db and not sql_string_for_db.startswith(\"-- Database ID\"):\n",
    "                all_db_schemas_sql_strings[db_id] = sql_string_for_db\n",
    "            elif sql_string_for_db.startswith(\"-- Database ID\"):\n",
    "                print(f\"Warning: Schema for {db_id} reported as not found by generate_create_table_sql_for_db.\")\n",
    "            else:\n",
    "                print(f\"Warning: SQL generation returned empty or unexpected for {db_id} (Result: '{sql_string_for_db[:50]}...')\")\n",
    "\n",
    "        print(f\"Successfully populated `all_db_schemas_sql_strings` dictionary with {len(all_db_schemas_sql_strings)} entries.\")\n",
    "    else:\n",
    "        print(\"No schema data loaded from tables.json, so `all_db_schemas_sql_strings` will be empty.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The file '{spider_tables_json_path}' was not found.\")\n",
    "    all_db_schemas_sql_strings = {} # Ensure it's defined as empty on error\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"FATAL ERROR: Could not decode JSON from '{spider_tables_json_path}'. Check if it's a valid JSON file.\")\n",
    "    all_db_schemas_sql_strings = {}\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR during schema preparation: {e}\")\n",
    "    # import traceback # Uncomment if you need the full traceback here\n",
    "    # traceback.print_exc()\n",
    "    all_db_schemas_sql_strings = {}\n",
    "\n",
    "# --- Verification (you can add this to your cell to check after it runs) ---\n",
    "print(f\"\\n--- Verification of all_db_schemas_sql_strings ---\")\n",
    "print(f\"Type: {type(all_db_schemas_sql_strings)}\")\n",
    "print(f\"Number of schemas processed: {len(all_db_schemas_sql_strings)}\")\n",
    "if all_db_schemas_sql_strings:\n",
    "    # Print a sample to verify content\n",
    "    sample_db_id = list(all_db_schemas_sql_strings.keys())[0]\n",
    "    print(f\"Sample - DB ID: {sample_db_id}\")\n",
    "    # print(f\"Sample - SQL String (first 300 chars):\\n{all_db_schemas_sql_strings[sample_db_id][:300]}...\")\n",
    "else:\n",
    "    print(\"`all_db_schemas_sql_strings` is empty. Review errors above.\")\n",
    "# --- End of Cell 1 Logic ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d67f720-5263-4bb6-8db6-a4da23c1a95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: This experiment configuration will test each randomly selected query against ALL available Spider database schemas.\n",
      "\n",
      "Randomly selected 100 NL queries for the experiment:\n",
      "  Test Query 1: 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n",
      "  Test Query 2: 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n",
      "  Test Query 3: 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n",
      "  Test Query 4: 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n",
      "  Test Query 5: 'How many different nationalities do conductors have?' (True DB: orchestra)\n",
      "  Test Query 6: 'How many states are there?' (True DB: voter_1)\n",
      "  Test Query 7: 'What are the codes of template types that have fewer than 3 templates?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 8: 'How many dogs have not gone through any treatment?' (True DB: dog_kennels)\n",
      "  Test Query 9: 'What are the template ids of any templates used in more than a single document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 10: 'Show name, country, age for all singers ordered by age from the oldest to the youngest.' (True DB: concert_singer)\n",
      "  Test Query 11: 'Show the student IDs and numbers of friends corresponding to each.' (True DB: network_1)\n",
      "  Test Query 12: 'What are flight numbers of flights arriving at City \"Aberdeen\"?' (True DB: flight_2)\n",
      "  Test Query 13: 'How many countries speak both English and Dutch?' (True DB: world_1)\n",
      "  Test Query 14: 'What are the notes of the death events which has substring 'East'?' (True DB: battle_death)\n",
      "  Test Query 15: 'What are the names of conductors as well as the corresonding orchestras that they have conducted?' (True DB: orchestra)\n",
      "  Test Query 16: 'List the earnings of poker players in descending order.' (True DB: poker_player)\n",
      "  Test Query 17: 'Which owner has paid the largest amount of money in total for their dogs? Show the owner id and zip code.' (True DB: dog_kennels)\n",
      "  Test Query 18: 'Find the number of flights landing in the city of Aberdeen or Abilene.' (True DB: flight_2)\n",
      "  Test Query 19: 'How many pets have a greater weight than 10?' (True DB: pets_1)\n",
      "  Test Query 20: 'Show different citizenships and the maximum net worth of singers of each citizenship.' (True DB: singer)\n",
      "  Test Query 21: 'What are the population, name and leader of the country with the largest area?' (True DB: world_1)\n",
      "  Test Query 22: 'For each semester, what is the name and id of the one with the most students registered?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 23: 'Show paragraph details for paragraph with text 'Korea ' .' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 24: 'Return the number of  airports.' (True DB: flight_2)\n",
      "  Test Query 25: 'Find the average age of losers and winners of all matches.' (True DB: wta_1)\n",
      "  Test Query 26: 'What is the most commmon hometowns for teachers?' (True DB: course_teach)\n",
      "  Test Query 27: 'List the title of all cartoons in alphabetical order.' (True DB: tvshow)\n",
      "  Test Query 28: 'What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?' (True DB: car_1)\n",
      "  Test Query 29: 'What is the average transcript date?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 30: 'What is the total population of Gelderland district?' (True DB: world_1)\n",
      "  Test Query 31: 'Return the money rank of the player with the greatest earnings.' (True DB: poker_player)\n",
      "  Test Query 32: 'What are the names of the sections in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 33: 'What languages are only used by a single country with a republic government?' (True DB: world_1)\n",
      "  Test Query 34: 'Return the id of the document with the fewest paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 35: 'What are the descriptions for all the math courses?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 36: 'Find the first name of students who have both cat and dog pets .' (True DB: pets_1)\n",
      "  Test Query 37: 'Find the type and weight of the youngest pet.' (True DB: pets_1)\n",
      "  Test Query 38: 'Find the role, street, city and state of the professionals living in a city that contains the substring 'West'.' (True DB: dog_kennels)\n",
      "  Test Query 39: 'What is the code of airport that has the highest number of flights?' (True DB: flight_2)\n",
      "  Test Query 40: 'What is the Package Option of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Test Query 41: 'Tell me the age of the oldest dog.' (True DB: dog_kennels)\n",
      "  Test Query 42: 'What are the countries that have greater surface area than any country in Europe?' (True DB: world_1)\n",
      "  Test Query 43: 'Find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.' (True DB: concert_singer)\n",
      "  Test Query 44: 'List the names and birth dates of people in ascending alphabetical order of name.' (True DB: poker_player)\n",
      "  Test Query 45: 'How many cities in each district have a population that is above the average population across all cities?' (True DB: world_1)\n",
      "  Test Query 46: 'Return the nationalities for which there are two or more people.' (True DB: poker_player)\n",
      "  Test Query 47: 'How many documents do we have?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 48: 'Tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.' (True DB: dog_kennels)\n",
      "  Test Query 49: 'What are the names and descriptions for all the sections?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 50: 'How many available features are there in total?' (True DB: real_estate_properties)\n",
      "  Test Query 51: 'What are the birth year and citizenship of singers?' (True DB: singer)\n",
      "  Test Query 52: 'How many matches were played in each year?' (True DB: wta_1)\n",
      "  Test Query 53: 'Which airlines have at least 10 flights?' (True DB: flight_2)\n",
      "  Test Query 54: 'What is the name and id of the department with the most number of degrees ?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 55: 'What are the ids for templates that are not used in any documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 56: 'What is the last transcript release date?' (True DB: student_transcripts_tracking)\n",
      "  Test Query 57: 'What are the names of the teachers ordered by ascending age?' (True DB: course_teach)\n",
      "  Test Query 58: 'Show the date and id of the transcript with at least 2 course results.' (True DB: student_transcripts_tracking)\n",
      "  Test Query 59: 'What are the names of conductors whose nationalities are not \"USA\"?' (True DB: orchestra)\n",
      "  Test Query 60: 'What are the names of students who have no friends?' (True DB: network_1)\n",
      "  Test Query 61: 'What is the count of the car models produced in the United States?' (True DB: car_1)\n",
      "  Test Query 62: 'What are the names of countries that speak more than 2 languages, as well as how many languages they speak?' (True DB: world_1)\n",
      "  Test Query 63: 'Give the name, population, and head of state for the country that has the largest area.' (True DB: world_1)\n",
      "  Test Query 64: 'How many different results are there for the battles?' (True DB: battle_death)\n",
      "  Test Query 65: 'What are the names of the countries with no car makers?' (True DB: car_1)\n",
      "  Test Query 66: 'What is the language that is used by the largest number of Asian nations?' (True DB: world_1)\n",
      "  Test Query 67: 'Return the record companies of orchestras, sorted descending by the years in which they were founded.' (True DB: orchestra)\n",
      "  Test Query 68: 'What are the names of properties that are either houses or apartments with more than 1 room?' (True DB: real_estate_properties)\n",
      "  Test Query 69: 'find the package option of the tv channel that do not have any cartoon directed by Ben Jones.' (True DB: tvshow)\n",
      "  Test Query 70: 'List the last name of the owner owning the youngest dog.' (True DB: dog_kennels)\n",
      "  Test Query 71: 'What is the name and capacity of the stadium with the most concerts after 2013 ?' (True DB: concert_singer)\n",
      "  Test Query 72: 'What are the names of conductors who have conducted orchestras founded after the year 2008?' (True DB: orchestra)\n",
      "  Test Query 73: 'How many cars has over 6 cylinders?' (True DB: car_1)\n",
      "  Test Query 74: 'What is the number of car models that are produced by each maker and what is the id and full name of each maker?' (True DB: car_1)\n",
      "  Test Query 75: 'What are the names of conductors, sorted descending by the number of years they have worked?' (True DB: orchestra)\n",
      "  Test Query 76: 'What are the distinct template type descriptions for the templates ever used by any document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 77: 'What are the names of poker players, ordered ascending by the number of final tables they have made?' (True DB: poker_player)\n",
      "  Test Query 78: 'What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?' (True DB: car_1)\n",
      "  Test Query 79: 'What is the TV Channel of TV series with Episode \"A Love of a Lifetime\"? List the TV Channel's series name.' (True DB: tvshow)\n",
      "  Test Query 80: 'What is the lowest grade of students who do not have any friends?' (True DB: network_1)\n",
      "  Test Query 81: 'Show the name and theme for all concerts and the number of singers in each concert.' (True DB: concert_singer)\n",
      "  Test Query 82: 'What is the total ticket expense of the visitors whose membership level is 1?' (True DB: museum_visit)\n",
      "  Test Query 83: 'Which professionals have done at least two types of treatments? List the professional id and cell phone.' (True DB: dog_kennels)\n",
      "  Test Query 84: 'How many countries does each continent have? List the continent id, continent name and the number of countries.' (True DB: car_1)\n",
      "  Test Query 85: 'What is the average, minimum, and maximum age for all French singers?' (True DB: concert_singer)\n",
      "  Test Query 86: 'What is the car model with the highest mpg ?' (True DB: car_1)\n",
      "  Test Query 87: 'How many flights do we have?' (True DB: flight_2)\n",
      "  Test Query 88: 'What is the series name of the TV Channel that shows the cartoon \"The Rise of the Blue Beetle\"?' (True DB: tvshow)\n",
      "  Test Query 89: 'What is the name of the conductor who has conducted the most orchestras?' (True DB: orchestra)\n",
      "  Test Query 90: 'How many battles did not lose any ship with tonnage '225'?' (True DB: battle_death)\n",
      "  Test Query 91: 'Of all the contestants who got voted, what is the contestant number and name of the contestant who got least votes?' (True DB: voter_1)\n",
      "  Test Query 92: 'What are the regions that use English or Dutch?' (True DB: world_1)\n",
      "  Test Query 93: 'Find the average number of staff working for the museums that were open before 2009.' (True DB: museum_visit)\n",
      "  Test Query 94: 'Find the total number of players.' (True DB: wta_1)\n",
      "  Test Query 95: 'Sort all the shops by number products in descending order, and return the name, location and district of each shop.' (True DB: employee_hire_evaluation)\n",
      "  Test Query 96: 'Describe the section h.' (True DB: student_transcripts_tracking)\n",
      "  Test Query 97: 'Count the number of paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Test Query 98: 'Find the number of pets whose weight is heavier than 10.' (True DB: pets_1)\n",
      "  Test Query 99: 'What are the record companies that are used by both orchestras founded before 2003 and those founded after 2003?' (True DB: orchestra)\n",
      "  Test Query 100: 'What are the ids and makers of all car makers that produce at least 2 models and make more than 3 cars?' (True DB: car_1)\n",
      "\n",
      "Each of the 100 selected queries will be evaluated against all 166 available Spider database schemas.\n"
     ]
    }
   ],
   "source": [
    "# This cell defines parameters for running the experiment.\n",
    "# It will now randomly select queries and always use ALL database schemas as candidates.\n",
    "\n",
    "import random # Ensure random is imported at the top of your notebook or this cell\n",
    "# import os # Ensure os is imported (likely already done for path joining)\n",
    "# import json # Ensure json is imported (likely already done for loading)\n",
    "\n",
    "# --- 2.1. Experiment Parameters ---\n",
    "# Number of NL queries to RANDOMLY select from dev.json to process.\n",
    "# For initial testing in Colab, use a small subset. For a more thorough run, increase this.\n",
    "NUM_RANDOM_QUERIES_TO_TEST = 100 # For example, test 5 random queries\n",
    "\n",
    "# This will now effectively always be True based on your requirement.\n",
    "# The logic will be set up to use all schemas from all_db_schemas_sql_strings.\n",
    "# We can keep the variable for clarity or remove it if it's always all DBs.\n",
    "# For this implementation, let's explicitly aim for all DBs.\n",
    "print(\"INFO: This experiment configuration will test each randomly selected query against ALL available Spider database schemas.\")\n",
    "\n",
    "\n",
    "# --- 2.2. Randomly Select NL Queries for the Experiment ---\n",
    "# We will randomly sample NUM_RANDOM_QUERIES_TO_TEST queries from the loaded dev_data.\n",
    "if not dev_data: # dev_data should have been loaded in Cell 1\n",
    "    raise ValueError(\"dev_data is not loaded (from dev.json). Cannot select queries. Please run Cell 1 first.\")\n",
    "\n",
    "if len(dev_data) == 0:\n",
    "    raise ValueError(\"dev_data is empty. No queries to select.\")\n",
    "\n",
    "actual_num_queries_to_select = min(NUM_RANDOM_QUERIES_TO_TEST, len(dev_data))\n",
    "# Using min ensures we don't try to sample more queries than available.\n",
    "\n",
    "if actual_num_queries_to_select < NUM_RANDOM_QUERIES_TO_TEST:\n",
    "    print(f\"Warning: Requested {NUM_RANDOM_QUERIES_TO_TEST} random queries, but only {len(dev_data)} are available. Using all {len(dev_data)} queries.\")\n",
    "\n",
    "# Randomly sample without replacement\n",
    "selected_nl_queries = random.sample(dev_data, actual_num_queries_to_select)\n",
    "\n",
    "print(f\"\\nRandomly selected {len(selected_nl_queries)} NL queries for the experiment:\")\n",
    "for i, q_info in enumerate(selected_nl_queries):\n",
    "    print(f\"  Test Query {i+1}: '{q_info['question']}' (True DB: {q_info['db_id']})\")\n",
    "\n",
    "\n",
    "# --- 2.3. Determine Candidate Database Schemas for Each Query ---\n",
    "# For this experiment design, we ALWAYS use ALL available database schemas.\n",
    "# all_db_schemas_sql_strings should have been populated in Cell 1.\n",
    "if not all_sql_output: # Populated in Cell 1\n",
    "    raise ValueError(\"all_sql_output is empty. Schemas were not converted in Cell 1. Cannot proceed.\")\n",
    "\n",
    "candidate_schemas_for_evaluation = all_db_schemas_sql_strings # Use all converted schemas\n",
    "print(f\"\\nEach of the {len(selected_nl_queries)} selected queries will be evaluated against all {len(candidate_schemas_for_evaluation)} available Spider database schemas.\")\n",
    "\n",
    "if not candidate_schemas_for_evaluation: # Should not happen if all_db_schemas_sql_strings was populated\n",
    "    raise ValueError(\"No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "531bac23-fdaf-4552-a664-e0b0ae3ca27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured experiment project directory exists: '/raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1'\n",
      "Experiment results will be saved to: /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "LOCAL_EXPERIMENT_BASE_DIR = \"/raid/infolab/gaurav/Llama_Spider_A100_Project/\"\n",
    "\n",
    "\n",
    "EXPERIMENT_RUN_NAME = \"randomQ_allDBs_run1\" \n",
    "EXPERIMENT_PROJECT_DIR = os.path.join(LOCAL_EXPERIMENT_BASE_DIR, EXPERIMENT_RUN_NAME)\n",
    "\n",
    "try:\n",
    "    os.makedirs(EXPERIMENT_PROJECT_DIR, exist_ok=True)\n",
    "    print(f\"Ensured experiment project directory exists: '{EXPERIMENT_PROJECT_DIR}'\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory {EXPERIMENT_PROJECT_DIR}: {e}\")\n",
    "    EXPERIMENT_PROJECT_DIR = \".\" \n",
    "\n",
    "\n",
    "RESULTS_FILENAME = \"spider_random_query_all_db_scores.json\"\n",
    "EXPERIMENT_RESULTS_FILE = os.path.join(EXPERIMENT_PROJECT_DIR, RESULTS_FILENAME)\n",
    "\n",
    "print(f\"Experiment results will be saved to: {EXPERIMENT_RESULTS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f06c3025-9d75-4217-8071-1418e90aaa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function 'get_yes_no_token_ids' defined (with actual logic).\n"
     ]
    }
   ],
   "source": [
    "# Cell defining get_yes_no_token_ids (CORRECTED)\n",
    "def get_yes_no_token_ids(tokenizer_arg):\n",
    "    \"\"\"\n",
    "    Determines the token IDs for 'Yes' and 'No', accounting for potential leading spaces.\n",
    "    Llama-2-chat tends to produce \" Yes\" or \" No\" as single tokens after the prompt.\n",
    "    \"\"\"\n",
    "    # Try with leading space first, as it's common for chat models\n",
    "    yes_token_id_with_space = tokenizer_arg.encode(\" Yes\", add_special_tokens=False)\n",
    "    no_token_id_with_space = tokenizer_arg.encode(\" No\", add_special_tokens=False)\n",
    "\n",
    "    if len(yes_token_id_with_space) == 1 and len(no_token_id_with_space) == 1:\n",
    "        print(\"Using ' Yes' and ' No' (with leading space) for Yes/No token IDs.\")\n",
    "        return yes_token_id_with_space[0], no_token_id_with_space[0] # Explicit return\n",
    "    else:\n",
    "        # Fallback to \"Yes\" and \"No\" without leading space\n",
    "        yes_token_id_no_space = tokenizer_arg.encode(\"Yes\", add_special_tokens=False)\n",
    "        no_token_id_no_space = tokenizer_arg.encode(\"No\", add_special_tokens=False)\n",
    "        if len(yes_token_id_no_space) == 1 and len(no_token_id_no_space) == 1:\n",
    "            print(\"Warning: Using 'Yes' and 'No' (no leading space) for Yes/No token IDs. This might be suboptimal for chat models.\")\n",
    "            return yes_token_id_no_space[0], no_token_id_no_space[0] # Explicit return\n",
    "        else:\n",
    "            # This case is problematic.\n",
    "            print(f\"ERROR: Could not determine reliable single token IDs for 'Yes'/'No' or ' Yes'/' No'.\")\n",
    "            print(f\"Tokenization of ' Yes': {yes_token_id_with_space} (decoded: {[tokenizer_arg.decode(t) for t in yes_token_id_with_space]})\")\n",
    "            print(f\"Tokenization of ' No': {no_token_id_with_space} (decoded: {[tokenizer_arg.decode(t) for t in no_token_id_with_space]})\")\n",
    "            print(f\"Tokenization of 'Yes': {yes_token_id_no_space} (decoded: {[tokenizer_arg.decode(t) for t in yes_token_id_no_space]})\")\n",
    "            print(f\"Tokenization of 'No': {no_token_id_no_space} (decoded: {[tokenizer_arg.decode(t) for t in no_token_id_no_space]})\")\n",
    "            # It's better to raise an error here so the problem is immediately obvious\n",
    "            # rather than returning None and causing a TypeError later.\n",
    "            raise ValueError(\"Unstable tokenization for 'Yes'/'No'. Review tokenization outputs above. Cannot proceed without reliable Yes/No token IDs.\")\n",
    "\n",
    "print(\"Helper function 'get_yes_no_token_ids' defined (with actual logic).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb8b6cb-d43f-40a9-bf6e-6779c779201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Using 'Yes' and 'No' (no leading space) for Yes/No token IDs. This might be suboptimal for chat models.\n",
      "YES_TOKEN_ID: 3869 ('Yes')\n",
      "NO_TOKEN_ID: 1939 ('No')\n"
     ]
    }
   ],
   "source": [
    "if 'tokenizer' in globals() and tokenizer is not None:\n",
    "    try:\n",
    "        YES_TOKEN_ID, NO_TOKEN_ID = get_yes_no_token_ids(tokenizer)\n",
    "        print(f\"YES_TOKEN_ID: {YES_TOKEN_ID} ('{tokenizer.decode([YES_TOKEN_ID])}')\")\n",
    "        print(f\"NO_TOKEN_ID: {NO_TOKEN_ID} ('{tokenizer.decode([NO_TOKEN_ID])}')\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error defining YES/NO token IDs: {e}\")\n",
    "else:\n",
    "    print(\"ERROR: 'tokenizer' is not defined. Cannot define YES_TOKEN_ID and NO_TOKEN_ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc6a8811-2963-48c5-9f50-0eba843139cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core function 'get_yes_probability' defined.\n"
     ]
    }
   ],
   "source": [
    "import torch # Ensure torch is imported\n",
    "# After loading your tokenizer:\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", ...) # Or your specific model\n",
    "\n",
    "# Llama 2 Chat Template (common structure)\n",
    "# Make sure this matches the exact format expected by YOUR specific Llama 2 variant.\n",
    "# Check the model card on Hugging Face for the precise template.\n",
    "chat_template_llama2 = (\n",
    "    \"{% if messages[0]['role'] == 'system' %}\"\n",
    "    \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "    \"{% else %}\"\n",
    "    \"<s>[INST] \"\n",
    "    \"{% endif %}\"\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'user' %}\"\n",
    "    \"{{ message['content'] }} [/INST]\"\n",
    "    \"{% elif message['role'] == 'assistant' %}\"\n",
    "    \" {{ message['content'] }} </s><s>[INST]\"\n",
    "    \"{% elif message['role'] == 'system' and loop.index0 > 0 %}\" # Handle system message if not first\n",
    "    \" <<SYS>>\\n{{ message['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}\" # Add generation prompt if last message is not assistant\n",
    "    \" \" # This space is important before the assistant starts generating\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "# A simpler version if you always have system then user:\n",
    "# chat_template_llama2_simple = \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n{{ messages[1]['content'] }} [/INST] \"\n",
    "\n",
    "\n",
    "# --- CHOOSE THE CORRECT TEMPLATE FOR YOUR MODEL ---\n",
    "# For many Llama-2-chat models, the tokenizer might already have a default template\n",
    "# if loaded correctly, but if not, you can set it.\n",
    "# A common one if your `messages` list is always [system_message, user_message]:\n",
    "if tokenizer.chat_template is None:\n",
    "    if \"llama-2\" in tokenizer.name_or_path.lower() and \"chat\" in tokenizer.name_or_path.lower() : # Be more specific if needed\n",
    "        # This is a common structure for Llama-2-chat for a system prompt followed by a user prompt.\n",
    "        # The assistant's response will follow \" [/INST] \"\n",
    "        tokenizer.chat_template = (\n",
    "            \"{% if messages[0]['role'] == 'system' %}\"\n",
    "            \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "            \"{% endif %}\"\n",
    "            \"{{ messages[1]['content'] }} [/INST]\" # Assumes second message is user\n",
    "            # Add a space for the model to start generation if add_generation_prompt=True\n",
    "            \"{% if add_generation_prompt %} {% endif %}\"\n",
    "        )\n",
    "        print(\"Manually set Llama 2 chat template on tokenizer.\")\n",
    "    else:\n",
    "        print(\"Warning: tokenizer.chat_template is None and no specific template was set for the model type.\")\n",
    "        # You might need to define a different template or handle formatting manually.\n",
    "\n",
    "# --- Core function to get P(Yes) ---\n",
    "def get_yes_probability(model_arg, tokenizer_arg, system_prompt_arg, user_prompt_content_arg, yes_token_id_arg, no_token_id_arg, max_length=2048):\n",
    "    \"\"\"\n",
    "    Gets the probability of the model answering \"Yes\" to the given query and schema.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_arg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_content_arg}\n",
    "    ]\n",
    "\n",
    "    prompt_for_model = tokenizer_arg.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer_arg(\n",
    "        prompt_for_model,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length - 10\n",
    "    )\n",
    "    inputs = {k: v.to(model_arg.device) for k, v in inputs.items()}\n",
    "\n",
    "    if inputs['input_ids'].shape[1] >= max_length - 10:\n",
    "         print(f\"Warning: Prompt for query was truncated. Length: {inputs['input_ids'].shape[1]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_arg(**inputs)\n",
    "        logits = outputs.logits\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        logit_yes = next_token_logits[:, yes_token_id_arg].item()\n",
    "        logit_no = next_token_logits[:, no_token_id_arg].item()\n",
    "\n",
    "    max_logit = max(logit_yes, logit_no)\n",
    "    exp_yes = torch.exp(torch.tensor(logit_yes - max_logit, device=model_arg.device))\n",
    "    exp_no = torch.exp(torch.tensor(logit_no - max_logit, device=model_arg.device))\n",
    "\n",
    "    prob_yes = exp_yes / (exp_yes + exp_no)\n",
    "    return prob_yes.item()\n",
    "\n",
    "print(\"Core function 'get_yes_probability' defined.\") # Add a print statement to confirm execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dfe1828-56ee-4994-91e0-9ecc5acfb60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM_PROMPT and USER_PROMPT_TEMPLATE defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Prompt Configuration ---\n",
    "# This SYSTEM_PROMPT will be passed to your get_yes_probability function,\n",
    "# which then should use it when constructing the messages for the chat model.\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert data analyst. Your task is to determine if a given natural language query \"\n",
    "    \"can be answered *solely* based on the provided database schema. \"\n",
    "    \"Do not attempt to answer the query itself. Your entire response must be only the word 'Yes' or the word 'No'.\"\n",
    ")\n",
    "\n",
    "# This USER_PROMPT_TEMPLATE is used directly in your experiment loop\n",
    "# to format the schema and query for the user message.\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Database Schema:\n",
    "---\n",
    "{schema_string}\n",
    "---\n",
    "Natural Language Query: \"{nl_query}\"\n",
    "---\n",
    "Can the query be answered using *only* the provided schema and its potential contents? Answer with either \"Yes\" or \"No\".\n",
    "\"\"\"\n",
    "\n",
    "print(\"SYSTEM_PROMPT and USER_PROMPT_TEMPLATE defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a534772-a426-4df2-bb02-72aae58c82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing get_yes_probability directly...\n",
      "Test User Prompt: Database Schema:\n",
      "---\n",
      "CREATE TABLE TestTable (id INT, name TEXT);\n",
      "---\n",
      "Natural Language Query: \"What is the name for id 1?\"\n",
      "---\n",
      "Can the query be answered using *only* the provided schema and its potential contents? Answer with either \"Yes\" or \"No\".\n",
      "\n",
      "get_yes_probability returned: 0.8991213440895081\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing get_yes_probability directly...\")\n",
    "try:\n",
    "    # Construct a very simple schema and query for testing\n",
    "    test_schema = \"CREATE TABLE TestTable (id INT, name TEXT);\"\n",
    "    test_nl_query = \"What is the name for id 1?\"\n",
    "    sample_user_prompt_content = USER_PROMPT_TEMPLATE.format(\n",
    "        schema_string=test_schema,\n",
    "        nl_query=test_nl_query\n",
    "    )\n",
    "    print(f\"Test User Prompt: {sample_user_prompt_content}\")\n",
    "\n",
    "    # Make sure all these variables are defined and loaded:\n",
    "    # model, tokenizer, SYSTEM_PROMPT, YES_TOKEN_ID, NO_TOKEN_ID\n",
    "    prob = get_yes_probability(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        SYSTEM_PROMPT,\n",
    "        sample_user_prompt_content,\n",
    "        YES_TOKEN_ID,\n",
    "        NO_TOKEN_ID\n",
    "    )\n",
    "    print(f\"get_yes_probability returned: {prob}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"Error during direct call to get_yes_probability:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75247d87-a7f5-4ca4-8770-78e43e0c7e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Experiment: 100 Random Queries vs. 166 Total DB Schemas ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641d50c6864e42139e0506a379f0fa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NL Queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query 1/100 (ID: spider_dev_q0_idx0): 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca550b54ecc4862a2257757f87a3559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q0_idx0:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 1 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 2/100 (ID: spider_dev_q1_idx1): 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f2ef6a200b4a6c95c6a917b890847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q1_idx1:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 2 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 3/100 (ID: spider_dev_q2_idx2): 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee990280f6344979c0ca6700bb0766d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q2_idx2:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 3 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 4/100 (ID: spider_dev_q3_idx3): 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01bd9cb8fbb41888e58f4c670ac89fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q3_idx3:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 4 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 5/100 (ID: spider_dev_q4_idx4): 'How many different nationalities do conductors have?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ee0b2dd401478b93c66801a4994c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q4_idx4:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 5 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 6/100 (ID: spider_dev_q5_idx5): 'How many states are there?' (True DB: voter_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea28c6dc6ab44b3b8e597ca51bfb6eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q5_idx5:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 6 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 7/100 (ID: spider_dev_q6_idx6): 'What are the codes of template types that have fewer than 3 templates?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa957f0bef7f4582ace520b36895b851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q6_idx6:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 7 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 8/100 (ID: spider_dev_q7_idx7): 'How many dogs have not gone through any treatment?' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f58a32d30c47c38178ee0585232274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q7_idx7:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 8 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 9/100 (ID: spider_dev_q8_idx8): 'What are the template ids of any templates used in more than a single document?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7b16962000487a9f99eea98c380a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q8_idx8:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 9 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 10/100 (ID: spider_dev_q9_idx9): 'Show name, country, age for all singers ordered by age from the oldest to the youngest.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ed5ac7da984928b66d57e83a504114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q9_idx9:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 10 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 11/100 (ID: spider_dev_q10_idx10): 'Show the student IDs and numbers of friends corresponding to each.' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ee2f64880b496bbd5861b03da9e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q10_idx10:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 11 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 12/100 (ID: spider_dev_q11_idx11): 'What are flight numbers of flights arriving at City \"Aberdeen\"?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f5e87814524eb19936fea50be9662f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q11_idx11:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 12 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 13/100 (ID: spider_dev_q12_idx12): 'How many countries speak both English and Dutch?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133032e161414b87a983778bc3b41f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q12_idx12:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 13 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 14/100 (ID: spider_dev_q13_idx13): 'What are the notes of the death events which has substring 'East'?' (True DB: battle_death)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e92773a0b647be9efe37781a444af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q13_idx13:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 14 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 15/100 (ID: spider_dev_q14_idx14): 'What are the names of conductors as well as the corresonding orchestras that they have conducted?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fbf9eca6a547e5bc8b4a83a71b0c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q14_idx14:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 15 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 16/100 (ID: spider_dev_q15_idx15): 'List the earnings of poker players in descending order.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53b3e892ec443f8831b6a1b74accf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q15_idx15:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 16 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 17/100 (ID: spider_dev_q16_idx16): 'Which owner has paid the largest amount of money in total for their dogs? Show the owner id and zip code.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b31db295d94bcd851f17c6c3c3e547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q16_idx16:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 17 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 18/100 (ID: spider_dev_q17_idx17): 'Find the number of flights landing in the city of Aberdeen or Abilene.' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2262137b62d34327ac8e8f501dc03bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q17_idx17:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 18 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 19/100 (ID: spider_dev_q18_idx18): 'How many pets have a greater weight than 10?' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a774e40e3354596b13ef70f4d067a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q18_idx18:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 19 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 20/100 (ID: spider_dev_q19_idx19): 'Show different citizenships and the maximum net worth of singers of each citizenship.' (True DB: singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c730eb28134d405f93710a9eafb8a0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q19_idx19:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 20 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 21/100 (ID: spider_dev_q20_idx20): 'What are the population, name and leader of the country with the largest area?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88cfd46cf064bef9a7fb6167aaf4f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q20_idx20:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 21 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 22/100 (ID: spider_dev_q21_idx21): 'For each semester, what is the name and id of the one with the most students registered?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77365228f76747ff93c741e45ed58eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q21_idx21:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 22 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 23/100 (ID: spider_dev_q22_idx22): 'Show paragraph details for paragraph with text 'Korea ' .' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037de86f87e0462c9851ad963769757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q22_idx22:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 23 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 24/100 (ID: spider_dev_q23_idx23): 'Return the number of  airports.' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c516d37cc40844119591a2986193c45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q23_idx23:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 24 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 25/100 (ID: spider_dev_q24_idx24): 'Find the average age of losers and winners of all matches.' (True DB: wta_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a14ce6094942c1a3f980a21ad06f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q24_idx24:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 25 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 26/100 (ID: spider_dev_q25_idx25): 'What is the most commmon hometowns for teachers?' (True DB: course_teach)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501816a094ba4b4c98561f3911742de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q25_idx25:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 26 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 27/100 (ID: spider_dev_q26_idx26): 'List the title of all cartoons in alphabetical order.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ae3d82870d4e93ad2798fe65eb5f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q26_idx26:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 27 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 28/100 (ID: spider_dev_q27_idx27): 'What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9e6f83e9534bfd9a3bef079263a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q27_idx27:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 28 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 29/100 (ID: spider_dev_q28_idx28): 'What is the average transcript date?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b1dbf8645d4f65a8da2d78d0fc06f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q28_idx28:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 29 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 30/100 (ID: spider_dev_q29_idx29): 'What is the total population of Gelderland district?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e5cc072ecb4215a74d37c4bf1c2aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q29_idx29:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 30 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 31/100 (ID: spider_dev_q30_idx30): 'Return the money rank of the player with the greatest earnings.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33877c0b36de46338578374914e838b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q30_idx30:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 31 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 32/100 (ID: spider_dev_q31_idx31): 'What are the names of the sections in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1dbd31e51042f5b99e0741067c153a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q31_idx31:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 32 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 33/100 (ID: spider_dev_q32_idx32): 'What languages are only used by a single country with a republic government?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e398753baa4803a4af01bad58eaa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q32_idx32:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 33 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 34/100 (ID: spider_dev_q33_idx33): 'Return the id of the document with the fewest paragraphs.' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae39bf695efc4ccbb306d73dafe1d803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q33_idx33:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 34 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 35/100 (ID: spider_dev_q34_idx34): 'What are the descriptions for all the math courses?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e89fbce50745668d5e636db7f8b74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q34_idx34:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 35 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 36/100 (ID: spider_dev_q35_idx35): 'Find the first name of students who have both cat and dog pets .' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e954ae1d57d431fb52ffd37f069d100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q35_idx35:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 36 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 37/100 (ID: spider_dev_q36_idx36): 'Find the type and weight of the youngest pet.' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5956d3882ee74f589f9351dbb5acc14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q36_idx36:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 37 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 38/100 (ID: spider_dev_q37_idx37): 'Find the role, street, city and state of the professionals living in a city that contains the substring 'West'.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db709e2a1ae428f9ac9f68f24ffa6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q37_idx37:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 38 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 39/100 (ID: spider_dev_q38_idx38): 'What is the code of airport that has the highest number of flights?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e39c1321b242c9b9556b9766a13963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q38_idx38:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 39 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 40/100 (ID: spider_dev_q39_idx39): 'What is the Package Option of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b0037a74a4438baf382b961143d4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q39_idx39:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 40 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 41/100 (ID: spider_dev_q40_idx40): 'Tell me the age of the oldest dog.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac4f6433f7c4a5a906ee7f93e270ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q40_idx40:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 41 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 42/100 (ID: spider_dev_q41_idx41): 'What are the countries that have greater surface area than any country in Europe?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6005acc908dc468a9189187de3001efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q41_idx41:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 42 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 43/100 (ID: spider_dev_q42_idx42): 'Find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a69dec74cd34a4b8afdeab7377e8479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q42_idx42:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 43 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 44/100 (ID: spider_dev_q43_idx43): 'List the names and birth dates of people in ascending alphabetical order of name.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f51908de5394f759451c4010f10d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q43_idx43:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 44 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 45/100 (ID: spider_dev_q44_idx44): 'How many cities in each district have a population that is above the average population across all cities?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe1a09c2a73464383b662c3aa99f54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q44_idx44:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 45 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 46/100 (ID: spider_dev_q45_idx45): 'Return the nationalities for which there are two or more people.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce2051068cd42669ae9bb73f73995ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q45_idx45:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 46 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 47/100 (ID: spider_dev_q46_idx46): 'How many documents do we have?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33f25701d54e0b8618a94a4fda8432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q46_idx46:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 47 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 48/100 (ID: spider_dev_q47_idx47): 'Tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74489aacf434c7faf8269ca9261ff3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q47_idx47:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 48 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 49/100 (ID: spider_dev_q48_idx48): 'What are the names and descriptions for all the sections?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e68fc1b56034621b885c5ba894e67bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q48_idx48:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 49 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 50/100 (ID: spider_dev_q49_idx49): 'How many available features are there in total?' (True DB: real_estate_properties)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb46bc64c264878a8e127c3f2eb0e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q49_idx49:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 50 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 51/100 (ID: spider_dev_q50_idx50): 'What are the birth year and citizenship of singers?' (True DB: singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a41e2ceddc44f3bb11beb0163042b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q50_idx50:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 51 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 52/100 (ID: spider_dev_q51_idx51): 'How many matches were played in each year?' (True DB: wta_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26eb023367d4b83b039a93522920826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q51_idx51:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 52 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 53/100 (ID: spider_dev_q52_idx52): 'Which airlines have at least 10 flights?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26452bd7fdf49629485ed6019f6ec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q52_idx52:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 53 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 54/100 (ID: spider_dev_q53_idx53): 'What is the name and id of the department with the most number of degrees ?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e633eeda8f477291e2e07905154db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q53_idx53:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 54 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 55/100 (ID: spider_dev_q54_idx54): 'What are the ids for templates that are not used in any documents?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328435a4540d42299f2497be5f611a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q54_idx54:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 55 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 56/100 (ID: spider_dev_q55_idx55): 'What is the last transcript release date?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2765bec85c3142d3a2f50dbce4113061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q55_idx55:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 56 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 57/100 (ID: spider_dev_q56_idx56): 'What are the names of the teachers ordered by ascending age?' (True DB: course_teach)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce40609f7ba14e6fa93273c3f564716e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q56_idx56:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 57 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 58/100 (ID: spider_dev_q57_idx57): 'Show the date and id of the transcript with at least 2 course results.' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596b39908f6c456e84ea6be954b63d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q57_idx57:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 58 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 59/100 (ID: spider_dev_q58_idx58): 'What are the names of conductors whose nationalities are not \"USA\"?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7f38c00cc34e1bb4859a8ab746473a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q58_idx58:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 59 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 60/100 (ID: spider_dev_q59_idx59): 'What are the names of students who have no friends?' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f7cb4c45ab4c01b07fdef52c160233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q59_idx59:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 60 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 61/100 (ID: spider_dev_q60_idx60): 'What is the count of the car models produced in the United States?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10d9d9ab9de4434a135873f2288d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q60_idx60:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 61 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 62/100 (ID: spider_dev_q61_idx61): 'What are the names of countries that speak more than 2 languages, as well as how many languages they speak?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d441d8f089a41d790427779b38f09b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q61_idx61:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 62 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 63/100 (ID: spider_dev_q62_idx62): 'Give the name, population, and head of state for the country that has the largest area.' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5499d03a2e4fe9a9f9b46de0705338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q62_idx62:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 63 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 64/100 (ID: spider_dev_q63_idx63): 'How many different results are there for the battles?' (True DB: battle_death)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ded8bb53ea4e2782e6f9e642cc64a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q63_idx63:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 64 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 65/100 (ID: spider_dev_q64_idx64): 'What are the names of the countries with no car makers?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9679b24295f044a6813f6253646f5099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q64_idx64:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 65 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 66/100 (ID: spider_dev_q65_idx65): 'What is the language that is used by the largest number of Asian nations?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6724118c49452891180e0de0abb125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q65_idx65:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 66 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 67/100 (ID: spider_dev_q66_idx66): 'Return the record companies of orchestras, sorted descending by the years in which they were founded.' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdda2d907be418f82078de9dd05a9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q66_idx66:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 67 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 68/100 (ID: spider_dev_q67_idx67): 'What are the names of properties that are either houses or apartments with more than 1 room?' (True DB: real_estate_properties)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbc4e61b9da4257a66531155eea6b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q67_idx67:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 68 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 69/100 (ID: spider_dev_q68_idx68): 'find the package option of the tv channel that do not have any cartoon directed by Ben Jones.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bc9ee335b54ff4a8c2836046d22241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q68_idx68:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 69 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 70/100 (ID: spider_dev_q69_idx69): 'List the last name of the owner owning the youngest dog.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06349beca4184107a06db7372e01828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q69_idx69:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 70 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 71/100 (ID: spider_dev_q70_idx70): 'What is the name and capacity of the stadium with the most concerts after 2013 ?' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000a423725e4469895eaec5618f23d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q70_idx70:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 71 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 72/100 (ID: spider_dev_q71_idx71): 'What are the names of conductors who have conducted orchestras founded after the year 2008?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcebc7f5fa84e2fb9bb3547f434344d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q71_idx71:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 72 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 73/100 (ID: spider_dev_q72_idx72): 'How many cars has over 6 cylinders?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af146244d544716900bcc107a615070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q72_idx72:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 73 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 74/100 (ID: spider_dev_q73_idx73): 'What is the number of car models that are produced by each maker and what is the id and full name of each maker?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baebf9797cd14e2b8f21d70751a6db3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q73_idx73:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 74 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 75/100 (ID: spider_dev_q74_idx74): 'What are the names of conductors, sorted descending by the number of years they have worked?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d474460f1a7a49c095dd7397ba6a01ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q74_idx74:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 75 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 76/100 (ID: spider_dev_q75_idx75): 'What are the distinct template type descriptions for the templates ever used by any document?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c616c54c22b04a6d8edbd54e33a2030c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q75_idx75:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 76 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 77/100 (ID: spider_dev_q76_idx76): 'What are the names of poker players, ordered ascending by the number of final tables they have made?' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edd4dc574eb49af86a7cb065bc0f92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q76_idx76:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 77 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 78/100 (ID: spider_dev_q77_idx77): 'What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562611d4d5174057b2599f1e06accdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q77_idx77:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 78 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 79/100 (ID: spider_dev_q78_idx78): 'What is the TV Channel of TV series with Episode \"A Love of a Lifetime\"? List the TV Channel's series name.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180e59379f594c75b4bd98b8f68d1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q78_idx78:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 79 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 80/100 (ID: spider_dev_q79_idx79): 'What is the lowest grade of students who do not have any friends?' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec6d0c4593b4570915e93d7e91ae3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q79_idx79:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 80 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 81/100 (ID: spider_dev_q80_idx80): 'Show the name and theme for all concerts and the number of singers in each concert.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4a384b9cac4556b80aa1b2124817ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q80_idx80:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 81 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 82/100 (ID: spider_dev_q81_idx81): 'What is the total ticket expense of the visitors whose membership level is 1?' (True DB: museum_visit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1753fd89cfdf4a12b6be7dd9ccea71c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q81_idx81:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 82 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 83/100 (ID: spider_dev_q82_idx82): 'Which professionals have done at least two types of treatments? List the professional id and cell phone.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767e441aa6d44ce8b70e4e5da2136eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q82_idx82:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 83 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 84/100 (ID: spider_dev_q83_idx83): 'How many countries does each continent have? List the continent id, continent name and the number of countries.' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bff424ff1aa468c960c64a99e4e0877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q83_idx83:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 84 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 85/100 (ID: spider_dev_q84_idx84): 'What is the average, minimum, and maximum age for all French singers?' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4fc87ef0984bef839c1b085a47fd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q84_idx84:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 85 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 86/100 (ID: spider_dev_q85_idx85): 'What is the car model with the highest mpg ?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc289a5f8f274558b0afa8b416b1461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q85_idx85:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 86 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 87/100 (ID: spider_dev_q86_idx86): 'How many flights do we have?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9fbc1d99384194aeebb9d5e2ee3ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q86_idx86:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 87 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 88/100 (ID: spider_dev_q87_idx87): 'What is the series name of the TV Channel that shows the cartoon \"The Rise of the Blue Beetle\"?' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868e902b17944bb289429ee8438da4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q87_idx87:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 88 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 89/100 (ID: spider_dev_q88_idx88): 'What is the name of the conductor who has conducted the most orchestras?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01ec14d4bea4aaaa890a58a3d050556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q88_idx88:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 89 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 90/100 (ID: spider_dev_q89_idx89): 'How many battles did not lose any ship with tonnage '225'?' (True DB: battle_death)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a7eddb7fea414ba218885fc187f4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q89_idx89:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 90 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 91/100 (ID: spider_dev_q90_idx90): 'Of all the contestants who got voted, what is the contestant number and name of the contestant who got least votes?' (True DB: voter_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0a874ddcb44029b43a07962675ae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q90_idx90:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 91 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 92/100 (ID: spider_dev_q91_idx91): 'What are the regions that use English or Dutch?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f753896702cf404286762f97e38a0f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q91_idx91:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 92 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 93/100 (ID: spider_dev_q92_idx92): 'Find the average number of staff working for the museums that were open before 2009.' (True DB: museum_visit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bb1ae1583f4cfc89271ea01af41dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q92_idx92:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 93 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 94/100 (ID: spider_dev_q93_idx93): 'Find the total number of players.' (True DB: wta_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b94ca3e7c1541358cd6ba018b12d7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q93_idx93:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 94 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 95/100 (ID: spider_dev_q94_idx94): 'Sort all the shops by number products in descending order, and return the name, location and district of each shop.' (True DB: employee_hire_evaluation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f0cd39eb9b4e7197ca67e31cd22acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q94_idx94:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 95 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 96/100 (ID: spider_dev_q95_idx95): 'Describe the section h.' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c4c5c8a54d4a0a8fc3ab202da9044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q95_idx95:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 96 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 97/100 (ID: spider_dev_q96_idx96): 'Count the number of paragraphs.' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5356bcaad543bfa9204879778d8b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q96_idx96:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 97 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 98/100 (ID: spider_dev_q97_idx97): 'Find the number of pets whose weight is heavier than 10.' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a63eadf3a8c4e4f9caa8aa7eb5ac64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q97_idx97:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 98 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 99/100 (ID: spider_dev_q98_idx98): 'What are the record companies that are used by both orchestras founded before 2003 and those founded after 2003?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72ea728909b40719f267095060ee68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q98_idx98:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 99 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 100/100 (ID: spider_dev_q99_idx99): 'What are the ids and makers of all car makers that produce at least 2 models and make more than 3 cars?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccb1fa14eff45269db32e4e7e331e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q99_idx99:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 100 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "--- Experiment Loop Finished ---\n",
      "Processed 100 queries in total.\n",
      "Final results comprehensively saved to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure these imports are at the top of your script/notebook ---\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "from tqdm.auto import tqdm # Use .auto or .notebook for Jupyter\n",
    "\n",
    "# --- Prerequisites (must be defined and populated from Cell 1 and Cell 2): ---\n",
    "# model, tokenizer, SYSTEM_PROMPT, USER_PROMPT_TEMPLATE,\n",
    "# YES_TOKEN_ID, NO_TOKEN_ID, get_yes_probability,\n",
    "# selected_nl_queries, candidate_schemas_for_evaluation, EXPERIMENT_RESULTS_FILE\n",
    "# --- (Assume these are correctly defined above this cell) ---\n",
    "\n",
    "# --- 3.1. Initialize Results Storage ---\n",
    "experiment_all_query_results = []\n",
    "\n",
    "# --- 3.2. Start the Loop ---\n",
    "# This initial print is fine as it's before any tqdm loops start for this cell's main logic\n",
    "print(f\"\\n--- Starting Experiment: {len(selected_nl_queries)} Random Queries vs. {len(candidate_schemas_for_evaluation)} Total DB Schemas ---\")\n",
    "\n",
    "# Outer loop: Iterate through each randomly selected NL query\n",
    "for query_idx, nl_query_info in enumerate(tqdm(selected_nl_queries, desc=\"Processing NL Queries\")):\n",
    "    current_nl_query_text = nl_query_info['question']\n",
    "    true_db_id_for_query = nl_query_info['db_id']\n",
    "    experiment_query_id = f\"spider_dev_q{query_idx}_{nl_query_info.get('query_id', 'idx'+str(query_idx))}\"\n",
    "\n",
    "    # Use tqdm.write for status updates related to the outer loop's progress\n",
    "    # The '\\n' at the beginning helps separate entries for each query visually.\n",
    "    tqdm.write(f\"\\nProcessing Query {query_idx + 1}/{len(selected_nl_queries)} (ID: {experiment_query_id}): '{current_nl_query_text}' (True DB: {true_db_id_for_query})\")\n",
    "\n",
    "    scores_for_current_query = []\n",
    "\n",
    "    # --- Optional: For debugging, print scores for the VERY FIRST query only ---\n",
    "    # print_debug_scores_for_first_query_only = True\n",
    "    # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "    #     tqdm.write(f\"  --- Incremental Scores for First Query: '{current_nl_query_text}' ---\")\n",
    "    # --- End Optional Debug Print Setup ---\n",
    "\n",
    "    # Inner loop: Iterate through each candidate database schema\n",
    "    for candidate_db_id, candidate_schema_sql in tqdm(\n",
    "        candidate_schemas_for_evaluation.items(),\n",
    "        desc=f\"  DBs for Q:{experiment_query_id[:20]}\", # Description for the inner bar\n",
    "        leave=False  # Inner bar will be removed upon completion of its loop\n",
    "    ):\n",
    "        user_prompt_content = USER_PROMPT_TEMPLATE.format(\n",
    "            schema_string=candidate_schema_sql,\n",
    "            nl_query=current_nl_query_text\n",
    "        )\n",
    "        p_yes_score = -1.0\n",
    "\n",
    "        try:\n",
    "            p_yes_score = get_yes_probability(\n",
    "                model, tokenizer, SYSTEM_PROMPT, user_prompt_content, YES_TOKEN_ID, NO_TOKEN_ID\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Use tqdm.write for error messages occurring inside the inner loop\n",
    "            tqdm.write(f\"    ERROR: Exception in get_yes_probability for Query ID '{experiment_query_id}' with DB '{candidate_db_id}'.\")\n",
    "            tqdm.write(f\"    Exception type: {type(e).__name__}, Message: {e}\")\n",
    "            # if you need full traceback for debugging, tqdm.write(traceback.format_exc()) might work,\n",
    "            # but it can be very verbose. Printing to a log file is better for extensive tracebacks.\n",
    "            # traceback.print_exc() # This will print to stderr and might still mess with tqdm display\n",
    "\n",
    "        scores_for_current_query.append({\n",
    "            'candidate_db_id': candidate_db_id,\n",
    "            'p_yes_score': p_yes_score\n",
    "        })\n",
    "\n",
    "        # --- Optional: For debugging, print scores for the VERY FIRST query only ---\n",
    "        # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "        #     tqdm.write(f\"    DB: {candidate_db_id}, Score: {p_yes_score:.4f}\") # Incremental print with tqdm.write\n",
    "        # --- End Optional Debug Print ---\n",
    "\n",
    "    ranked_databases_for_query = sorted(scores_for_current_query, key=lambda x: x['p_yes_score'], reverse=True)\n",
    "\n",
    "    # --- Optional: For debugging, print sorted scores for the VERY FIRST query only ---\n",
    "    # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "    #     tqdm.write(f\"  --- Sorted Ranked Databases for First Query: '{current_nl_query_text}' (Top 10) ---\")\n",
    "    #     for rank_info in ranked_databases_for_query[:10]:\n",
    "    #         tqdm.write(f\"    Ranked DB: {rank_info['candidate_db_id']}, Score: {rank_info['p_yes_score']:.4f}\")\n",
    "    # --- End Optional Debug Print ---\n",
    "\n",
    "    experiment_all_query_results.append({\n",
    "        'experiment_query_id': experiment_query_id,\n",
    "        'nl_query_text': current_nl_query_text,\n",
    "        'true_db_id': true_db_id_for_query,\n",
    "        'ranked_databases_with_scores': ranked_databases_for_query\n",
    "    })\n",
    "\n",
    "    # --- 3.3. Periodic Saving of Results ---\n",
    "    if (query_idx + 1) % 1 == 0 or (query_idx + 1) == len(selected_nl_queries):\n",
    "        try:\n",
    "            with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "                json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "            # Use tqdm.write for save messages that occur between outer loop iterations\n",
    "            tqdm.write(f\"  Successfully saved intermediate results for {len(experiment_all_query_results)} queries to {EXPERIMENT_RESULTS_FILE}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ERROR: Could not save intermediate results: {e}\")\n",
    "\n",
    "# --- 3.4. Experiment Loop Completion ---\n",
    "# These final prints are after all tqdm loops are done, so standard print is fine.\n",
    "print(\"\\n--- Experiment Loop Finished ---\")\n",
    "if experiment_all_query_results:\n",
    "    print(f\"Processed {len(experiment_all_query_results)} queries in total.\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "            json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "        print(f\"Final results comprehensively saved to {EXPERIMENT_RESULTS_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save final results: {e}\")\n",
    "else:\n",
    "    print(\"No results were generated from the experiment. Check logs for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed3a14-354d-4762-a702-1fce12986b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path where the evaluation summary (Recall@K results) will be saved\n",
    "EVAL_RESULTS_SAVE_PATH = \"recall_k_results.json\"\n",
    "\n",
    "# --- 4.1. Define Recall@K Calculation Function ---\n",
    "def calculate_recall_at_k_metric(all_query_results_list, k_values_list):\n",
    "    \"\"\"\n",
    "    Calculates Recall@K for a list of K values.\n",
    "    Each item in all_query_results_list should be a dictionary with:\n",
    "        'true_db_id': The ground truth database ID for the query.\n",
    "        'ranked_databases_with_scores': A list of {'candidate_db_id': id, 'p_yes_score': score},\n",
    "                                         sorted by score in descending order.\n",
    "    \"\"\"\n",
    "    recall_counts = {k: 0 for k in k_values_list}  # Stores how many times true_db was in top K\n",
    "    total_valid_queries = 0  # Queries for which we have a true_db_id\n",
    "\n",
    "    if not all_query_results_list:\n",
    "        return {k: 0.0 for k in k_values_list}, 0\n",
    "\n",
    "    for query_result in all_query_results_list:\n",
    "        true_db = query_result.get('true_db_id')\n",
    "        ranked_dbs_info = query_result.get('ranked_databases_with_scores')\n",
    "\n",
    "        if true_db is None or ranked_dbs_info is None:\n",
    "            print(f\"Warning: Skipping query result due to missing 'true_db_id' or 'ranked_databases_with_scores': \"\n",
    "                  f\"{query_result.get('experiment_query_id', 'Unknown Query')}\")\n",
    "            continue  # Skip if essential information is missing\n",
    "\n",
    "        total_valid_queries += 1\n",
    "        # Extract just the DB IDs from the ranked list\n",
    "        ranked_db_ids_only = [item['candidate_db_id'] for item in ranked_dbs_info]\n",
    "\n",
    "        for k in k_values_list:\n",
    "            # Get the top K predicted database IDs\n",
    "            top_k_predicted_dbs = ranked_db_ids_only[:k]\n",
    "            if true_db in top_k_predicted_dbs:\n",
    "                recall_counts[k] += 1\n",
    "\n",
    "    # Calculate final recall percentages\n",
    "    recall_percentages = {}\n",
    "    if total_valid_queries > 0:\n",
    "        for k in k_values_list:\n",
    "            recall_percentages[k] = (recall_counts[k] / total_valid_queries) * 100.0  # As percentage\n",
    "    else:\n",
    "        recall_percentages = {k: 0.0 for k in k_values_list}\n",
    "\n",
    "    return recall_percentages, total_valid_queries\n",
    "\n",
    "\n",
    "# --- 4.2. Perform Evaluation ---\n",
    "# Load results if this cell is run in a new session and experiment_all_query_results isn't in memory\n",
    "# (assuming results were saved to EXPERIMENT_RESULTS_FILE)\n",
    "loaded_results_for_eval = None\n",
    "if 'experiment_all_query_results' in globals() and experiment_all_query_results:\n",
    "    print(\"Using in-memory experiment_all_query_results for evaluation.\")\n",
    "    loaded_results_for_eval = experiment_all_query_results\n",
    "elif os.path.exists(EXPERIMENT_RESULTS_FILE):\n",
    "    print(f\"Loading results from {EXPERIMENT_RESULTS_FILE} for evaluation...\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'r') as f_in:\n",
    "            loaded_results_for_eval = json.load(f_in)\n",
    "        print(f\"Successfully loaded {len(loaded_results_for_eval)} results from file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results from file for evaluation: {e}\")\n",
    "else:\n",
    "    print(\"No results available in memory or in the specified results file for evaluation.\")\n",
    "\n",
    "if loaded_results_for_eval:\n",
    "    K_VALUES_TO_EVALUATE = [1, 3, 5, 10]  # Define the K values you care about\n",
    "    recall_scores_map, num_queries_evaluated = calculate_recall_at_k_metric(\n",
    "        loaded_results_for_eval, K_VALUES_TO_EVALUATE\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Evaluation: Recall@K ---\")\n",
    "    print(f\"Evaluated on {num_queries_evaluated} queries.\")\n",
    "    for k_val, recall_val in recall_scores_map.items():\n",
    "        print(f\"Recall@{k_val}: {recall_val:.2f}%\")\n",
    "\n",
    "    # --- 4.2.1. Save evaluation results to a JSON file ---\n",
    "    try:\n",
    "        eval_summary = {\n",
    "            \"num_queries_evaluated\": num_queries_evaluated,\n",
    "            \"recall_scores\": recall_scores_map\n",
    "        }\n",
    "        with open(EVAL_RESULTS_SAVE_PATH, 'w') as fout:\n",
    "            json.dump(eval_summary, fout, indent=2)\n",
    "        print(f\"Saved evaluation results to '{EVAL_RESULTS_SAVE_PATH}'\")\n",
    "    except Exception as save_err:\n",
    "        print(f\"Error saving evaluation results: {save_err}\")\n",
    "\n",
    "    # --- 4.3. Optional: Print Detailed Results for a Few Queries ---\n",
    "    print(\"\\n--- Sample Detailed Query Results (Top 5 Queries) ---\")\n",
    "    for i, res in enumerate(loaded_results_for_eval[:5]):  # Show for first 5 queries\n",
    "        print(f\"\\nQuery {i+1}: '{res.get('nl_query_text', '<no text>')}' (True DB: {res.get('true_db_id')})\")\n",
    "        print(\"  Top Ranked Databases (with P(Yes) scores):\")\n",
    "        for rank, db_info in enumerate(res.get('ranked_databases_with_scores', [])[:5]):  # Show top 5 ranked DBs\n",
    "            is_true_db_char = \"*\" if db_info['candidate_db_id'] == res['true_db_id'] else \" \"\n",
    "            print(f\"    {rank+1}. {db_info['candidate_db_id']}{is_true_db_char} \"\n",
    "                  f\"(Score: {db_info['p_yes_score']:.4f})\")\n",
    "else:\n",
    "    print(\"Cannot perform evaluation as no results were loaded or generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_spider_env)",
   "language": "python",
   "name": "llama_spider_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
