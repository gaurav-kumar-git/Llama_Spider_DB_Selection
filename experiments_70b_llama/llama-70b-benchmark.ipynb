{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c999f2fd-56f0-4ae9-949c-4803f663a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: accelerate in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: bitsandbytes in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: sentencepiece in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: datasets in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: huggingface_hub in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.32.3)\n",
      "Requirement already satisfied: tqdm in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: psutil in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: sympy in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: six>=1.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate bitsandbytes sentencepiece pandas datasets huggingface_hub tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc106017-bfb9-40d0-8409-ff72140b945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets version: 8.1.5\n",
      "ipywidgets location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/ipywidgets/__init__.py\n",
      "tqdm version: 4.67.1\n",
      "tqdm location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/tqdm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "  import ipywidgets\n",
    "  print(f\"ipywidgets version: {ipywidgets.__version__}\")\n",
    "  print(f\"ipywidgets location: {ipywidgets.__file__}\")\n",
    "\n",
    "  import tqdm\n",
    "  print(f\"tqdm version: {tqdm.__version__}\")\n",
    "  print(f\"tqdm location: {tqdm.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48f920e-9675-4ae6-ac4a-e221b3e0175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm imported successfully from .auto\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93037c0fdac24c61930de69d7612ea8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minimal Auto Test:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple tqdm .auto loop completed\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(\"tqdm imported successfully from .auto\")\n",
    "my_list = list(range(3))\n",
    "for i in tqdm(my_list, desc=\"Minimal Auto Test\"):\n",
    "    time.sleep(0.2)\n",
    "print(\"Simple tqdm .auto loop completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51bd609-5bef-4bae-9977-8909136a2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8aed063-c3c2-49b9-ba1c-3ec07ec68adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0\n",
      "CUDA available: True\n",
      "CUDA version PyTorch compiled with: 11.8\n",
      "Number of GPUs available to PyTorch: 8\n",
      "  GPU 0: NVIDIA A100-SXM4-80GB\n",
      "  GPU 1: NVIDIA A100-SXM4-80GB\n",
      "  GPU 2: NVIDIA A100-SXM4-80GB\n",
      "  GPU 3: NVIDIA A100-SXM4-80GB\n",
      "  GPU 4: NVIDIA A100-SXM4-80GB\n",
      "  GPU 5: NVIDIA A100-SXM4-80GB\n",
      "  GPU 6: NVIDIA A100-SXM4-80GB\n",
      "  GPU 7: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch compiled with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs available to PyTorch: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"ERROR: PyTorch cannot see the GPUs! Check installation and CUDA compatibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba6d845-eeb6-4dc3-8936-00a0686991c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac563a7e-b468-4b6e-9b89-ea76a46e229b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7821cc80302f49d183f15a7ff38c5342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful or already authenticated.\n",
      "\n",
      "--- Cell 2: Hugging Face Login Attempt Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Hugging Face Hub Authentication ---\n",
    "# You MUST have requested access to Llama 2 models via Meta's form on Hugging Face\n",
    "# AND have your request approved.\n",
    "\n",
    "# Option 1: If you've stored your token as an environment variable on the server\n",
    "# HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "# if HF_TOKEN:\n",
    "#     print(\"Logging into Hugging Face Hub using token from environment variable...\")\n",
    "#     login(token=HF_TOKEN)\n",
    "# else:\n",
    "#     print(\"HF_TOKEN environment variable not set. Attempting widget login if in interactive environment, or manual CLI login might be needed.\")\n",
    "#     login() # Will prompt if in an environment that supports it\n",
    "\n",
    "# Option 2: Paste token directly (less secure, use with caution)\n",
    "# HF_TOKEN = \"YOUR_HF_READ_TOKEN_HERE\"\n",
    "# login(token=HF_TOKEN)\n",
    "\n",
    "# Option 3: Use huggingface-cli login in a server terminal beforehand (Recommended)\n",
    "# If already logged in via CLI, this cell might not be strictly necessary,\n",
    "# but running login() can confirm status or refresh credentials.\n",
    "try:\n",
    "    login() # Will use cached token or prompt if needed\n",
    "    print(\"Hugging Face login successful or already authenticated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Hugging Face login failed: {e}. Ensure you are authenticated to download Llama 2.\")\n",
    "\n",
    "print(\"\\n--- Cell 2: Hugging Face Login Attempt Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339f0694-4129-4a0a-9bec-150838594c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Model: meta-llama/Llama-2-70b-chat-hf\n",
      "BitsAndBytesConfig: load_in_4bit=True, compute_dtype=torch.bfloat16\n",
      "System and User prompt templates defined.\n",
      "Hugging Face model cache directory set to: /raid/infolab/gaurav/Llama_Spider_A100_Project/experiments_70b_llama/.hf_model_cache_70b\n",
      "\n",
      "--- Cell 3: Model and Prompt Configuration Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Model and Tokenizer Configuration ---\n",
    "import os\n",
    "\n",
    "# 3.1. Specify the Llama 2 70B Chat Model\n",
    "MODEL_NAME = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "print(f\"Target Model: {MODEL_NAME}\")\n",
    "\n",
    "# 3.2. Configure 4-bit Quantization (essential for 70B, even on A100s for single/few GPU use)\n",
    "# A100s support bfloat16, which is excellent for mixed-precision.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",        # nf4 is a good default\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Use bfloat16 for computation on A100s\n",
    "    bnb_4bit_use_double_quant=True,   # Can save a bit more memory\n",
    ")\n",
    "print(f\"BitsAndBytesConfig: load_in_4bit={bnb_config.load_in_4bit}, compute_dtype={bnb_config.bnb_4bit_compute_dtype}\")\n",
    "\n",
    "# 3.3. Define Prompt Templates\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert data analyst. Your task is to determine if a given natural language query \"\n",
    "    \"can be answered *solely* based on the provided database schema. \"\n",
    "    \"Do not attempt to answer the query itself. Your entire response must be only the word 'Yes' or the word 'No'.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Database Schema:\n",
    "---\n",
    "{schema_string}\n",
    "---\n",
    "Natural Language Query: \"{nl_query}\"\n",
    "---\n",
    "Can the query be answered using *only* the provided schema and its potential contents? Answer with either \"Yes\" or \"No\".\n",
    "\"\"\"\n",
    "print(\"System and User prompt templates defined.\")\n",
    "\n",
    "# 3.4. Define Cache Directory for Hugging Face downloads (optional, but good for managing large models)\n",
    "# Create it within your project directory on the A100 server.\n",
    "HF_MODEL_CACHE_DIR = os.path.join(os.getcwd(), \".hf_model_cache_70b\") # Assumes current dir is project root\n",
    "os.makedirs(HF_MODEL_CACHE_DIR, exist_ok=True)\n",
    "print(f\"Hugging Face model cache directory set to: {HF_MODEL_CACHE_DIR}\")\n",
    "\n",
    "print(\"\\n--- Cell 3: Model and Prompt Configuration Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd45122-14da-4134-8b16-2732bbe33a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for meta-llama/Llama-2-70b-chat-hf...\n",
      "Set tokenizer.pad_token to tokenizer.eos_token ('</s>')\n",
      "Tokenizer loaded successfully.\n",
      "Found single token for 'Yes': ID 3869\n",
      "Found single token for 'No': ID 1939\n",
      "GLOBAL YES_TOKEN_ID: 3869 ('Yes')\n",
      "GLOBAL NO_TOKEN_ID: 1939 ('No')\n",
      "\n",
      "--- Cell 4: Tokenizer Loading and Yes/No Token ID Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Load Tokenizer and Define Yes/No Token Logic ---\n",
    "\n",
    "# 4.1. Load Tokenizer\n",
    "print(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=HF_MODEL_CACHE_DIR)\n",
    "    # Set pad token if not already set (Llama tokenizers often don't have one)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        print(f\"Set tokenizer.pad_token to tokenizer.eos_token ('{tokenizer.eos_token}')\")\n",
    "    print(\"Tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load tokenizer for {MODEL_NAME}: {e}\")\n",
    "\n",
    "\n",
    "# 4.2. Define Helper Function to get Yes/No Token IDs\n",
    "def get_yes_no_token_ids(tokenizer_arg):\n",
    "    \"\"\"Determines token IDs for 'Yes'/'No', preferring those with a leading space.\"\"\"\n",
    "    # Try with leading space first for chat models\n",
    "    yes_variants = [\" Yes\", \"Yes\"]\n",
    "    no_variants = [\" No\", \"No\"]\n",
    "    \n",
    "    final_yes_id = None\n",
    "    final_no_id = None\n",
    "\n",
    "    for variant in yes_variants:\n",
    "        token_ids = tokenizer_arg.encode(variant, add_special_tokens=False)\n",
    "        if len(token_ids) == 1:\n",
    "            final_yes_id = token_ids[0]\n",
    "            print(f\"Found single token for '{variant}': ID {final_yes_id}\")\n",
    "            break\n",
    "            \n",
    "    for variant in no_variants:\n",
    "        token_ids = tokenizer_arg.encode(variant, add_special_tokens=False)\n",
    "        if len(token_ids) == 1:\n",
    "            final_no_id = token_ids[0]\n",
    "            print(f\"Found single token for '{variant}': ID {final_no_id}\")\n",
    "            break\n",
    "\n",
    "    if final_yes_id is None or final_no_id is None:\n",
    "        print(f\"ERROR: Could not determine reliable single token IDs for 'Yes'/'No' or variants.\")\n",
    "        # You might want to print detailed tokenization attempts here if this error occurs\n",
    "        raise ValueError(\"Unstable tokenization for 'Yes'/'No'. Cannot proceed.\")\n",
    "    \n",
    "    return final_yes_id, final_no_id\n",
    "\n",
    "# 4.3. Define Global YES_TOKEN_ID and NO_TOKEN_ID\n",
    "try:\n",
    "    YES_TOKEN_ID, NO_TOKEN_ID = get_yes_no_token_ids(tokenizer)\n",
    "    print(f\"GLOBAL YES_TOKEN_ID: {YES_TOKEN_ID} ('{tokenizer.decode([YES_TOKEN_ID]).strip()}')\")\n",
    "    print(f\"GLOBAL NO_TOKEN_ID: {NO_TOKEN_ID} ('{tokenizer.decode([NO_TOKEN_ID]).strip()}')\")\n",
    "except ValueError as e:\n",
    "    raise RuntimeError(f\"Failed to set YES/NO token IDs: {e}\")\n",
    "\n",
    "print(\"\\n--- Cell 4: Tokenizer Loading and Yes/No Token ID Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546dc473-9b23-4b0d-aff2-a1064c893deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: meta-llama/Llama-2-70b-chat-hf with 4-bit quantization. This will take significant time and memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2022dca3ac46f9988096501e2dc2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully!\n",
      "Time taken to load model: 46.84 seconds.\n",
      "Model device map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 2, 'model.layers.25': 2, 'model.layers.26': 2, 'model.layers.27': 2, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.layers.32': 3, 'model.layers.33': 3, 'model.layers.34': 3, 'model.layers.35': 3, 'model.layers.36': 3, 'model.layers.37': 3, 'model.layers.38': 4, 'model.layers.39': 4, 'model.layers.40': 4, 'model.layers.41': 4, 'model.layers.42': 4, 'model.layers.43': 4, 'model.layers.44': 4, 'model.layers.45': 4, 'model.layers.46': 4, 'model.layers.47': 4, 'model.layers.48': 5, 'model.layers.49': 5, 'model.layers.50': 5, 'model.layers.51': 5, 'model.layers.52': 5, 'model.layers.53': 5, 'model.layers.54': 5, 'model.layers.55': 5, 'model.layers.56': 5, 'model.layers.57': 5, 'model.layers.58': 6, 'model.layers.59': 6, 'model.layers.60': 6, 'model.layers.61': 6, 'model.layers.62': 6, 'model.layers.63': 6, 'model.layers.64': 6, 'model.layers.65': 6, 'model.layers.66': 6, 'model.layers.67': 6, 'model.layers.68': 7, 'model.layers.69': 7, 'model.layers.70': 7, 'model.layers.71': 7, 'model.layers.72': 7, 'model.layers.73': 7, 'model.layers.74': 7, 'model.layers.75': 7, 'model.layers.76': 7, 'model.layers.77': 7, 'model.layers.78': 7, 'model.layers.79': 7, 'model.norm': 7, 'model.rotary_emb': 7, 'lm_head': 7}\n",
      "Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\n",
      "\n",
      "--- Cell 5: Llama 2 70B Model Loading Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Llama 2 70B Model ---\n",
    "# This is a memory-intensive step. `device_map=\"auto\"` will attempt to distribute\n",
    "# the model across available GPUs if one is insufficient.\n",
    "# Ensure CUDA_VISIBLE_DEVICES is set in your shell if you want to restrict which GPUs are used.\n",
    "import gc\n",
    "print(f\"Loading model: {MODEL_NAME} with 4-bit quantization. This will take significant time and memory...\")\n",
    "model_load_start_time = time.time()\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,    # Apply 4-bit quantization\n",
    "        torch_dtype=torch.bfloat16,        # Use bfloat16 on A100s\n",
    "        device_map=\"auto\",                 # Distribute model across available GPUs automatically\n",
    "        trust_remote_code=True,            # Often needed for newer models\n",
    "        cache_dir=HF_MODEL_CACHE_DIR\n",
    "    )\n",
    "    model_load_end_time = time.time()\n",
    "    print(\"\\nModel loaded successfully!\")\n",
    "    print(f\"Time taken to load model: {model_load_end_time - model_load_start_time:.2f} seconds.\")\n",
    "    print(f\"Model device map: {model.hf_device_map}\") # Shows how layers are distributed\n",
    "    # For a 70B model, this should show parts on different GPUs if more than one is used.\n",
    "    \n",
    "    # Perform a quick memory cleanup after loading large model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise RuntimeError(f\"Failed to load model {MODEL_NAME}: {e}. Check VRAM, CUDA setup, and Hugging Face authentication.\")\n",
    "\n",
    "print(\"\\n--- Cell 5: Llama 2 70B Model Loading Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2688f1be-afae-4ce5-8991-2686bbfac0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m new_max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m  \u001b[38;5;66;03m# Let's try allowing up to 256 new tokens\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43minputs\u001b[49m,\n\u001b[1;32m      9\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39mnew_max_tokens, \u001b[38;5;66;03m# MODIFIED\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     12\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m     13\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;66;03m# Important for some models when batching or using attention_mask\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m response_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m assistant_response_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# --- MODIFIED PART ---\n",
    "# Increase max_new_tokens to allow for longer output\n",
    "# You can adjust this value. The model will also stop if it generates an EOS token.\n",
    "new_max_tokens = 256  # Let's try allowing up to 256 new tokens\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=new_max_tokens, # MODIFIED\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id # Important for some models when batching or using attention_mask\n",
    "    )\n",
    "\n",
    "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "assistant_response_start = -1\n",
    "# Try to find the common end-of-instruction marker for chat models\n",
    "# For Llama-2 style:\n",
    "if \" [/INST] \" in response_text:\n",
    "    assistant_response_start = response_text.rfind(\" [/INST] \") + len(\" [/INST] \")\n",
    "# For other potential chatML-like structures:\n",
    "elif \"<|assistant|>\\n\" in response_text: # Anthropic/Claude style or similar\n",
    "    assistant_response_start = response_text.rfind(\"<|assistant|>\\n\") + len(\"<|assistant|>\\n\")\n",
    "elif \"<|im_start|>assistant\\n\" in response_text: # Newer ChatML\n",
    "    assistant_response_start = response_text.rfind(\"<|im_start|>assistant\\n\") + len(\"<|im_start|>assistant\\n\")\n",
    "\n",
    "\n",
    "if assistant_response_start != -1:\n",
    "    clean_response = response_text[assistant_response_start:].strip()\n",
    "else:\n",
    "    # Fallback: if the prompt was simple and no clear marker,\n",
    "    # try to remove the original prompt from the start of the response text.\n",
    "    # This is less robust.\n",
    "    formatted_prompt_without_generation_cue = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    if response_text.startswith(formatted_prompt_without_generation_cue):\n",
    "        clean_response = response_text[len(formatted_prompt_without_generation_cue):].strip()\n",
    "    else:\n",
    "        # Last resort: very basic split if we can't find a good marker.\n",
    "        # This assumes the model *only* added new text.\n",
    "        prompt_tokens_count = inputs.input_ids.shape[1]\n",
    "        generated_tokens = outputs[0][prompt_tokens_count:]\n",
    "        clean_response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        if not clean_response: # If the above still fails, show the raw output\n",
    "             clean_response = \"Could not reliably clean the prompt. Raw output (minus special tokens):\\n\" + response_text\n",
    "\n",
    "\n",
    "print(f\"\\nModel Response (cleaned, potentially longer): {clean_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fae66bb-f328-4814-9e23-cbc376eca2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started. Looking for zip file at: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip\n",
      "Zip file found at /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip.\n",
      "Attempting to unzip /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip to /raid/infolab/gaurav/Llama_Spider_A100_Project/...\n",
      "Successfully unzipped files to /raid/infolab/gaurav/Llama_Spider_A100_Project/\n",
      "Contents of /raid/infolab/gaurav/Llama_Spider_A100_Project/:\n",
      "  - experiments_70b_llama\n",
      "  - .gitignore\n",
      "  - backup_to_github.sh\n",
      "  - Miniconda3-latest-Linux-x86_64.sh\n",
      "  - spider_subset_data.zip\n",
      "  - randomQ_allDBs_run1\n",
      "  - .ipynb_checkpoints\n",
      "  - .git\n",
      "  - miniconda3\n",
      "  - 100_queries.txt\n",
      "  - spider_subset_data\n",
      "  - __MACOSX\n",
      "\n",
      "Verifying extracted file paths...\n",
      "SUCCESS: dev.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "SUCCESS: tables.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n",
      "\n",
      "--- Ready to load data ---\n",
      "Path to dev.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "Path to tables.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "SERVER_ZIP_FILE_PATH = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip'\n",
    "EXTRACTION_DESTINATION_DIR_ON_SERVER = '/raid/infolab/gaurav/Llama_Spider_A100_Project/'\n",
    "\n",
    "DEV_JSON_PATH = None\n",
    "TABLES_JSON_PATH = None\n",
    "\n",
    "def unzip_data(zip_filepath, dest_dir):\n",
    "    \"\"\"\n",
    "    Unzips a zip file to a specified destination directory.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to unzip {zip_filepath} to {dest_dir}...\")\n",
    "    try:\n",
    "        \n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "        print(f\"Successfully unzipped files to {dest_dir}\")\n",
    "\n",
    "        print(f\"Contents of {dest_dir}:\")\n",
    "        for item in os.listdir(dest_dir):\n",
    "            print(f\"  - {item}\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: {zip_filepath} is not a valid zip file or is corrupted.\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Zip file not found at {zip_filepath}. Please ensure the path is correct.\")\n",
    "        return False\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied to write to {dest_dir} or read {zip_filepath}.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during unzipping: {e}\")\n",
    "        return False\n",
    "\n",
    "print(f\"Script started. Looking for zip file at: {SERVER_ZIP_FILE_PATH}\")\n",
    "\n",
    "if os.path.exists(SERVER_ZIP_FILE_PATH):\n",
    "    print(f\"Zip file found at {SERVER_ZIP_FILE_PATH}.\")\n",
    "    if unzip_data(SERVER_ZIP_FILE_PATH, EXTRACTION_DESTINATION_DIR_ON_SERVER):\n",
    "        \n",
    "        EXPECTED_EXTRACTED_FOLDER_NAME = 'spider_subset_data' # This is the folder INSIDE the zip\n",
    "\n",
    "        DEV_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'dev.json')\n",
    "        TABLES_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'tables.json')\n",
    "\n",
    "        print(\"\\nVerifying extracted file paths...\")\n",
    "        if os.path.exists(DEV_JSON_PATH):\n",
    "            print(f\"SUCCESS: dev.json path is valid: {DEV_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: dev.json NOT FOUND at expected path: {DEV_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "\n",
    "        if os.path.exists(TABLES_JSON_PATH):\n",
    "            print(f\"SUCCESS: tables.json path is valid: {TABLES_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: tables.json NOT FOUND at expected path: {TABLES_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Unzipping failed on the server. Cannot define data paths.\")\n",
    "else:\n",
    "    print(f\"ERROR: Zip file NOT FOUND at {SERVER_ZIP_FILE_PATH} on the server.\")\n",
    "    print(\"Please ensure the 'scp' command was successful and the path is correct.\")\n",
    "\n",
    "\n",
    "if DEV_JSON_PATH and TABLES_JSON_PATH and os.path.exists(DEV_JSON_PATH) and os.path.exists(TABLES_JSON_PATH):\n",
    "    print(\"\\n--- Ready to load data ---\")\n",
    "    print(f\"Path to dev.json: {DEV_JSON_PATH}\")\n",
    "    print(f\"Path to tables.json: {TABLES_JSON_PATH}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n--- Data paths are not correctly set up. Cannot proceed with data loading. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b93479-df37-4b4b-9f80-44c9222dba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 queries from dev.json\n",
      "Loaded 166 database schemas from tables.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(f\"ERROR: File not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "dev_data = load_json_data(DEV_JSON_PATH)\n",
    "tables_data = load_json_data(TABLES_JSON_PATH)\n",
    "\n",
    "if dev_data and tables_data:\n",
    "    print(f\"Loaded {len(dev_data)} queries from dev.json\")\n",
    "    print(f\"Loaded {len(tables_data)} database schemas from tables.json\")\n",
    "else:\n",
    "    print(\"Failed to load Spider data. Please check paths and upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c304d6-7712-4138-9d36-cbab1a8e225d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Preparing Database Schema SQL Strings (Dictionary Output) ---\n",
      "Loaded schema data for 166 databases from '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json'.\n",
      "Successfully populated `all_db_schemas_sql_strings` dictionary with 166 entries.\n",
      "\n",
      "--- Verification of all_db_schemas_sql_strings ---\n",
      "Type: <class 'dict'>\n",
      "Number of schemas processed: 166\n",
      "Sample - DB ID: perpetrator\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# import os # Not strictly needed for this dictionary creation unless used in paths\n",
    "# import traceback # Only needed if you keep the full traceback print in except\n",
    "\n",
    "# --- Helper Functions (These are the same as you provided) ---\n",
    "def load_schemas(tables_json_path):\n",
    "    \"\"\"Loads schemas from tables.json into a dictionary keyed by db_id.\"\"\"\n",
    "    with open(tables_json_path, 'r') as f:\n",
    "        schemas_list = json.load(f)\n",
    "    schemas_dict = {db_info['db_id']: db_info for db_info in schemas_list}\n",
    "    return schemas_dict\n",
    "\n",
    "def map_spider_type_to_sql_type(spider_type, is_pk_or_fk=False):\n",
    "    \"\"\"Maps Spider's generic types to SQLite data types.\"\"\"\n",
    "    spider_type = spider_type.lower()\n",
    "    if spider_type == \"text\":\n",
    "        return \"TEXT\"\n",
    "    elif spider_type == \"number\":\n",
    "        return \"INTEGER\" if is_pk_or_fk else \"REAL\"\n",
    "    elif spider_type == \"time\":\n",
    "        return \"DATETIME\"\n",
    "    elif spider_type == \"boolean\":\n",
    "        return \"BOOLEAN\"\n",
    "    elif spider_type == \"others\":\n",
    "        return \"BLOB\"\n",
    "    else:\n",
    "        return \"TEXT\"\n",
    "\n",
    "def escape_sql_identifier(name):\n",
    "    \"\"\"Escapes SQL identifiers (table/column names) if they contain spaces or are keywords.\"\"\"\n",
    "    if \" \" in name or name.lower() in {\"select\", \"from\", \"where\", \"table\", \"primary\", \"key\", \"foreign\", \"index\", \"order\", \"group\"}:\n",
    "        return f'\"{name}\"'\n",
    "    return name\n",
    "\n",
    "def generate_create_table_sql_for_db(db_id, all_schemas_data): # Parameter name changed for consistency\n",
    "    \"\"\"\n",
    "    Generates SQL CREATE TABLE statements for a given db_id from the Spider schema.\n",
    "    'all_schemas_data' is the dictionary produced by load_schemas.\n",
    "    \"\"\"\n",
    "    if db_id not in all_schemas_data:\n",
    "        return f\"-- Database ID '{db_id}' not found in schemas.\"\n",
    "\n",
    "    db_schema = all_schemas_data[db_id] # Get the specific schema info for this db_id\n",
    "    sql_statements = []\n",
    "    column_info_by_index = {}\n",
    "    for i, (table_idx, col_name_original) in enumerate(db_schema['column_names_original']):\n",
    "        if col_name_original == \"*\":\n",
    "            continue\n",
    "        column_info_by_index[i] = {\n",
    "            \"original_name\": col_name_original,\n",
    "            \"table_index\": table_idx,\n",
    "            \"original_table_name\": db_schema['table_names_original'][table_idx],\n",
    "            \"type\": db_schema['column_types'][i]\n",
    "        }\n",
    "    for table_idx, table_name_original in enumerate(db_schema['table_names_original']):\n",
    "        escaped_table_name = escape_sql_identifier(table_name_original)\n",
    "        column_definitions = []\n",
    "        table_constraints = []\n",
    "        current_table_columns = []\n",
    "        for col_global_idx, (tbl_idx_for_col, col_name_orig) in enumerate(db_schema['column_names_original']):\n",
    "            if col_name_orig == \"*\":\n",
    "                continue\n",
    "            if tbl_idx_for_col == table_idx:\n",
    "                current_table_columns.append({\n",
    "                    \"global_idx\": col_global_idx,\n",
    "                    \"name\": col_name_orig,\n",
    "                    \"type\": db_schema['column_types'][col_global_idx]\n",
    "                })\n",
    "        pk_column_indices_for_table = [\n",
    "            pk_idx for pk_idx in db_schema['primary_keys']\n",
    "            if column_info_by_index.get(pk_idx) and column_info_by_index[pk_idx]['table_index'] == table_idx\n",
    "        ]\n",
    "        pk_column_names_for_table = [column_info_by_index[idx]['original_name'] for idx in pk_column_indices_for_table]\n",
    "        for col_data in current_table_columns:\n",
    "            col_name_original = col_data['name']\n",
    "            spider_type = col_data['type']\n",
    "            col_global_idx = col_data['global_idx']\n",
    "            is_pk_col = col_global_idx in pk_column_indices_for_table\n",
    "            is_fk_col = any(fk_pair[0] == col_global_idx for fk_pair in db_schema['foreign_keys'])\n",
    "            sql_type = map_spider_type_to_sql_type(spider_type, is_pk_or_fk=(is_pk_col or is_fk_col))\n",
    "            escaped_col_name = escape_sql_identifier(col_name_original)\n",
    "            col_def_str = f\"{escaped_col_name} {sql_type}\"\n",
    "            if is_pk_col and len(pk_column_names_for_table) == 1:\n",
    "                col_def_str += \" PRIMARY KEY\"\n",
    "            column_definitions.append(col_def_str)\n",
    "        if len(pk_column_names_for_table) > 1:\n",
    "            escaped_pk_cols = [escape_sql_identifier(name) for name in pk_column_names_for_table]\n",
    "            table_constraints.append(f\"PRIMARY KEY ({', '.join(escaped_pk_cols)})\")\n",
    "        for fk_col_idx, referenced_col_idx in db_schema['foreign_keys']:\n",
    "            if column_info_by_index.get(fk_col_idx) and \\\n",
    "               column_info_by_index.get(referenced_col_idx) and \\\n",
    "               column_info_by_index[fk_col_idx]['table_index'] == table_idx:\n",
    "                fk_column_name = column_info_by_index[fk_col_idx]['original_name']\n",
    "                referenced_table_name = column_info_by_index[referenced_col_idx]['original_table_name']\n",
    "                referenced_column_name = column_info_by_index[referenced_col_idx]['original_name']\n",
    "                escaped_fk_col = escape_sql_identifier(fk_column_name)\n",
    "                escaped_ref_table = escape_sql_identifier(referenced_table_name)\n",
    "                escaped_ref_col = escape_sql_identifier(referenced_column_name)\n",
    "                table_constraints.append(\n",
    "                    f\"FOREIGN KEY ({escaped_fk_col}) REFERENCES {escaped_ref_table} ({escaped_ref_col})\"\n",
    "                )\n",
    "        all_parts = column_definitions + table_constraints\n",
    "        create_table_statement = f\"CREATE TABLE {escaped_table_name} (\\n  \"\n",
    "        create_table_statement += \",\\n  \".join(all_parts)\n",
    "        create_table_statement += \"\\n);\"\n",
    "        sql_statements.append(create_table_statement)\n",
    "    return \"\\n\\n\".join(sql_statements)\n",
    "# --- End of Helper Functions ---\n",
    "\n",
    "\n",
    "# --- MODIFIED \"Main Execution\" for \"Cell 1\" to produce the dictionary ---\n",
    "# This code will be run when you execute the Jupyter cell.\n",
    "# The output variable needed by your experiment is `all_db_schemas_sql_strings`.\n",
    "\n",
    "all_db_schemas_sql_strings = {} # This is the dictionary your experiment needs\n",
    "\n",
    "# Define the path to your tables.json\n",
    "spider_tables_json_path = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json'\n",
    "\n",
    "print(\"--- Cell 1: Preparing Database Schema SQL Strings (Dictionary Output) ---\")\n",
    "try:\n",
    "    # 1. Load all schema structures from tables.json\n",
    "    # `all_db_schemas_data_loaded` will be a dictionary: {db_id: schema_info_dict, ...}\n",
    "    all_db_schemas_data_loaded = load_schemas(spider_tables_json_path) # Renamed to avoid confusion with function parameter\n",
    "    print(f\"Loaded schema data for {len(all_db_schemas_data_loaded)} databases from '{spider_tables_json_path}'.\")\n",
    "\n",
    "    # 2. Iterate through each loaded schema and generate its SQL string, storing it in the dictionary\n",
    "    if all_db_schemas_data_loaded:\n",
    "        for db_id in all_db_schemas_data_loaded: # Iterate through keys (db_ids)\n",
    "            # Call generate_create_table_sql_for_db, passing the full loaded data\n",
    "            # and the current db_id.\n",
    "            sql_string_for_db = generate_create_table_sql_for_db(db_id, all_db_schemas_data_loaded)\n",
    "\n",
    "            # Store the raw SQL string in the dictionary.\n",
    "            # We only store it if it's a successful generation (doesn't start with the error message)\n",
    "            if sql_string_for_db and not sql_string_for_db.startswith(\"-- Database ID\"):\n",
    "                all_db_schemas_sql_strings[db_id] = sql_string_for_db\n",
    "            elif sql_string_for_db.startswith(\"-- Database ID\"):\n",
    "                print(f\"Warning: Schema for {db_id} reported as not found by generate_create_table_sql_for_db.\")\n",
    "            else:\n",
    "                print(f\"Warning: SQL generation returned empty or unexpected for {db_id} (Result: '{sql_string_for_db[:50]}...')\")\n",
    "\n",
    "        print(f\"Successfully populated `all_db_schemas_sql_strings` dictionary with {len(all_db_schemas_sql_strings)} entries.\")\n",
    "    else:\n",
    "        print(\"No schema data loaded from tables.json, so `all_db_schemas_sql_strings` will be empty.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The file '{spider_tables_json_path}' was not found.\")\n",
    "    all_db_schemas_sql_strings = {} # Ensure it's defined as empty on error\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"FATAL ERROR: Could not decode JSON from '{spider_tables_json_path}'. Check if it's a valid JSON file.\")\n",
    "    all_db_schemas_sql_strings = {}\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR during schema preparation: {e}\")\n",
    "    # import traceback # Uncomment if you need the full traceback here\n",
    "    # traceback.print_exc()\n",
    "    all_db_schemas_sql_strings = {}\n",
    "\n",
    "# --- Verification (you can add this to your cell to check after it runs) ---\n",
    "print(f\"\\n--- Verification of all_db_schemas_sql_strings ---\")\n",
    "print(f\"Type: {type(all_db_schemas_sql_strings)}\")\n",
    "print(f\"Number of schemas processed: {len(all_db_schemas_sql_strings)}\")\n",
    "if all_db_schemas_sql_strings:\n",
    "    # Print a sample to verify content\n",
    "    sample_db_id = list(all_db_schemas_sql_strings.keys())[0]\n",
    "    print(f\"Sample - DB ID: {sample_db_id}\")\n",
    "    # print(f\"Sample - SQL String (first 300 chars):\\n{all_db_schemas_sql_strings[sample_db_id][:300]}...\")\n",
    "else:\n",
    "    print(\"`all_db_schemas_sql_strings` is empty. Review errors above.\")\n",
    "# --- End of Cell 1 Logic ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2452e5b-6f75-47d1-bc17-276b3afc9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sampling\n",
    "\n",
    "# This cell defines parameters for running the experiment.\n",
    "# It will now randomly select queries and always use ALL database schemas as candidates.\n",
    "\n",
    "import random # Ensure random is imported at the top of your notebook or this cell\n",
    "# import os # Ensure os is imported (likely already done for path joining)\n",
    "# import json # Ensure json is imported (likely already done for loading)\n",
    "\n",
    "# --- 2.1. Experiment Parameters ---\n",
    "# Number of NL queries to RANDOMLY select from dev.json to process.\n",
    "# For initial testing in Colab, use a small subset. For a more thorough run, increase this.\n",
    "NUM_RANDOM_QUERIES_TO_TEST = 100 # For example, test 5 random queries\n",
    "\n",
    "# This will now effectively always be True based on your requirement.\n",
    "# The logic will be set up to use all schemas from all_db_schemas_sql_strings.\n",
    "# We can keep the variable for clarity or remove it if it's always all DBs.\n",
    "# For this implementation, let's explicitly aim for all DBs.\n",
    "print(\"INFO: This experiment configuration will test each randomly selected query against ALL available Spider database schemas.\")\n",
    "\n",
    "\n",
    "# --- 2.2. Randomly Select NL Queries for the Experiment ---\n",
    "# We will randomly sample NUM_RANDOM_QUERIES_TO_TEST queries from the loaded dev_data.\n",
    "if not dev_data: # dev_data should have been loaded in Cell 1\n",
    "    raise ValueError(\"dev_data is not loaded (from dev.json). Cannot select queries. Please run Cell 1 first.\")\n",
    "\n",
    "if len(dev_data) == 0:\n",
    "    raise ValueError(\"dev_data is empty. No queries to select.\")\n",
    "\n",
    "actual_num_queries_to_select = min(NUM_RANDOM_QUERIES_TO_TEST, len(dev_data))\n",
    "# Using min ensures we don't try to sample more queries than available.\n",
    "\n",
    "if actual_num_queries_to_select < NUM_RANDOM_QUERIES_TO_TEST:\n",
    "    print(f\"Warning: Requested {NUM_RANDOM_QUERIES_TO_TEST} random queries, but only {len(dev_data)} are available. Using all {len(dev_data)} queries.\")\n",
    "\n",
    "# Randomly sample without replacement\n",
    "selected_nl_queries = random.sample(dev_data, actual_num_queries_to_select)\n",
    "\n",
    "print(f\"\\nRandomly selected {len(selected_nl_queries)} NL queries for the experiment:\")\n",
    "for i, q_info in enumerate(selected_nl_queries):\n",
    "    print(f\"  Test Query {i+1}: '{q_info['question']}' (True DB: {q_info['db_id']})\")\n",
    "\n",
    "\n",
    "# --- 2.3. Determine Candidate Database Schemas for Each Query ---\n",
    "# For this experiment design, we ALWAYS use ALL available database schemas.\n",
    "# all_db_schemas_sql_strings should have been populated in Cell 1.\n",
    "if not all_sql_output: # Populated in Cell 1\n",
    "    raise ValueError(\"all_sql_output is empty. Schemas were not converted in Cell 1. Cannot proceed.\")\n",
    "\n",
    "candidate_schemas_for_evaluation = all_db_schemas_sql_strings # Use all converted schemas\n",
    "print(f\"\\nEach of the {len(selected_nl_queries)} selected queries will be evaluated against all {len(candidate_schemas_for_evaluation)} available Spider database schemas.\")\n",
    "\n",
    "if not candidate_schemas_for_evaluation: # Should not happen if all_db_schemas_sql_strings was populated\n",
    "    raise ValueError(\"No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d67f720-5263-4bb6-8db6-a4da23c1a95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: This experiment configuration will test each randomly selected query against ALL available Spider database schemas.\n",
      "Loaded 100 queries from '/raid/infolab/gaurav/Llama_Spider_A100_Project/100_queries.txt':\n",
      "  Query 1: 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n",
      "  Query 2: 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n",
      "  Query 3: 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n",
      "  Query 4: 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n",
      "  Query 5: 'How many different nationalities do conductors have?' (True DB: orchestra)\n",
      "  Query 6: 'How many states are there?' (True DB: voter_1)\n",
      "  Query 7: 'What are the codes of template types that have fewer than 3 templates?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 8: 'How many dogs have not gone through any treatment?' (True DB: dog_kennels)\n",
      "  Query 9: 'What are the template ids of any templates used in more than a single document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 10: 'Show name, country, age for all singers ordered by age from the oldest to the youngest.' (True DB: concert_singer)\n",
      "  Query 11: 'Show the student IDs and numbers of friends corresponding to each.' (True DB: network_1)\n",
      "  Query 12: 'What are flight numbers of flights arriving at City \"Aberdeen\"?' (True DB: flight_2)\n",
      "  Query 13: 'How many countries speak both English and Dutch?' (True DB: world_1)\n",
      "  Query 14: 'What are the notes of the death events which has substring 'East'?' (True DB: battle_death)\n",
      "  Query 15: 'What are the names of conductors as well as the corresonding orchestras that they have conducted?' (True DB: orchestra)\n",
      "  Query 16: 'List the earnings of poker players in descending order.' (True DB: poker_player)\n",
      "  Query 17: 'Which owner has paid the largest amount of money in total for their dogs? Show the owner id and zip code.' (True DB: dog_kennels)\n",
      "  Query 18: 'Find the number of flights landing in the city of Aberdeen or Abilene.' (True DB: flight_2)\n",
      "  Query 19: 'How many pets have a greater weight than 10?' (True DB: pets_1)\n",
      "  Query 20: 'Show different citizenships and the maximum net worth of singers of each citizenship.' (True DB: singer)\n",
      "  Query 21: 'What are the population, name and leader of the country with the largest area?' (True DB: world_1)\n",
      "  Query 22: 'For each semester, what is the name and id of the one with the most students registered?' (True DB: student_transcripts_tracking)\n",
      "  Query 23: 'Show paragraph details for paragraph with text 'Korea ' .' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 24: 'Return the number of  airports.' (True DB: flight_2)\n",
      "  Query 25: 'Find the average age of losers and winners of all matches.' (True DB: wta_1)\n",
      "  Query 26: 'What is the most commmon hometowns for teachers?' (True DB: course_teach)\n",
      "  Query 27: 'List the title of all cartoons in alphabetical order.' (True DB: tvshow)\n",
      "  Query 28: 'What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?' (True DB: car_1)\n",
      "  Query 29: 'What is the average transcript date?' (True DB: student_transcripts_tracking)\n",
      "  Query 30: 'What is the total population of Gelderland district?' (True DB: world_1)\n",
      "  Query 31: 'Return the money rank of the player with the greatest earnings.' (True DB: poker_player)\n",
      "  Query 32: 'What are the names of the sections in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n",
      "  Query 33: 'What languages are only used by a single country with a republic government?' (True DB: world_1)\n",
      "  Query 34: 'Return the id of the document with the fewest paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 35: 'What are the descriptions for all the math courses?' (True DB: student_transcripts_tracking)\n",
      "  Query 36: 'Find the first name of students who have both cat and dog pets .' (True DB: pets_1)\n",
      "  Query 37: 'Find the type and weight of the youngest pet.' (True DB: pets_1)\n",
      "  Query 38: 'Find the role, street, city and state of the professionals living in a city that contains the substring 'West'.' (True DB: dog_kennels)\n",
      "  Query 39: 'What is the code of airport that has the highest number of flights?' (True DB: flight_2)\n",
      "  Query 40: 'What is the Package Option of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Query 41: 'Tell me the age of the oldest dog.' (True DB: dog_kennels)\n",
      "  Query 42: 'What are the countries that have greater surface area than any country in Europe?' (True DB: world_1)\n",
      "  Query 43: 'Find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.' (True DB: concert_singer)\n",
      "  Query 44: 'List the names and birth dates of people in ascending alphabetical order of name.' (True DB: poker_player)\n",
      "  Query 45: 'How many cities in each district have a population that is above the average population across all cities?' (True DB: world_1)\n",
      "  Query 46: 'Return the nationalities for which there are two or more people.' (True DB: poker_player)\n",
      "  Query 47: 'How many documents do we have?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 48: 'Tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.' (True DB: dog_kennels)\n",
      "  Query 49: 'What are the names and descriptions for all the sections?' (True DB: student_transcripts_tracking)\n",
      "  Query 50: 'How many available features are there in total?' (True DB: real_estate_properties)\n",
      "  Query 51: 'What are the birth year and citizenship of singers?' (True DB: singer)\n",
      "  Query 52: 'How many matches were played in each year?' (True DB: wta_1)\n",
      "  Query 53: 'Which airlines have at least 10 flights?' (True DB: flight_2)\n",
      "  Query 54: 'What is the name and id of the department with the most number of degrees ?' (True DB: student_transcripts_tracking)\n",
      "  Query 55: 'What are the ids for templates that are not used in any documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 56: 'What is the last transcript release date?' (True DB: student_transcripts_tracking)\n",
      "  Query 57: 'What are the names of the teachers ordered by ascending age?' (True DB: course_teach)\n",
      "  Query 58: 'Show the date and id of the transcript with at least 2 course results.' (True DB: student_transcripts_tracking)\n",
      "  Query 59: 'What are the names of conductors whose nationalities are not \"USA\"?' (True DB: orchestra)\n",
      "  Query 60: 'What are the names of students who have no friends?' (True DB: network_1)\n",
      "  Query 61: 'What is the count of the car models produced in the United States?' (True DB: car_1)\n",
      "  Query 62: 'What are the names of countries that speak more than 2 languages, as well as how many languages they speak?' (True DB: world_1)\n",
      "  Query 63: 'Give the name, population, and head of state for the country that has the largest area.' (True DB: world_1)\n",
      "  Query 64: 'How many different results are there for the battles?' (True DB: battle_death)\n",
      "  Query 65: 'What are the names of the countries with no car makers?' (True DB: car_1)\n",
      "  Query 66: 'What is the language that is used by the largest number of Asian nations?' (True DB: world_1)\n",
      "  Query 67: 'Return the record companies of orchestras, sorted descending by the years in which they were founded.' (True DB: orchestra)\n",
      "  Query 68: 'What are the names of properties that are either houses or apartments with more than 1 room?' (True DB: real_estate_properties)\n",
      "  Query 69: 'find the package option of the tv channel that do not have any cartoon directed by Ben Jones.' (True DB: tvshow)\n",
      "  Query 70: 'List the last name of the owner owning the youngest dog.' (True DB: dog_kennels)\n",
      "  Query 71: 'What is the name and capacity of the stadium with the most concerts after 2013 ?' (True DB: concert_singer)\n",
      "  Query 72: 'What are the names of conductors who have conducted orchestras founded after the year 2008?' (True DB: orchestra)\n",
      "  Query 73: 'How many cars has over 6 cylinders?' (True DB: car_1)\n",
      "  Query 74: 'What is the number of car models that are produced by each maker and what is the id and full name of each maker?' (True DB: car_1)\n",
      "  Query 75: 'What are the names of conductors, sorted descending by the number of years they have worked?' (True DB: orchestra)\n",
      "  Query 76: 'What are the distinct template type descriptions for the templates ever used by any document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 77: 'What are the names of poker players, ordered ascending by the number of final tables they have made?' (True DB: poker_player)\n",
      "  Query 78: 'What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?' (True DB: car_1)\n",
      "  Query 79: 'What is the TV Channel of TV series with Episode \"A Love of a Lifetime\"? List the TV Channel's series name.' (True DB: tvshow)\n",
      "  Query 80: 'What is the lowest grade of students who do not have any friends?' (True DB: network_1)\n",
      "  Query 81: 'Show the name and theme for all concerts and the number of singers in each concert.' (True DB: concert_singer)\n",
      "  Query 82: 'What is the total ticket expense of the visitors whose membership level is 1?' (True DB: museum_visit)\n",
      "  Query 83: 'Which professionals have done at least two types of treatments? List the professional id and cell phone.' (True DB: dog_kennels)\n",
      "  Query 84: 'How many countries does each continent have? List the continent id, continent name and the number of countries.' (True DB: car_1)\n",
      "  Query 85: 'What is the average, minimum, and maximum age for all French singers?' (True DB: concert_singer)\n",
      "  Query 86: 'What is the car model with the highest mpg ?' (True DB: car_1)\n",
      "  Query 87: 'How many flights do we have?' (True DB: flight_2)\n",
      "  Query 88: 'What is the series name of the TV Channel that shows the cartoon \"The Rise of the Blue Beetle\"?' (True DB: tvshow)\n",
      "  Query 89: 'What is the name of the conductor who has conducted the most orchestras?' (True DB: orchestra)\n",
      "  Query 90: 'How many battles did not lose any ship with tonnage '225'?' (True DB: battle_death)\n",
      "  Query 91: 'Of all the contestants who got voted, what is the contestant number and name of the contestant who got least votes?' (True DB: voter_1)\n",
      "  Query 92: 'What are the regions that use English or Dutch?' (True DB: world_1)\n",
      "  Query 93: 'Find the average number of staff working for the museums that were open before 2009.' (True DB: museum_visit)\n",
      "  Query 94: 'Find the total number of players.' (True DB: wta_1)\n",
      "  Query 95: 'Sort all the shops by number products in descending order, and return the name, location and district of each shop.' (True DB: employee_hire_evaluation)\n",
      "  Query 96: 'Describe the section h.' (True DB: student_transcripts_tracking)\n",
      "  Query 97: 'Count the number of paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 98: 'Find the number of pets whose weight is heavier than 10.' (True DB: pets_1)\n",
      "  Query 99: 'What are the record companies that are used by both orchestras founded before 2003 and those founded after 2003?' (True DB: orchestra)\n",
      "  Query 100: 'What are the ids and makers of all car makers that produce at least 2 models and make more than 3 cars?' (True DB: car_1)\n",
      "\n",
      "Each of the 100 selected queries will be evaluated against all 166 available Spider database schemas.\n"
     ]
    }
   ],
   "source": [
    "# This cell defines parameters for running the experiment.\n",
    "# It will now randomly select queries and always use ALL database schemas as candidates.\n",
    "\n",
    "import random # Ensure random is imported at the top of your notebook or this cell\n",
    "# import os # Ensure os is imported (likely already done for path joining)\n",
    "# import json # Ensure json is imported (likely already done for loading)\n",
    "\n",
    "# --- 2.1. Experiment Parameters ---\n",
    "# Number of NL queries to RANDOMLY select from dev.json to process.\n",
    "# For initial testing in Colab, use a small subset. For a more thorough run, increase this.\n",
    "NUM_RANDOM_QUERIES_TO_TEST = 100 # For example, test 5 random queries\n",
    "\n",
    "# This will now effectively always be True based on your requirement.\n",
    "# The logic will be set up to use all schemas from all_db_schemas_sql_strings.\n",
    "# We can keep the variable for clarity or remove it if it's always all DBs.\n",
    "# For this implementation, let's explicitly aim for all DBs.\n",
    "print(\"INFO: This experiment configuration will test each randomly selected query against ALL available Spider database schemas.\")\n",
    "\n",
    "\n",
    "# --- 2.2. Randomly Select NL Queries for the Experiment ---\n",
    "# We will randomly sample NUM_RANDOM_QUERIES_TO_TEST queries from the loaded dev_data.\n",
    "if not dev_data: # dev_data should have been loaded in Cell 1\n",
    "    raise ValueError(\"dev_data is not loaded (from dev.json). Cannot select queries. Please run Cell 1 first.\")\n",
    "\n",
    "if len(dev_data) == 0:\n",
    "    raise ValueError(\"dev_data is empty. No queries to select.\")\n",
    "\n",
    "actual_num_queries_to_select = min(NUM_RANDOM_QUERIES_TO_TEST, len(dev_data))\n",
    "# Using min ensures we don't try to sample more queries than available.\n",
    "\n",
    "if actual_num_queries_to_select < NUM_RANDOM_QUERIES_TO_TEST:\n",
    "    print(f\"Warning: Requested {NUM_RANDOM_QUERIES_TO_TEST} random queries, but only {len(dev_data)} are available. Using all {len(dev_data)} queries.\")\n",
    "\n",
    "# Randomly sample without replacementselected_nl_queries = random.sample(dev_data, actual_num_queries_to_select)\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Path to your text file containing lines like:\n",
    "#   Test Query 1: 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n",
    "TEXT_QUERIES_FILE = \"/raid/infolab/gaurav/Llama_Spider_A100_Project/100_queries.txt\"\n",
    "\n",
    "if not os.path.exists(TEXT_QUERIES_FILE):\n",
    "    raise FileNotFoundError(f\"Cannot find '{TEXT_QUERIES_FILE}' – make sure it’s in your working directory or update the path.\")\n",
    "\n",
    "selected_nl_queries = []\n",
    "pattern = re.compile(r\"Test Query\\s+\\d+:\\s+'(.+)'\\s+\\(True DB:\\s*([^)]+)\\)\")\n",
    "\n",
    "with open(TEXT_QUERIES_FILE, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        line = line.strip()\n",
    "        # Skip any header or non‐“Test Query” lines\n",
    "        if not line.startswith(\"Test Query\"):\n",
    "            continue\n",
    "\n",
    "        m = pattern.match(line)\n",
    "        if not m:\n",
    "            print(f\"Warning: could not parse line:\\n  {line}\")\n",
    "            continue\n",
    "\n",
    "        question_text = m.group(1)\n",
    "        true_db_id    = m.group(2)\n",
    "\n",
    "        # Build the same dict‐structure downstream code expects\n",
    "        selected_nl_queries.append({\n",
    "            \"question\": question_text,\n",
    "            \"db_id\":    true_db_id\n",
    "        })\n",
    "\n",
    "if len(selected_nl_queries) == 0:\n",
    "    raise ValueError(f\"No queries were parsed from '{TEXT_QUERIES_FILE}'. Check your file’s format.\")\n",
    "\n",
    "print(f\"Loaded {len(selected_nl_queries)} queries from '{TEXT_QUERIES_FILE}':\")\n",
    "for i, q in enumerate(selected_nl_queries, 1):\n",
    "    print(f\"  Query {i}: '{q['question']}' (True DB: {q['db_id']})\")\n",
    "\n",
    "# --- 2.3. Determine Candidate Database Schemas for Each Query ---\n",
    "# For this experiment design, we ALWAYS use ALL available database schemas.\n",
    "# all_db_schemas_sql_strings should have been populated in Cell 1.\n",
    "# if not all_sql_output: # Populated in Cell 1\n",
    "#     raise ValueError(\"all_sql_output is empty. Schemas were not converted in Cell 1. Cannot proceed.\")\n",
    "\n",
    "candidate_schemas_for_evaluation = all_db_schemas_sql_strings # Use all converted schemas\n",
    "print(f\"\\nEach of the {len(selected_nl_queries)} selected queries will be evaluated against all {len(candidate_schemas_for_evaluation)} available Spider database schemas.\")\n",
    "\n",
    "if not candidate_schemas_for_evaluation: # Should not happen if all_db_schemas_sql_strings was populated\n",
    "    raise ValueError(\"No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531bac23-fdaf-4552-a664-e0b0ae3ca27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured experiment project directory exists: '/raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1'\n",
      "Experiment results will be saved to: /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "LOCAL_EXPERIMENT_BASE_DIR = \"/raid/infolab/gaurav/Llama_Spider_A100_Project/\"\n",
    "\n",
    "\n",
    "EXPERIMENT_RUN_NAME = \"randomQ_allDBs_run1\" \n",
    "EXPERIMENT_PROJECT_DIR = os.path.join(LOCAL_EXPERIMENT_BASE_DIR, EXPERIMENT_RUN_NAME)\n",
    "\n",
    "try:\n",
    "    os.makedirs(EXPERIMENT_PROJECT_DIR, exist_ok=True)\n",
    "    print(f\"Ensured experiment project directory exists: '{EXPERIMENT_PROJECT_DIR}'\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory {EXPERIMENT_PROJECT_DIR}: {e}\")\n",
    "    EXPERIMENT_PROJECT_DIR = \".\" \n",
    "\n",
    "\n",
    "RESULTS_FILENAME = \"spider_random_query_all_db_scores.json\"\n",
    "EXPERIMENT_RESULTS_FILE = os.path.join(EXPERIMENT_PROJECT_DIR, RESULTS_FILENAME)\n",
    "\n",
    "print(f\"Experiment results will be saved to: {EXPERIMENT_RESULTS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06c3025-9d75-4217-8071-1418e90aaa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function 'get_yes_no_token_ids' defined (with actual logic).\n"
     ]
    }
   ],
   "source": [
    "# Cell defining get_yes_no_token_ids (CORRECTED)\n",
    "def get_yes_no_token_ids(tokenizer_arg):\n",
    "    \"\"\"\n",
    "    Determines the token IDs for 'Yes' and 'No', accounting for potential leading spaces.\n",
    "    Llama-2-chat tends to produce \" Yes\" or \" No\" as single tokens after the prompt.\n",
    "    \"\"\"\n",
    "    # Try with leading space first, as it's common for chat models\n",
    "    yes_token_id_with_space = tokenizer_arg.encode(\" Yes\", add_special_tokens=False)\n",
    "    no_token_id_with_space = tokenizer_arg.encode(\" No\", add_special_tokens=False)\n",
    "\n",
    "    if len(yes_token_id_with_space) == 1 and len(no_token_id_with_space) == 1:\n",
    "        print(\"Using ' Yes' and ' No' (with leading space) for Yes/No token IDs.\")\n",
    "        return yes_token_id_with_space[0], no_token_id_with_space[0] # Explicit return\n",
    "    else:\n",
    "        # Fallback to \"Yes\" and \"No\" without leading space\n",
    "        yes_token_id_no_space = tokenizer_arg.encode(\"Yes\", add_special_tokens=False)\n",
    "        no_token_id_no_space = tokenizer_arg.encode(\"No\", add_special_tokens=False)\n",
    "        if len(yes_token_id_no_space) == 1 and len(no_token_id_no_space) == 1:\n",
    "            print(\"Warning: Using 'Yes' and 'No' (no leading space) for Yes/No token IDs. This might be suboptimal for chat models.\")\n",
    "            return yes_token_id_no_space[0], no_token_id_no_space[0] # Explicit return\n",
    "        else:\n",
    "            # This case is problematic.\n",
    "            print(f\"ERROR: Could not determine reliable single token IDs for 'Yes'/'No' or ' Yes'/' No'.\")\n",
    "            print(f\"Tokenization of ' Yes': {yes_token_id_with_space} (decoded: {[tokenizer_arg.decode(t) for t in yes_token_id_with_space]})\")\n",
    "            print(f\"Tokenization of ' No': {no_token_id_with_space} (decoded: {[tokenizer_arg.decode(t) for t in no_token_id_with_space]})\")\n",
    "            print(f\"Tokenization of 'Yes': {yes_token_id_no_space} (decoded: {[tokenizer_arg.decode(t) for t in yes_token_id_no_space]})\")\n",
    "            print(f\"Tokenization of 'No': {no_token_id_no_space} (decoded: {[tokenizer_arg.decode(t) for t in no_token_id_no_space]})\")\n",
    "            # It's better to raise an error here so the problem is immediately obvious\n",
    "            # rather than returning None and causing a TypeError later.\n",
    "            raise ValueError(\"Unstable tokenization for 'Yes'/'No'. Review tokenization outputs above. Cannot proceed without reliable Yes/No token IDs.\")\n",
    "\n",
    "print(\"Helper function 'get_yes_no_token_ids' defined (with actual logic).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abb8b6cb-d43f-40a9-bf6e-6779c779201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Using 'Yes' and 'No' (no leading space) for Yes/No token IDs. This might be suboptimal for chat models.\n",
      "YES_TOKEN_ID: 3869 ('Yes')\n",
      "NO_TOKEN_ID: 1939 ('No')\n"
     ]
    }
   ],
   "source": [
    "if 'tokenizer' in globals() and tokenizer is not None:\n",
    "    try:\n",
    "        YES_TOKEN_ID, NO_TOKEN_ID = get_yes_no_token_ids(tokenizer)\n",
    "        print(f\"YES_TOKEN_ID: {YES_TOKEN_ID} ('{tokenizer.decode([YES_TOKEN_ID])}')\")\n",
    "        print(f\"NO_TOKEN_ID: {NO_TOKEN_ID} ('{tokenizer.decode([NO_TOKEN_ID])}')\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error defining YES/NO token IDs: {e}\")\n",
    "else:\n",
    "    print(\"ERROR: 'tokenizer' is not defined. Cannot define YES_TOKEN_ID and NO_TOKEN_ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc6a8811-2963-48c5-9f50-0eba843139cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core function 'get_yes_probability' defined.\n"
     ]
    }
   ],
   "source": [
    "import torch # Ensure torch is imported\n",
    "# After loading your tokenizer:\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", ...) # Or your specific model\n",
    "\n",
    "# Llama 2 Chat Template (common structure)\n",
    "# Make sure this matches the exact format expected by YOUR specific Llama 2 variant.\n",
    "# Check the model card on Hugging Face for the precise template.\n",
    "chat_template_llama2 = (\n",
    "    \"{% if messages[0]['role'] == 'system' %}\"\n",
    "    \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "    \"{% else %}\"\n",
    "    \"<s>[INST] \"\n",
    "    \"{% endif %}\"\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'user' %}\"\n",
    "    \"{{ message['content'] }} [/INST]\"\n",
    "    \"{% elif message['role'] == 'assistant' %}\"\n",
    "    \" {{ message['content'] }} </s><s>[INST]\"\n",
    "    \"{% elif message['role'] == 'system' and loop.index0 > 0 %}\" # Handle system message if not first\n",
    "    \" <<SYS>>\\n{{ message['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}\" # Add generation prompt if last message is not assistant\n",
    "    \" \" # This space is important before the assistant starts generating\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "# A simpler version if you always have system then user:\n",
    "# chat_template_llama2_simple = \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n{{ messages[1]['content'] }} [/INST] \"\n",
    "\n",
    "\n",
    "# --- CHOOSE THE CORRECT TEMPLATE FOR YOUR MODEL ---\n",
    "# For many Llama-2-chat models, the tokenizer might already have a default template\n",
    "# if loaded correctly, but if not, you can set it.\n",
    "# A common one if your `messages` list is always [system_message, user_message]:\n",
    "if tokenizer.chat_template is None:\n",
    "    if \"llama-2\" in tokenizer.name_or_path.lower() and \"chat\" in tokenizer.name_or_path.lower() : # Be more specific if needed\n",
    "        # This is a common structure for Llama-2-chat for a system prompt followed by a user prompt.\n",
    "        # The assistant's response will follow \" [/INST] \"\n",
    "        tokenizer.chat_template = (\n",
    "            \"{% if messages[0]['role'] == 'system' %}\"\n",
    "            \"<s>[INST] <<SYS>>\\n{{ messages[0]['content'] }}\\n<</SYS>>\\n\\n\"\n",
    "            \"{% endif %}\"\n",
    "            \"{{ messages[1]['content'] }} [/INST]\" # Assumes second message is user\n",
    "            # Add a space for the model to start generation if add_generation_prompt=True\n",
    "            \"{% if add_generation_prompt %} {% endif %}\"\n",
    "        )\n",
    "        print(\"Manually set Llama 2 chat template on tokenizer.\")\n",
    "    else:\n",
    "        print(\"Warning: tokenizer.chat_template is None and no specific template was set for the model type.\")\n",
    "        # You might need to define a different template or handle formatting manually.\n",
    "\n",
    "# --- Core function to get P(Yes) ---\n",
    "def get_yes_probability(model_arg, tokenizer_arg, system_prompt_arg, user_prompt_content_arg, yes_token_id_arg, no_token_id_arg, max_length=2048):\n",
    "    \"\"\"\n",
    "    Gets the probability of the model answering \"Yes\" to the given query and schema.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_arg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_content_arg}\n",
    "    ]\n",
    "\n",
    "    prompt_for_model = tokenizer_arg.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer_arg(\n",
    "        prompt_for_model,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length - 10\n",
    "    )\n",
    "    inputs = {k: v.to(model_arg.device) for k, v in inputs.items()}\n",
    "\n",
    "    if inputs['input_ids'].shape[1] >= max_length - 10:\n",
    "         print(f\"Warning: Prompt for query was truncated. Length: {inputs['input_ids'].shape[1]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_arg(**inputs)\n",
    "        logits = outputs.logits\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        logit_yes = next_token_logits[:, yes_token_id_arg].item()\n",
    "        logit_no = next_token_logits[:, no_token_id_arg].item()\n",
    "\n",
    "    max_logit = max(logit_yes, logit_no)\n",
    "    exp_yes = torch.exp(torch.tensor(logit_yes - max_logit, device=model_arg.device))\n",
    "    exp_no = torch.exp(torch.tensor(logit_no - max_logit, device=model_arg.device))\n",
    "\n",
    "    prob_yes = exp_yes / (exp_yes + exp_no)\n",
    "    return prob_yes.item()\n",
    "\n",
    "print(\"Core function 'get_yes_probability' defined.\") # Add a print statement to confirm execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dfe1828-56ee-4994-91e0-9ecc5acfb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Condensed Prompt Configuration (fits in a 2K‐token window) ---\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert analyst. Decide if a natural‐language question can be answered *only* from the given schema. \n",
    "If all required tables, columns, and join‐paths exist, respond with exactly “Yes”. Otherwise, respond with exactly “No”.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "# Few‐Shot Examples (Spider style)\n",
    "\n",
    "[Schema: student(student_id, student_name); course(course_id, course_name); enrollment(student_id→student, course_id→course)]\n",
    "Q: List the names of all students enrolled in the 'Math' course.\n",
    "Reasoning: enrollment links student↔course; course_name exists; student_name exists → SQL possible.\n",
    "A: Yes\n",
    "\n",
    "[Schema: orders(order_id, customer_id, amount); customer(customer_id, customer_name)]\n",
    "Q: Find the total number of orders placed in 2019.\n",
    "Reasoning: no order_date or year column → cannot filter by 2019.\n",
    "A: No\n",
    "\n",
    "# Now Evaluate\n",
    "\n",
    "[Schema: {schema_string}]\n",
    "Q: {nl_query}\n",
    "A:\n",
    "\"\"\"\n",
    "final_prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "{SYSTEM_PROMPT}\n",
    "<</SYS>>\n",
    "\n",
    "{USER_PROMPT_TEMPLATE}[/INST]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a534772-a426-4df2-bb02-72aae58c82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing get_yes_probability directly...\n",
      "Test User Prompt: \n",
      "# Few‐Shot Examples (Spider style)\n",
      "\n",
      "[Schema: student(student_id, student_name); course(course_id, course_name); enrollment(student_id→student, course_id→course)]\n",
      "Q: List the names of all students enrolled in the 'Math' course.\n",
      "Reasoning: enrollment links student↔course; course_name exists; student_name exists → SQL possible.\n",
      "A: Yes\n",
      "\n",
      "[Schema: orders(order_id, customer_id, amount); customer(customer_id, customer_name)]\n",
      "Q: Find the total number of orders placed in 2019.\n",
      "Reasoning: no order_date or year column → cannot filter by 2019.\n",
      "A: No\n",
      "\n",
      "# Now Evaluate\n",
      "\n",
      "[Schema: CREATE TABLE TestTable (id INT, name TEXT);]\n",
      "Q: What is the name for id 1?\n",
      "A:\n",
      "\n",
      "get_yes_probability returned: 0.9981324076652527\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing get_yes_probability directly...\")\n",
    "try:\n",
    "    # Construct a very simple schema and query for testing\n",
    "    test_schema = \"CREATE TABLE TestTable (id INT, name TEXT);\"\n",
    "    test_nl_query = \"What is the name for id 1?\"\n",
    "    sample_user_prompt_content = USER_PROMPT_TEMPLATE.format(\n",
    "        schema_string=test_schema,\n",
    "        nl_query=test_nl_query\n",
    "    )\n",
    "    print(f\"Test User Prompt: {sample_user_prompt_content}\")\n",
    "\n",
    "    # Make sure all these variables are defined and loaded:\n",
    "    # model, tokenizer, SYSTEM_PROMPT, YES_TOKEN_ID, NO_TOKEN_ID\n",
    "    prob = get_yes_probability(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        SYSTEM_PROMPT,\n",
    "        sample_user_prompt_content,\n",
    "        YES_TOKEN_ID,\n",
    "        NO_TOKEN_ID\n",
    "    )\n",
    "    print(f\"get_yes_probability returned: {prob}\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"Error during direct call to get_yes_probability:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75247d87-a7f5-4ca4-8770-78e43e0c7e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Experiment: 100 Random Queries vs. 166 Total DB Schemas ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df14251edc94c1b9b60b6f039d5b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NL Queries:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query 1/100 (ID: spider_dev_q0_idx0): 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb03ccf6ef44e2b42bf05b047a848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q0_idx0:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 1 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 2/100 (ID: spider_dev_q1_idx1): 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3406c78f1a9a4d71adc415c4007dd951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q1_idx1:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 2 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 3/100 (ID: spider_dev_q2_idx2): 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2373a7cd85475d8c7b603abd7dcd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q2_idx2:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 3 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 4/100 (ID: spider_dev_q3_idx3): 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584dca241c0841f58fcdcc902030f56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q3_idx3:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 4 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 5/100 (ID: spider_dev_q4_idx4): 'How many different nationalities do conductors have?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622e7dc4f2a14fd29cc80c459eeaa29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q4_idx4:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 5 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 6/100 (ID: spider_dev_q5_idx5): 'How many states are there?' (True DB: voter_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edecda120414e09979bacdb34aa785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q5_idx5:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 6 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 7/100 (ID: spider_dev_q6_idx6): 'What are the codes of template types that have fewer than 3 templates?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4477a95e7446c38836f9f36f0b26a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q6_idx6:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 7 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 8/100 (ID: spider_dev_q7_idx7): 'How many dogs have not gone through any treatment?' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc05a82354e43b385d97d659c9321d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q7_idx7:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 8 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 9/100 (ID: spider_dev_q8_idx8): 'What are the template ids of any templates used in more than a single document?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaad4ca10a24d0399c8bd76824bb064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q8_idx8:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 9 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 10/100 (ID: spider_dev_q9_idx9): 'Show name, country, age for all singers ordered by age from the oldest to the youngest.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592925862a18404db27e401b1f32aa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q9_idx9:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 10 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 11/100 (ID: spider_dev_q10_idx10): 'Show the student IDs and numbers of friends corresponding to each.' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a422dc2b8de426e966e1df1916dfa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q10_idx10:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 11 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 12/100 (ID: spider_dev_q11_idx11): 'What are flight numbers of flights arriving at City \"Aberdeen\"?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fa997084d140aaba43e8684fdc3c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q11_idx11:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 12 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 13/100 (ID: spider_dev_q12_idx12): 'How many countries speak both English and Dutch?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f2079ed33043b2abe505d98fe25cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q12_idx12:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 13 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 14/100 (ID: spider_dev_q13_idx13): 'What are the notes of the death events which has substring 'East'?' (True DB: battle_death)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb1e658889743a09afece4005f05ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q13_idx13:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 14 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 15/100 (ID: spider_dev_q14_idx14): 'What are the names of conductors as well as the corresonding orchestras that they have conducted?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f9aae23942416c88a8cabe41abd4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q14_idx14:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 15 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 16/100 (ID: spider_dev_q15_idx15): 'List the earnings of poker players in descending order.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130c8195373d4d788ecdeb0e20b69e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q15_idx15:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 16 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 17/100 (ID: spider_dev_q16_idx16): 'Which owner has paid the largest amount of money in total for their dogs? Show the owner id and zip code.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3bde35ec234a46b093352ac9d4906b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q16_idx16:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 17 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 18/100 (ID: spider_dev_q17_idx17): 'Find the number of flights landing in the city of Aberdeen or Abilene.' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9829467cb5449fb81852d7b2dd03b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q17_idx17:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 18 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 19/100 (ID: spider_dev_q18_idx18): 'How many pets have a greater weight than 10?' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecc01494f2d4a97a2a6bf91ae1179c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q18_idx18:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 19 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 20/100 (ID: spider_dev_q19_idx19): 'Show different citizenships and the maximum net worth of singers of each citizenship.' (True DB: singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d2c5e3709d49aa89b0701fce55792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q19_idx19:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 20 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 21/100 (ID: spider_dev_q20_idx20): 'What are the population, name and leader of the country with the largest area?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca54af46502466d841b4a684b436def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q20_idx20:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 21 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 22/100 (ID: spider_dev_q21_idx21): 'For each semester, what is the name and id of the one with the most students registered?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a7bdf3bdcc4566bde3fde0cbca8324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q21_idx21:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 22 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 23/100 (ID: spider_dev_q22_idx22): 'Show paragraph details for paragraph with text 'Korea ' .' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b79d9c941144b49bfd771978af6ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q22_idx22:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 23 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 24/100 (ID: spider_dev_q23_idx23): 'Return the number of  airports.' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f3d6862fba4cff8c1014f6c2d4b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q23_idx23:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 24 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 25/100 (ID: spider_dev_q24_idx24): 'Find the average age of losers and winners of all matches.' (True DB: wta_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ef1cea9e4a4d82a3211b0cb623cc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q24_idx24:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 25 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 26/100 (ID: spider_dev_q25_idx25): 'What is the most commmon hometowns for teachers?' (True DB: course_teach)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b000c053dc694068b03c787d24ac6ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q25_idx25:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 26 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 27/100 (ID: spider_dev_q26_idx26): 'List the title of all cartoons in alphabetical order.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a89dc4b8804bde8c3e2753a75db6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q26_idx26:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 27 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 28/100 (ID: spider_dev_q27_idx27): 'What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351f26b1f92b4415b3c62f841a2bb06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q27_idx27:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 28 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 29/100 (ID: spider_dev_q28_idx28): 'What is the average transcript date?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b00096117eb43ae91cd36a10be82cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q28_idx28:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 29 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 30/100 (ID: spider_dev_q29_idx29): 'What is the total population of Gelderland district?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc3ff78477d41a9ade9b5cabf05f020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q29_idx29:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 30 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 31/100 (ID: spider_dev_q30_idx30): 'Return the money rank of the player with the greatest earnings.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb11bf8f209b44fcbfc2a5a3df9aace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q30_idx30:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 31 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 32/100 (ID: spider_dev_q31_idx31): 'What are the names of the sections in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51ce848fbc74023833fdbaa12e7ab2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q31_idx31:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 32 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 33/100 (ID: spider_dev_q32_idx32): 'What languages are only used by a single country with a republic government?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982404e2ccb4ada8b6a0926d73f7501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q32_idx32:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 33 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 34/100 (ID: spider_dev_q33_idx33): 'Return the id of the document with the fewest paragraphs.' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa59bc7cbb394ce1a4f4f1df6097885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q33_idx33:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 34 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 35/100 (ID: spider_dev_q34_idx34): 'What are the descriptions for all the math courses?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d4734148d647c284ca773031a06a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q34_idx34:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 35 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 36/100 (ID: spider_dev_q35_idx35): 'Find the first name of students who have both cat and dog pets .' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b310202932f34536824145922d50a606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q35_idx35:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 36 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 37/100 (ID: spider_dev_q36_idx36): 'Find the type and weight of the youngest pet.' (True DB: pets_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3190d4c48e54d9f8f65e051b7b30909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q36_idx36:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 37 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 38/100 (ID: spider_dev_q37_idx37): 'Find the role, street, city and state of the professionals living in a city that contains the substring 'West'.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48386a6a5bb42dc8df5c10a6e23a020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q37_idx37:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 38 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 39/100 (ID: spider_dev_q38_idx38): 'What is the code of airport that has the highest number of flights?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091332c56e744bfa9bf83bf62adf79f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q38_idx38:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 39 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 40/100 (ID: spider_dev_q39_idx39): 'What is the Package Option of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7be94fe40d4587ae599eaf306faa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q39_idx39:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 40 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 41/100 (ID: spider_dev_q40_idx40): 'Tell me the age of the oldest dog.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941e6f938638455d9eaf3e83d0e62210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q40_idx40:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 41 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 42/100 (ID: spider_dev_q41_idx41): 'What are the countries that have greater surface area than any country in Europe?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65aae88abf64de591917e2b9f85ad6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q41_idx41:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 42 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 43/100 (ID: spider_dev_q42_idx42): 'Find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb187021f14d2fa5b63d8c3c72390d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q42_idx42:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 43 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 44/100 (ID: spider_dev_q43_idx43): 'List the names and birth dates of people in ascending alphabetical order of name.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6808da66d7c34f4fbc19bb8e5832d3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q43_idx43:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 44 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 45/100 (ID: spider_dev_q44_idx44): 'How many cities in each district have a population that is above the average population across all cities?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c85a92419a48e2b68887d0d6e7442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q44_idx44:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 45 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 46/100 (ID: spider_dev_q45_idx45): 'Return the nationalities for which there are two or more people.' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7abe25d83544a1ba10a0f2e90f0dc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q45_idx45:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 46 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 47/100 (ID: spider_dev_q46_idx46): 'How many documents do we have?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79d28d7c2614e8d9881fb7dbc104bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q46_idx46:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 47 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 48/100 (ID: spider_dev_q47_idx47): 'Tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d2e19b478f42cbbb420e2c187641d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q47_idx47:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 48 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 49/100 (ID: spider_dev_q48_idx48): 'What are the names and descriptions for all the sections?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51025438a0a4383a19c46b796685e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q48_idx48:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 49 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 50/100 (ID: spider_dev_q49_idx49): 'How many available features are there in total?' (True DB: real_estate_properties)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229906cfaa6049558bd452928cf87cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q49_idx49:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 50 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 51/100 (ID: spider_dev_q50_idx50): 'What are the birth year and citizenship of singers?' (True DB: singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb563a708747d692a3d145b1a3aa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q50_idx50:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 51 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 52/100 (ID: spider_dev_q51_idx51): 'How many matches were played in each year?' (True DB: wta_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77160a26704444ebeadb08f15c9ab85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q51_idx51:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 52 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 53/100 (ID: spider_dev_q52_idx52): 'Which airlines have at least 10 flights?' (True DB: flight_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1c579561354be297cd979df04b634e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q52_idx52:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 53 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 54/100 (ID: spider_dev_q53_idx53): 'What is the name and id of the department with the most number of degrees ?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f79db2c3ed6454d8cbae44411da9b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q53_idx53:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 54 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 55/100 (ID: spider_dev_q54_idx54): 'What are the ids for templates that are not used in any documents?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da14159430234cb7a39ecfeeb0d6943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q54_idx54:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 55 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 56/100 (ID: spider_dev_q55_idx55): 'What is the last transcript release date?' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7a90c9c3e941568df4b9249098a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q55_idx55:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 56 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 57/100 (ID: spider_dev_q56_idx56): 'What are the names of the teachers ordered by ascending age?' (True DB: course_teach)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6496dce80e394af1ba4898bb898ef99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q56_idx56:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 57 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 58/100 (ID: spider_dev_q57_idx57): 'Show the date and id of the transcript with at least 2 course results.' (True DB: student_transcripts_tracking)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9825d73789264f6393b3659e597bd2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q57_idx57:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 58 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 59/100 (ID: spider_dev_q58_idx58): 'What are the names of conductors whose nationalities are not \"USA\"?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49240ea637e4c689ae7996cf4b1fcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q58_idx58:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 59 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 60/100 (ID: spider_dev_q59_idx59): 'What are the names of students who have no friends?' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64352bd2a0e408ab73feadac75ae812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q59_idx59:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 60 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 61/100 (ID: spider_dev_q60_idx60): 'What is the count of the car models produced in the United States?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8b93f70f504ab682b1d55c1e7d90bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q60_idx60:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 61 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 62/100 (ID: spider_dev_q61_idx61): 'What are the names of countries that speak more than 2 languages, as well as how many languages they speak?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3320b00bbc14dc7b70e4cbedd0fbad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q61_idx61:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 62 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 63/100 (ID: spider_dev_q62_idx62): 'Give the name, population, and head of state for the country that has the largest area.' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba218874fd5a4d659beae0a43e167b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q62_idx62:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 63 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 64/100 (ID: spider_dev_q63_idx63): 'How many different results are there for the battles?' (True DB: battle_death)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913e13ae0a0242ab94c4f4dc5bd3b73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q63_idx63:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 64 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 65/100 (ID: spider_dev_q64_idx64): 'What are the names of the countries with no car makers?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7c6fa516e74f92af28819809539c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q64_idx64:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 65 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 66/100 (ID: spider_dev_q65_idx65): 'What is the language that is used by the largest number of Asian nations?' (True DB: world_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a5b7c3f3f24ddfb2a945ee4183544d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q65_idx65:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 66 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 67/100 (ID: spider_dev_q66_idx66): 'Return the record companies of orchestras, sorted descending by the years in which they were founded.' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f980102b5a4aa8b4ee779ac633537b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q66_idx66:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 67 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 68/100 (ID: spider_dev_q67_idx67): 'What are the names of properties that are either houses or apartments with more than 1 room?' (True DB: real_estate_properties)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901852d8d2a843478b7dfc0fc69d3d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q67_idx67:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 68 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 69/100 (ID: spider_dev_q68_idx68): 'find the package option of the tv channel that do not have any cartoon directed by Ben Jones.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3e1abf3226456ea86f41a10e2f71ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q68_idx68:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 69 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 70/100 (ID: spider_dev_q69_idx69): 'List the last name of the owner owning the youngest dog.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5159a6ecbb94f49a31f6c8e348c50c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q69_idx69:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 70 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 71/100 (ID: spider_dev_q70_idx70): 'What is the name and capacity of the stadium with the most concerts after 2013 ?' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683a7d19c0e84f879691cc73c6aa0c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q70_idx70:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 71 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 72/100 (ID: spider_dev_q71_idx71): 'What are the names of conductors who have conducted orchestras founded after the year 2008?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df9e483b714207a1182419c3b59b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q71_idx71:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 72 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 73/100 (ID: spider_dev_q72_idx72): 'How many cars has over 6 cylinders?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e96bbf7f934ffdb6e07c22ff62e2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q72_idx72:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 73 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 74/100 (ID: spider_dev_q73_idx73): 'What is the number of car models that are produced by each maker and what is the id and full name of each maker?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30172f9037514e93b106e009fae62996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q73_idx73:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 74 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 75/100 (ID: spider_dev_q74_idx74): 'What are the names of conductors, sorted descending by the number of years they have worked?' (True DB: orchestra)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bed6e77d5e45f8bdf0d50423253927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q74_idx74:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 75 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 76/100 (ID: spider_dev_q75_idx75): 'What are the distinct template type descriptions for the templates ever used by any document?' (True DB: cre_Doc_Template_Mgt)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882ff2df24854f569c8564cfadf1403b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q75_idx75:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 76 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 77/100 (ID: spider_dev_q76_idx76): 'What are the names of poker players, ordered ascending by the number of final tables they have made?' (True DB: poker_player)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71059eee8e2f4a55a5b27f8fa779f760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q76_idx76:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 77 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 78/100 (ID: spider_dev_q77_idx77): 'What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213c8fdc4faf414fbaed1b5dda6faf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q77_idx77:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 78 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 79/100 (ID: spider_dev_q78_idx78): 'What is the TV Channel of TV series with Episode \"A Love of a Lifetime\"? List the TV Channel's series name.' (True DB: tvshow)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e01854da8274319b5ddf4dc7fcae74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q78_idx78:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 79 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 80/100 (ID: spider_dev_q79_idx79): 'What is the lowest grade of students who do not have any friends?' (True DB: network_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6db40f52978433fa492bbbad9d4d9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q79_idx79:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 80 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 81/100 (ID: spider_dev_q80_idx80): 'Show the name and theme for all concerts and the number of singers in each concert.' (True DB: concert_singer)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cb952db91f48609cf06539cc72d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q80_idx80:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 81 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 82/100 (ID: spider_dev_q81_idx81): 'What is the total ticket expense of the visitors whose membership level is 1?' (True DB: museum_visit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c5b9b948e34400878f8900394aa665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q81_idx81:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 82 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 83/100 (ID: spider_dev_q82_idx82): 'Which professionals have done at least two types of treatments? List the professional id and cell phone.' (True DB: dog_kennels)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb11df8c316b461eb100b09a4bef1343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q82_idx82:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "Warning: Prompt for query was truncated. Length: 2038\n",
      "  Successfully saved intermediate results for 83 queries to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json\n",
      "\n",
      "Processing Query 84/100 (ID: spider_dev_q83_idx83): 'How many countries does each continent have? List the continent id, continent name and the number of countries.' (True DB: car_1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48c1835e49b4f0aa121a6e2332183a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  DBs for Q:spider_dev_q83_idx83:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prompt for query was truncated. Length: 2038\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure these imports are at the top of your script/notebook ---\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "from tqdm.auto import tqdm # Use .auto or .notebook for Jupyter\n",
    "\n",
    "# --- Prerequisites (must be defined and populated from Cell 1 and Cell 2): ---\n",
    "# model, tokenizer, SYSTEM_PROMPT, USER_PROMPT_TEMPLATE,\n",
    "# YES_TOKEN_ID, NO_TOKEN_ID, get_yes_probability,\n",
    "# selected_nl_queries, candidate_schemas_for_evaluation, EXPERIMENT_RESULTS_FILE\n",
    "# --- (Assume these are correctly defined above this cell) ---\n",
    "\n",
    "# --- 3.1. Initialize Results Storage ---\n",
    "experiment_all_query_results = []\n",
    "\n",
    "# --- 3.2. Start the Loop ---\n",
    "# This initial print is fine as it's before any tqdm loops start for this cell's main logic\n",
    "print(f\"\\n--- Starting Experiment: {len(selected_nl_queries)} Random Queries vs. {len(candidate_schemas_for_evaluation)} Total DB Schemas ---\")\n",
    "\n",
    "# Outer loop: Iterate through each randomly selected NL query\n",
    "for query_idx, nl_query_info in enumerate(tqdm(selected_nl_queries, desc=\"Processing NL Queries\")):\n",
    "    current_nl_query_text = nl_query_info['question']\n",
    "    true_db_id_for_query = nl_query_info['db_id']\n",
    "    experiment_query_id = f\"spider_dev_q{query_idx}_{nl_query_info.get('query_id', 'idx'+str(query_idx))}\"\n",
    "\n",
    "    # Use tqdm.write for status updates related to the outer loop's progress\n",
    "    # The '\\n' at the beginning helps separate entries for each query visually.\n",
    "    tqdm.write(f\"\\nProcessing Query {query_idx + 1}/{len(selected_nl_queries)} (ID: {experiment_query_id}): '{current_nl_query_text}' (True DB: {true_db_id_for_query})\")\n",
    "\n",
    "    scores_for_current_query = []\n",
    "\n",
    "    # --- Optional: For debugging, print scores for the VERY FIRST query only ---\n",
    "    # print_debug_scores_for_first_query_only = True\n",
    "    # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "    #     tqdm.write(f\"  --- Incremental Scores for First Query: '{current_nl_query_text}' ---\")\n",
    "    # --- End Optional Debug Print Setup ---\n",
    "\n",
    "    # Inner loop: Iterate through each candidate database schema\n",
    "    for candidate_db_id, candidate_schema_sql in tqdm(\n",
    "        candidate_schemas_for_evaluation.items(),\n",
    "        desc=f\"  DBs for Q:{experiment_query_id[:20]}\", # Description for the inner bar\n",
    "        leave=False  # Inner bar will be removed upon completion of its loop\n",
    "    ):\n",
    "        user_prompt_content = USER_PROMPT_TEMPLATE.format(\n",
    "            schema_string=candidate_schema_sql,\n",
    "            nl_query=current_nl_query_text\n",
    "        )\n",
    "        p_yes_score = -1.0\n",
    "\n",
    "        try:\n",
    "            p_yes_score = get_yes_probability(\n",
    "                model, tokenizer, SYSTEM_PROMPT, user_prompt_content, YES_TOKEN_ID, NO_TOKEN_ID\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Use tqdm.write for error messages occurring inside the inner loop\n",
    "            tqdm.write(f\"    ERROR: Exception in get_yes_probability for Query ID '{experiment_query_id}' with DB '{candidate_db_id}'.\")\n",
    "            tqdm.write(f\"    Exception type: {type(e).__name__}, Message: {e}\")\n",
    "            # if you need full traceback for debugging, tqdm.write(traceback.format_exc()) might work,\n",
    "            # but it can be very verbose. Printing to a log file is better for extensive tracebacks.\n",
    "            # traceback.print_exc() # This will print to stderr and might still mess with tqdm display\n",
    "\n",
    "        scores_for_current_query.append({\n",
    "            'candidate_db_id': candidate_db_id,\n",
    "            'p_yes_score': p_yes_score\n",
    "        })\n",
    "\n",
    "        # --- Optional: For debugging, print scores for the VERY FIRST query only ---\n",
    "        # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "        #     tqdm.write(f\"    DB: {candidate_db_id}, Score: {p_yes_score:.4f}\") # Incremental print with tqdm.write\n",
    "        # --- End Optional Debug Print ---\n",
    "\n",
    "    ranked_databases_for_query = sorted(scores_for_current_query, key=lambda x: x['p_yes_score'], reverse=True)\n",
    "\n",
    "    # --- Optional: For debugging, print sorted scores for the VERY FIRST query only ---\n",
    "    # if print_debug_scores_for_first_query_only and query_idx == 0:\n",
    "    #     tqdm.write(f\"  --- Sorted Ranked Databases for First Query: '{current_nl_query_text}' (Top 10) ---\")\n",
    "    #     for rank_info in ranked_databases_for_query[:10]:\n",
    "    #         tqdm.write(f\"    Ranked DB: {rank_info['candidate_db_id']}, Score: {rank_info['p_yes_score']:.4f}\")\n",
    "    # --- End Optional Debug Print ---\n",
    "\n",
    "    experiment_all_query_results.append({\n",
    "        'experiment_query_id': experiment_query_id,\n",
    "        'nl_query_text': current_nl_query_text,\n",
    "        'true_db_id': true_db_id_for_query,\n",
    "        'ranked_databases_with_scores': ranked_databases_for_query\n",
    "    })\n",
    "\n",
    "    # --- 3.3. Periodic Saving of Results ---\n",
    "    if (query_idx + 1) % 1 == 0 or (query_idx + 1) == len(selected_nl_queries):\n",
    "        try:\n",
    "            with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "                json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "            # Use tqdm.write for save messages that occur between outer loop iterations\n",
    "            tqdm.write(f\"  Successfully saved intermediate results for {len(experiment_all_query_results)} queries to {EXPERIMENT_RESULTS_FILE}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ERROR: Could not save intermediate results: {e}\")\n",
    "\n",
    "# --- 3.4. Experiment Loop Completion ---\n",
    "# These final prints are after all tqdm loops are done, so standard print is fine.\n",
    "print(\"\\n--- Experiment Loop Finished ---\")\n",
    "if experiment_all_query_results:\n",
    "    print(f\"Processed {len(experiment_all_query_results)} queries in total.\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "            json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "        print(f\"Final results comprehensively saved to {EXPERIMENT_RESULTS_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save final results: {e}\")\n",
    "else:\n",
    "    print(\"No results were generated from the experiment. Check logs for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed3a14-354d-4762-a702-1fce12986b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_random_query_all_db_scores.json for evaluation...\n",
      "Successfully loaded 100 results from file.\n",
      "\n",
      "--- Evaluation: Recall@K ---\n",
      "Evaluated on 100 queries.\n",
      "Recall@1: 28.00%\n",
      "Recall@3: 47.00%\n",
      "Recall@5: 56.00%\n",
      "Recall@10: 66.00%\n",
      "Saved evaluation results to 'recall_k_results.json'\n",
      "\n",
      "--- Sample Detailed Query Results (Top 5 Queries) ---\n",
      "\n",
      "Query 1: 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "    1. music_2  (Score: 0.9992)\n",
      "    2. music_4  (Score: 0.9989)\n",
      "    3. music_1  (Score: 0.9987)\n",
      "    4. singer  (Score: 0.9986)\n",
      "    5. company_employee  (Score: 0.9981)\n",
      "\n",
      "Query 2: 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "    1. geo  (Score: 0.9996)\n",
      "    2. roller_coaster  (Score: 0.9994)\n",
      "    3. match_season  (Score: 0.9993)\n",
      "    4. world_1* (Score: 0.9992)\n",
      "    5. city_record  (Score: 0.9989)\n",
      "\n",
      "Query 3: 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "    1. company_employee  (Score: 0.9994)\n",
      "    2. music_2  (Score: 0.9993)\n",
      "    3. body_builder  (Score: 0.9993)\n",
      "    4. gymnast  (Score: 0.9993)\n",
      "    5. poker_player* (Score: 0.9992)\n",
      "\n",
      "Query 4: 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "    1. coffee_shop  (Score: 0.9996)\n",
      "    2. restaurants  (Score: 0.9996)\n",
      "    3. loan_1  (Score: 0.9996)\n",
      "    4. company_1  (Score: 0.9995)\n",
      "    5. company_office  (Score: 0.9994)\n",
      "\n",
      "Query 5: 'How many different nationalities do conductors have?' (True DB: orchestra)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "    1. match_season  (Score: 0.9994)\n",
      "    2. company_employee  (Score: 0.9994)\n",
      "    3. icfp_1  (Score: 0.9994)\n",
      "    4. orchestra* (Score: 0.9993)\n",
      "    5. swimming  (Score: 0.9992)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path where the evaluation summary (Recall@K results) will be saved\n",
    "EVAL_RESULTS_SAVE_PATH = \"recall_k_results.json\"\n",
    "\n",
    "# --- 4.1. Define Recall@K Calculation Function ---\n",
    "def calculate_recall_at_k_metric(all_query_results_list, k_values_list):\n",
    "    \"\"\"\n",
    "    Calculates Recall@K for a list of K values.\n",
    "    Each item in all_query_results_list should be a dictionary with:\n",
    "        'true_db_id': The ground truth database ID for the query.\n",
    "        'ranked_databases_with_scores': A list of {'candidate_db_id': id, 'p_yes_score': score},\n",
    "                                         sorted by score in descending order.\n",
    "    \"\"\"\n",
    "    recall_counts = {k: 0 for k in k_values_list}  # Stores how many times true_db was in top K\n",
    "    total_valid_queries = 0  # Queries for which we have a true_db_id\n",
    "\n",
    "    if not all_query_results_list:\n",
    "        return {k: 0.0 for k in k_values_list}, 0\n",
    "\n",
    "    for query_result in all_query_results_list:\n",
    "        true_db = query_result.get('true_db_id')\n",
    "        ranked_dbs_info = query_result.get('ranked_databases_with_scores')\n",
    "\n",
    "        if true_db is None or ranked_dbs_info is None:\n",
    "            print(f\"Warning: Skipping query result due to missing 'true_db_id' or 'ranked_databases_with_scores': \"\n",
    "                  f\"{query_result.get('experiment_query_id', 'Unknown Query')}\")\n",
    "            continue  # Skip if essential information is missing\n",
    "\n",
    "        total_valid_queries += 1\n",
    "        # Extract just the DB IDs from the ranked list\n",
    "        ranked_db_ids_only = [item['candidate_db_id'] for item in ranked_dbs_info]\n",
    "\n",
    "        for k in k_values_list:\n",
    "            # Get the top K predicted database IDs\n",
    "            top_k_predicted_dbs = ranked_db_ids_only[:k]\n",
    "            if true_db in top_k_predicted_dbs:\n",
    "                recall_counts[k] += 1\n",
    "\n",
    "    # Calculate final recall percentages\n",
    "    recall_percentages = {}\n",
    "    if total_valid_queries > 0:\n",
    "        for k in k_values_list:\n",
    "            recall_percentages[k] = (recall_counts[k] / total_valid_queries) * 100.0  # As percentage\n",
    "    else:\n",
    "        recall_percentages = {k: 0.0 for k in k_values_list}\n",
    "\n",
    "    return recall_percentages, total_valid_queries\n",
    "\n",
    "\n",
    "# --- 4.2. Perform Evaluation ---\n",
    "# Load results if this cell is run in a new session and experiment_all_query_results isn't in memory\n",
    "# (assuming results were saved to EXPERIMENT_RESULTS_FILE)\n",
    "loaded_results_for_eval = None\n",
    "if 'experiment_all_query_results' in globals() and experiment_all_query_results:\n",
    "    print(\"Using in-memory experiment_all_query_results for evaluation.\")\n",
    "    loaded_results_for_eval = experiment_all_query_results\n",
    "elif os.path.exists(EXPERIMENT_RESULTS_FILE):\n",
    "    print(f\"Loading results from {EXPERIMENT_RESULTS_FILE} for evaluation...\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'r') as f_in:\n",
    "            loaded_results_for_eval = json.load(f_in)\n",
    "        print(f\"Successfully loaded {len(loaded_results_for_eval)} results from file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results from file for evaluation: {e}\")\n",
    "else:\n",
    "    print(\"No results available in memory or in the specified results file for evaluation.\")\n",
    "\n",
    "if loaded_results_for_eval:\n",
    "    K_VALUES_TO_EVALUATE = [1, 3, 5, 10]  # Define the K values you care about\n",
    "    recall_scores_map, num_queries_evaluated = calculate_recall_at_k_metric(\n",
    "        loaded_results_for_eval, K_VALUES_TO_EVALUATE\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Evaluation: Recall@K ---\")\n",
    "    print(f\"Evaluated on {num_queries_evaluated} queries.\")\n",
    "    for k_val, recall_val in recall_scores_map.items():\n",
    "        print(f\"Recall@{k_val}: {recall_val:.2f}%\")\n",
    "\n",
    "    # --- 4.2.1. Save evaluation results to a JSON file ---\n",
    "    try:\n",
    "        eval_summary = {\n",
    "            \"num_queries_evaluated\": num_queries_evaluated,\n",
    "            \"recall_scores\": recall_scores_map\n",
    "        }\n",
    "        with open(EVAL_RESULTS_SAVE_PATH, 'w') as fout:\n",
    "            json.dump(eval_summary, fout, indent=2)\n",
    "        print(f\"Saved evaluation results to '{EVAL_RESULTS_SAVE_PATH}'\")\n",
    "    except Exception as save_err:\n",
    "        print(f\"Error saving evaluation results: {save_err}\")\n",
    "\n",
    "    # --- 4.3. Optional: Print Detailed Results for a Few Queries ---\n",
    "    print(\"\\n--- Sample Detailed Query Results (Top 5 Queries) ---\")\n",
    "    for i, res in enumerate(loaded_results_for_eval[:5]):  # Show for first 5 queries\n",
    "        print(f\"\\nQuery {i+1}: '{res.get('nl_query_text', '<no text>')}' (True DB: {res.get('true_db_id')})\")\n",
    "        print(\"  Top Ranked Databases (with P(Yes) scores):\")\n",
    "        for rank, db_info in enumerate(res.get('ranked_databases_with_scores', [])[:5]):  # Show top 5 ranked DBs\n",
    "            is_true_db_char = \"*\" if db_info['candidate_db_id'] == res['true_db_id'] else \" \"\n",
    "            print(f\"    {rank+1}. {db_info['candidate_db_id']}{is_true_db_char} \"\n",
    "                  f\"(Score: {db_info['p_yes_score']:.4f})\")\n",
    "else:\n",
    "    print(\"Cannot perform evaluation as no results were loaded or generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_spider_env)",
   "language": "python",
   "name": "llama_spider_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
