{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68760dd7-f0dc-4eba-abd9-199f3a70cfa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: accelerate in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: bitsandbytes in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: sentencepiece in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: datasets in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: huggingface_hub in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (0.32.3)\n",
      "Requirement already satisfied: tqdm in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: psutil in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: sympy in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: six>=1.5 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate bitsandbytes sentencepiece pandas datasets huggingface_hub tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d449a29-d76c-4f2f-a438-1cc81724339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets version: 8.1.5\n",
      "ipywidgets location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/ipywidgets/__init__.py\n",
      "tqdm version: 4.67.1\n",
      "tqdm location: /raid/infolab/gaurav/Llama_Spider_A100_Project/miniconda3/envs/llama_spider_env/lib/python3.10/site-packages/tqdm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "  import ipywidgets\n",
    "  print(f\"ipywidgets version: {ipywidgets.__version__}\")\n",
    "  print(f\"ipywidgets location: {ipywidgets.__file__}\")\n",
    "\n",
    "  import tqdm\n",
    "  print(f\"tqdm version: {tqdm.__version__}\")\n",
    "  print(f\"tqdm location: {tqdm.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01b81c8-78ad-492d-b6c9-be424482a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm imported successfully from .auto\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f593b66452d44408276a3a1a7b7ab1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minimal Auto Test:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple tqdm .auto loop completed\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(\"tqdm imported successfully from .auto\")\n",
    "my_list = list(range(3))\n",
    "for i in tqdm(my_list, desc=\"Minimal Auto Test\"):\n",
    "    time.sleep(0.2)\n",
    "print(\"Simple tqdm .auto loop completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6015af9-e860-4e27-af56-95091e424a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1206593a-e64c-4fe4-9e07-8dfd5c80d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0\n",
      "CUDA available: True\n",
      "CUDA version PyTorch compiled with: 11.8\n",
      "Number of GPUs available to PyTorch: 8\n",
      "  GPU 0: NVIDIA A100-SXM4-80GB\n",
      "  GPU 1: NVIDIA A100-SXM4-80GB\n",
      "  GPU 2: NVIDIA A100-SXM4-80GB\n",
      "  GPU 3: NVIDIA A100-SXM4-80GB\n",
      "  GPU 4: NVIDIA A100-SXM4-80GB\n",
      "  GPU 5: NVIDIA A100-SXM4-80GB\n",
      "  GPU 6: NVIDIA A100-SXM4-80GB\n",
      "  GPU 7: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version PyTorch compiled with: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs available to PyTorch: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"ERROR: PyTorch cannot see the GPUs! Check installation and CUDA compatibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6c79c7-ffaf-414f-a4a5-e646aadf5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Imports and Initial Configuration Complete ---\n",
      "PyTorch Version: 2.2.0\n",
      "Transformers Version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from huggingface_hub import login\n",
    "import transformers # <--- ADD THIS LINE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# --- Third-party Library Imports ---\n",
    "import torch\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "from huggingface_hub import login # For Hugging Face Hub authentication\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"--- Cell 1: Imports and Initial Configuration Complete ---\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73b2c1e-8370-4b5e-826c-99e53f07c854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c545d664220d4836996dd59d35734786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful or already authenticated.\n",
      "\n",
      "--- Cell 2: Hugging Face Login Attempt Complete ---\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    login() # Will use cached token or prompt if needed\n",
    "    print(\"Hugging Face login successful or already authenticated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Hugging Face login failed: {e}. Ensure you are authenticated to download Llama 2.\")\n",
    "\n",
    "print(\"\\n--- Cell 2: Hugging Face Login Attempt Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82706e9d-a125-4315-ae90-94faee8d6464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Model: meta-llama/Llama-3.1-8B-Instruct\n",
      "BitsAndBytesConfig: load_in_4bit=True, compute_dtype=torch.bfloat16\n",
      "Hugging Face model cache directory set to: /raid/infolab/gaurav/Llama_Spider_A100_Project/experiments_70b_llama/.hf_model_cache_70b\n",
      "\n",
      "--- Cell 3: Model and Prompt Configuration Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Model and Tokenizer Configuration ---\n",
    "import os\n",
    "\n",
    "# 3.1. Specify the Llama 2 70B Chat Model\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "print(f\"Target Model: {MODEL_NAME}\")\n",
    "\n",
    "# 3.2. Configure 4-bit Quantization (essential for 70B, even on A100s for single/few GPU use)\n",
    "# A100s support bfloat16, which is excellent for mixed-precision.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",        # nf4 is a good default\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Use bfloat16 for computation on A100s\n",
    "    bnb_4bit_use_double_quant=True,   # Can save a bit more memory\n",
    ")\n",
    "print(f\"BitsAndBytesConfig: load_in_4bit={bnb_config.load_in_4bit}, compute_dtype={bnb_config.bnb_4bit_compute_dtype}\")\n",
    "\n",
    "# 3.4. Define Cache Directory for Hugging Face downloads (optional, but good for managing large models)\n",
    "# Create it within your project directory on the A100 server.\n",
    "HF_MODEL_CACHE_DIR = os.path.join(os.getcwd(), \".hf_model_cache_70b\") # Assumes current dir is project root\n",
    "os.makedirs(HF_MODEL_CACHE_DIR, exist_ok=True)\n",
    "print(f\"Hugging Face model cache directory set to: {HF_MODEL_CACHE_DIR}\")\n",
    "\n",
    "print(\"\\n--- Cell 3: Model and Prompt Configuration Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ed7286-5629-4780-8c22-736b61519715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta-llama/Llama-3.1-8B-Instruct'}\n"
     ]
    }
   ],
   "source": [
    "print({MODEL_NAME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee56445-c515-496d-8611-12b685e7088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for meta-llama/Llama-3.1-8B-Instruct...\n",
      "Tokenizer pad_token was None, set to eos_token: <|eot_id|> (ID: 128009)\n",
      "Tokenizer loaded successfully.\n",
      "Tokenizer pad token ID: 128009\n",
      "Tokenizer EOS token ID: 128009\n",
      "Tokenizer BOS token ID: 128000\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Tokenizer ---\n",
    "# The tokenizer converts text into numerical IDs that the model understands, and vice-versa.\n",
    "# It's crucial that the tokenizer matches the model it was trained with.\n",
    "print(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    # token=HF_TOKEN # For recent versions of transformers, login() handles global auth.\n",
    "                     # You might need this for older versions or specific configurations.\n",
    "    trust_remote_code=True # Some models require this if they have custom code. Llama 2 generally doesn't, but good to be aware of.\n",
    ")\n",
    "\n",
    "# Llama models often don't have a pad token defined by default.\n",
    "# We set it to the EOS (End Of Sentence) token if it's not present.\n",
    "# This is important for batching inputs of different lengths, though for our P(Yes)\n",
    "# extraction (one prompt at a time), it's less critical but good practice.\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"Tokenizer pad_token was None, set to eos_token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "print(\"Tokenizer loaded successfully.\")\n",
    "print(f\"Tokenizer pad token ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"Tokenizer EOS token ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"Tokenizer BOS token ID: {tokenizer.bos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236b8d9a-adb8-4b8f-9651-8e1501cbb6be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: meta-llama/Llama-3.1-8B-Instruct with 4-bit quantization on GPU 1... This will take significant time and memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8e3b0aed2348eca5ee12c7705d0851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully on GPU 1!\n",
      "Time taken: 11.30 seconds.\n",
      "Model device map: {'': 6}\n",
      "Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\n",
      "\n",
      "--- Cell 5: Llama 3.1 8B Instruct Model Loading Complete ---\n",
      "Model max_position_embeddings: 131072\n",
      "Tokenizer model_max_length: 131072\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME} with 4-bit quantization on GPU 1... This will take significant time and memory...\")\n",
    "model_load_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,       # Apply 4-bit quantization\n",
    "        torch_dtype=torch.bfloat16,           # Use bfloat16 on A100s\n",
    "        device_map={\"\": 6},                   # 🔧 Manually assign everything to GPU 1\n",
    "        trust_remote_code=True,               # Required for some models\n",
    "        cache_dir=HF_MODEL_CACHE_DIR\n",
    "    )\n",
    "    model_load_end_time = time.time()\n",
    "    print(\"\\nModel loaded successfully on GPU 1!\")\n",
    "    print(f\"Time taken: {model_load_end_time - model_load_start_time:.2f} seconds.\")\n",
    "    print(f\"Model device map: {model.hf_device_map}\")  # Should show everything on device 1\n",
    "\n",
    "    # Optional: Clean up memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"Performed memory cleanup (torch.cuda.empty_cache(), gc.collect())\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise RuntimeError(f\"Failed to load model {MODEL_NAME} on GPU 1: {e}. Check VRAM, CUDA setup, and Hugging Face authentication.\")\n",
    "\n",
    "print(\"\\n--- Cell 5: Llama 3.1 8B Instruct Model Loading Complete ---\")\n",
    "\n",
    "print(\"Model max_position_embeddings:\", model.config.max_position_embeddings)\n",
    "print(\"Tokenizer model_max_length:\", tokenizer.model_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14926f95-8929-4625-a7f8-32d505739420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started. Looking for zip file at: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip\n",
      "Zip file found at /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip.\n",
      "Attempting to unzip /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip to /raid/infolab/gaurav/Llama_Spider_A100_Project/...\n",
      "Successfully unzipped files to /raid/infolab/gaurav/Llama_Spider_A100_Project/\n",
      "Contents of /raid/infolab/gaurav/Llama_Spider_A100_Project/:\n",
      "  - experiments_70b_llama\n",
      "  - .gitignore\n",
      "  - backup_to_github.sh\n",
      "  - Miniconda3-latest-Linux-x86_64.sh\n",
      "  - spider_subset_data.zip\n",
      "  - llm_generated_schema_examples.json\n",
      "  - randomQ_allDBs_run1\n",
      "  - .ipynb_checkpoints\n",
      "  - all_queries.txt\n",
      "  - .git\n",
      "  - miniconda3\n",
      "  - 100_queries.txt\n",
      "  - spider_subset_data\n",
      "  - __MACOSX\n",
      "\n",
      "Verifying extracted file paths...\n",
      "SUCCESS: dev.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "SUCCESS: tables.json path is valid: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n",
      "\n",
      "--- Ready to load data ---\n",
      "Path to dev.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/dev.json\n",
      "Path to tables.json: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/tables.json\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "SERVER_ZIP_FILE_PATH = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data.zip'\n",
    "EXTRACTION_DESTINATION_DIR_ON_SERVER = '/raid/infolab/gaurav/Llama_Spider_A100_Project/'\n",
    "\n",
    "DEV_JSON_PATH = None\n",
    "TABLES_JSON_PATH = None\n",
    "\n",
    "def unzip_data(zip_filepath, dest_dir):\n",
    "    \"\"\"\n",
    "    Unzips a zip file to a specified destination directory.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to unzip {zip_filepath} to {dest_dir}...\")\n",
    "    try:\n",
    "        \n",
    "        with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "        print(f\"Successfully unzipped files to {dest_dir}\")\n",
    "\n",
    "        print(f\"Contents of {dest_dir}:\")\n",
    "        for item in os.listdir(dest_dir):\n",
    "            print(f\"  - {item}\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: {zip_filepath} is not a valid zip file or is corrupted.\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Zip file not found at {zip_filepath}. Please ensure the path is correct.\")\n",
    "        return False\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied to write to {dest_dir} or read {zip_filepath}.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during unzipping: {e}\")\n",
    "        return False\n",
    "\n",
    "print(f\"Script started. Looking for zip file at: {SERVER_ZIP_FILE_PATH}\")\n",
    "\n",
    "if os.path.exists(SERVER_ZIP_FILE_PATH):\n",
    "    print(f\"Zip file found at {SERVER_ZIP_FILE_PATH}.\")\n",
    "    if unzip_data(SERVER_ZIP_FILE_PATH, EXTRACTION_DESTINATION_DIR_ON_SERVER):\n",
    "        \n",
    "        EXPECTED_EXTRACTED_FOLDER_NAME = 'spider_subset_data' # This is the folder INSIDE the zip\n",
    "\n",
    "        DEV_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'dev.json')\n",
    "        TABLES_JSON_PATH = os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME, 'tables.json')\n",
    "\n",
    "        print(\"\\nVerifying extracted file paths...\")\n",
    "        if os.path.exists(DEV_JSON_PATH):\n",
    "            print(f\"SUCCESS: dev.json path is valid: {DEV_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: dev.json NOT FOUND at expected path: {DEV_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "\n",
    "        if os.path.exists(TABLES_JSON_PATH):\n",
    "            print(f\"SUCCESS: tables.json path is valid: {TABLES_JSON_PATH}\")\n",
    "        else:\n",
    "            print(f\"ERROR: tables.json NOT FOUND at expected path: {TABLES_JSON_PATH}\")\n",
    "            print(f\"Please check the contents of {os.path.join(EXTRACTION_DESTINATION_DIR_ON_SERVER, EXPECTED_EXTRACTED_FOLDER_NAME)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Unzipping failed on the server. Cannot define data paths.\")\n",
    "else:\n",
    "    print(f\"ERROR: Zip file NOT FOUND at {SERVER_ZIP_FILE_PATH} on the server.\")\n",
    "    print(\"Please ensure the 'scp' command was successful and the path is correct.\")\n",
    "\n",
    "\n",
    "if DEV_JSON_PATH and TABLES_JSON_PATH and os.path.exists(DEV_JSON_PATH) and os.path.exists(TABLES_JSON_PATH):\n",
    "    print(\"\\n--- Ready to load data ---\")\n",
    "    print(f\"Path to dev.json: {DEV_JSON_PATH}\")\n",
    "    print(f\"Path to tables.json: {TABLES_JSON_PATH}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n--- Data paths are not correctly set up. Cannot proceed with data loading. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9436941-4794-4d16-b686-8ab6bcb0e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 queries from dev.json\n",
      "Loaded 166 database schemas from tables.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(f\"ERROR: File not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "dev_data = load_json_data(DEV_JSON_PATH)\n",
    "tables_data = load_json_data(TABLES_JSON_PATH)\n",
    "\n",
    "if dev_data and tables_data:\n",
    "    print(f\"Loaded {len(dev_data)} queries from dev.json\")\n",
    "    print(f\"Loaded {len(tables_data)} database schemas from tables.json\")\n",
    "else:\n",
    "    print(\"Failed to load Spider data. Please check paths and upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00306534-18c4-44d5-a20f-f93696b8eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define data directory and file paths\n",
    "SPIDER_DATA_DIR = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data'\n",
    "spider_tables_json_path = os.path.join(SPIDER_DATA_DIR, 'tables.json')\n",
    "llm_examples_path = os.path.join(SPIDER_DATA_DIR, 'llm_generated_schema_examples.json')\n",
    "\n",
    "# Load the LLM-generated examples map\n",
    "with open(llm_examples_path, 'r') as f:\n",
    "    db_id_to_questions_map = json.load(f)\n",
    "\n",
    "# Load the base schema structures\n",
    "with open(spider_tables_json_path, 'r') as f:\n",
    "    raw_schemas = json.load(f)\n",
    "# Map by database ID for easy lookup\n",
    "all_db_schemas_data_loaded = {db_info['db_id']: db_info for db_info in raw_schemas}\n",
    "\n",
    "# Initialize the container for enriched SQL strings\n",
    "all_db_schemas_sql_strings = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8056449-9e3a-418b-9f29-b5c420fcfc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building CODES-style Prompts (Paper-Exact Column Format) ---\n",
      "Found prerequisites. Generating prompts using databases from: /raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data/database\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f4ba66c6a4a79a8d8f0e0ff843e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating CODES-style prompts:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully generated 166 CODES-style prompts.\n",
      "\n",
      "--- Verification of a CODES-style Prompt (Paper-Exact Format) ---\n",
      "Generated prompt for 'flight_company':\n",
      "table airport, columns = [ airport.id ( integer | primary key | values: 1, 2 ), airport.City ( text | values: Akureyri, Amsterdam ), airport.Country ( text | values: Iceland, Netherlands ), airport.IATA ( text | values: AEY, AMS ), airport.ICAO ( text | values: BIAR, EHAM ), airport.name ( text | values: Akureyri Airport, Schiphol Airport ) ]\n",
      "table operate_company, columns = [ operate_company.id ( integer | primary key | values: 1, 2 ), operate_company.name ( text | values: Air China, Air China Cargo ), operate_company.Type ( text | values: Corporate, Joint Venture ), operate_company.Principal_activities ( text | values: Airline, Cargo airline ), operate_company.Incorporated_in ( text | values: China, Hong Kong ), operate_company.Group_Equity_Shareholding ( real | values: 18.77, 49.0 ) ]\n",
      "table flight, columns = [ flight.id ( integer | primary key | values: 1, 2 ), flight.Vehicle_Flight_number ( text | values: M2-F1 #0, M2-F1 #1 ), flight.Date ( text | values: March 1, 1963, August 16, 1963 ), flight.Pilot ( text | values: Thompson, Peterson ), flight.Velocity ( real | values: 135.0, 240.0 ), flight.Altitude ( real | values: 0.0, 3650.0 ), flight.airport_id ( integer | values: 1, 2 ), flight.company_id ( integer | values: 2, 3 ) ]\n",
      "foreign keys:\n",
      "flight.company_id = operate_company.id\n",
      "flight.airport_id = airport.id\n",
      "\n",
      "/*\n",
      "Example questions for this schema:\n",
      "-- What is the average altitude of flights that departed from airports in the United States?\n",
      "-- What are the names of the pilots who flew flights operated by companies whose name starts with 'A', on Sundays?\n",
      "-- Which airport has the highest number of flights that departed on a Monday?\n",
      "-- What is the velocity of flights that departed from the airport with the IATA code 'LHR', on a day when the temperature was above 0 degrees Celsius?\n",
      "-- How many flights operated by companies with a Group Equity Shareholding greater than 50% have been operated by pilots who are also the principal of the company they work for?\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# --- Integration of CODES Prompt Construction (Section 6 of the Paper) ---\n",
    "\n",
    "from tqdm.auto import tqdm # Ensure tqdm is imported for the progress bar\n",
    "import json\n",
    "import os\n",
    "import sqlite3 # <-- Import the sqlite3 library\n",
    "\n",
    "print(\"--- Building CODES-style Prompts (Paper-Exact Column Format) ---\")\n",
    "\n",
    "# --- Helper Functions for Prompt Construction ---\n",
    "\n",
    "def map_spider_type_to_sql_type(spider_type, is_pk_or_fk=False):\n",
    "    \"\"\"\n",
    "    Converts Spider's abstract data types to more standard SQL types.\n",
    "    \"\"\"\n",
    "    spider_type = spider_type.lower()\n",
    "    if spider_type == \"text\": return \"text\"\n",
    "    if spider_type == \"number\": return \"integer\" if is_pk_or_fk else \"real\"\n",
    "    if spider_type == \"time\": return \"datetime\"\n",
    "    if spider_type == \"boolean\": return \"boolean\"\n",
    "    return \"text\" # Default case\n",
    "\n",
    "def get_representative_values(cursor, table_name, column_name):\n",
    "    \"\"\"Executes a query to get up to 2 representative values for a column.\"\"\"\n",
    "    try:\n",
    "        query = f'SELECT DISTINCT \"{column_name}\" FROM \"{table_name}\" WHERE \"{column_name}\" IS NOT NULL LIMIT 2'\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        values = [str(row[0]) for row in rows]\n",
    "        return \", \".join(values) if values else \"N/A\"\n",
    "    except sqlite3.OperationalError:\n",
    "        return \"N/A\"\n",
    "\n",
    "def schema_filter_placeholder(db_schema):\n",
    "    \"\"\"\n",
    "    Placeholder for the schema filter.\n",
    "    \"\"\"\n",
    "    return db_schema['table_names_original']\n",
    "\n",
    "def value_retriever_placeholder(nl_query, db_id):\n",
    "    \"\"\"\n",
    "    Placeholder for the value retriever.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "def construct_codes_style_prompt(db_id, all_schemas_data, db_id_to_questions_map, db_dir):\n",
    "    \"\"\"\n",
    "    Constructs a database prompt string with the paper-exact column format.\n",
    "    \"\"\"\n",
    "    if db_id not in all_schemas_data:\n",
    "        return f\"-- Database ID '{db_id}' not found.\"\n",
    "\n",
    "    db_path = os.path.join(db_dir, db_id, f\"{db_id}.sqlite\")\n",
    "    if not os.path.exists(db_path):\n",
    "        return f\"-- Database file not found at: {db_path}\"\n",
    "\n",
    "    db_schema = all_schemas_data[db_id]\n",
    "    prompt_parts = []\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        column_info_map = {\n",
    "            i: {\"name\": c_name, \"table_index\": t_idx, \"type\": db_schema['column_types'][i]}\n",
    "            for i, (t_idx, c_name) in enumerate(db_schema['column_names_original']) if c_name != \"*\"\n",
    "        }\n",
    "        \n",
    "        relevant_tables = schema_filter_placeholder(db_schema)\n",
    "\n",
    "        for table_idx, table_name in enumerate(db_schema['table_names_original']):\n",
    "            if table_name not in relevant_tables:\n",
    "                continue\n",
    "\n",
    "            column_defs = []\n",
    "            for col_idx, col_info in column_info_map.items():\n",
    "                if col_info['table_index'] == table_idx:\n",
    "                    \n",
    "                    ### MODIFICATION START: Reformatting the column definition string ###\n",
    "                    \n",
    "                    # 1. Create the prefixed column name (e.g., \"movie.title\")\n",
    "                    prefixed_col_name = f\"{table_name}.{col_info['name']}\"\n",
    "                    \n",
    "                    # 2. Build the list of parts that go INSIDE the parentheses\n",
    "                    col_parts_inside_parentheses = []\n",
    "                    \n",
    "                    # Add data type\n",
    "                    is_pk_or_fk = col_idx in db_schema['primary_keys'] or any(fk[0] == col_idx for fk in db_schema['foreign_keys'])\n",
    "                    col_parts_inside_parentheses.append(map_spider_type_to_sql_type(col_info['type'], is_pk_or_fk))\n",
    "                    \n",
    "                    # Add primary key info\n",
    "                    if col_idx in db_schema['primary_keys']:\n",
    "                        col_parts_inside_parentheses.append(\"primary key\")\n",
    "                    \n",
    "                    # Add comment placeholder to match paper's format\n",
    "                    # col_parts_inside_parentheses.append(\"comment: N/A\")\n",
    "                    \n",
    "                    # Fetch and add representative values\n",
    "                    rep_values = get_representative_values(cursor, table_name, col_info['name'])\n",
    "                    col_parts_inside_parentheses.append(f\"values: {rep_values}\")\n",
    "                    \n",
    "                    # 3. Assemble the final string in the new, correct format\n",
    "                    final_column_string = f\"{prefixed_col_name} ( { ' | '.join(col_parts_inside_parentheses)} )\"\n",
    "                    column_defs.append(final_column_string)\n",
    "\n",
    "                    ### MODIFICATION END ###\n",
    "            \n",
    "            prompt_parts.append(f\"table {table_name}, columns = [ {', '.join(column_defs)} ]\")\n",
    "\n",
    "        # --- Foreign Key Information (no change needed here) ---\n",
    "        if db_schema['foreign_keys']:\n",
    "            prompt_parts.append(\"foreign keys:\")\n",
    "            table_info_map = {i: name for i, name in enumerate(db_schema['table_names_original'])}\n",
    "            for fk_col_idx, ref_col_idx in db_schema['foreign_keys']:\n",
    "                fk_table_name = table_info_map[column_info_map[fk_col_idx]['table_index']]\n",
    "                fk_col_name = column_info_map[fk_col_idx]['name']\n",
    "                ref_table_name = table_info_map[column_info_map[ref_col_idx]['table_index']]\n",
    "                ref_col_name = column_info_map[ref_col_idx]['name']\n",
    "                prompt_parts.append(f\"{fk_table_name}.{fk_col_name} = {ref_table_name}.{ref_col_name}\")\n",
    "\n",
    "        # --- Matched Values (no change needed here) ---\n",
    "        matched_values = value_retriever_placeholder(\"some query\", db_id)\n",
    "        if matched_values:\n",
    "            prompt_parts.append(\"matched values:\")\n",
    "            for table_col, value in matched_values.items():\n",
    "                prompt_parts.append(f\"{table_col} ({value})\")\n",
    "\n",
    "        # --- Append LLM-generated examples (no change needed here) ---\n",
    "        example_questions = db_id_to_questions_map.get(db_id, [])\n",
    "        if example_questions:\n",
    "            examples_string = \"\\n\".join([f\"-- {q}\" for q in example_questions])\n",
    "            final_comment = f\"\\n/*\\nExample questions for this schema:\\n{examples_string}\\n*/\"\n",
    "            prompt_parts.append(final_comment)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing db '{db_id}': {e}\")\n",
    "        return f\"-- Error generating prompt for db {db_id}.\"\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "# --- Generate the new prompts for all databases ---\n",
    "\n",
    "# Define the path to your database directory. UPDATE THIS IF NEEDED.\n",
    "SPIDER_DATA_DIR = '/raid/infolab/gaurav/Llama_Spider_A100_Project/spider_subset_data' # Assuming you unzipped spider.zip here\n",
    "DATABASE_DIR = os.path.join(SPIDER_DATA_DIR, 'database')\n",
    "\n",
    "all_db_schemas_codes_style_prompts = {}\n",
    "# Make sure the prerequisite data from your notebook is loaded\n",
    "if 'all_db_schemas_data_loaded' in globals() and all_db_schemas_data_loaded and \\\n",
    "   'db_id_to_questions_map' in globals() and db_id_to_questions_map:\n",
    "    \n",
    "    print(f\"Found prerequisites. Generating prompts using databases from: {DATABASE_DIR}\")\n",
    "    for db_id in tqdm(all_db_schemas_data_loaded.keys(), desc=\"Generating CODES-style prompts\"):\n",
    "        # Pass the DATABASE_DIR to the function\n",
    "        all_db_schemas_codes_style_prompts[db_id] = construct_codes_style_prompt(\n",
    "            db_id, all_db_schemas_data_loaded, db_id_to_questions_map, DATABASE_DIR\n",
    "        )\n",
    "    print(f\"\\nSuccessfully generated {len(all_db_schemas_codes_style_prompts)} CODES-style prompts.\")\n",
    "    \n",
    "    # --- Verification Step ---\n",
    "    print(\"\\n--- Verification of a CODES-style Prompt (Paper-Exact Format) ---\")\n",
    "    db_to_verify = 'flight_company'\n",
    "    if db_to_verify in all_db_schemas_codes_style_prompts:\n",
    "        print(f\"Generated prompt for '{db_to_verify}':\")\n",
    "        print(all_db_schemas_codes_style_prompts[db_to_verify])\n",
    "    else:\n",
    "        print(f\"Could not find schema for '{db_to_verify}' to verify.\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Prerequisite data ('all_db_schemas_data_loaded' or 'db_id_to_questions_map') not found. Please run the previous cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca38b07-cca2-42a7-91f8-72770d2cce7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 queries from '/raid/infolab/gaurav/Llama_Spider_A100_Project/all_queries.txt':\n",
      "  Query 1: 'Show the property type descriptions of properties belonging to that code.' (True DB: real_estate_properties)\n",
      "  Query 2: 'What are the name of the countries where there is not a single car maker?' (True DB: car_1)\n",
      "  Query 3: 'What are the date and the operating professional's first name of each treatment?' (True DB: dog_kennels)\n",
      "  Query 4: 'List each owner's first name, last name, and the size of his for her dog.' (True DB: dog_kennels)\n",
      "  Query 5: 'Find the first name and age of students who have a dog but do not have a cat as a pet.' (True DB: pets_1)\n",
      "  Query 6: 'What is the number of cars with a greater accelerate than the one with the most horsepower?' (True DB: car_1)\n",
      "  Query 7: 'What are the names of the teachers who are aged either 32 or 33?' (True DB: course_teach)\n",
      "  Query 8: 'Return the maximum final tables made across all poker players who have earnings below 200000.' (True DB: poker_player)\n",
      "  Query 9: 'Show template ids, version numbers, and template type codes for all templates.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 10: 'What is the most common nationality of people?' (True DB: poker_player)\n",
      "  Query 11: 'find the pixel aspect ratio and nation of the tv channels that do not use English.' (True DB: tvshow)\n",
      "  Query 12: 'What is the template type code of the template used by document with the name \"Data base\"?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 13: 'What is the maker of the carr produced in the earliest year and what year was it?' (True DB: car_1)\n",
      "  Query 14: 'Count the number of high schoolers.' (True DB: network_1)\n",
      "  Query 15: 'Find the average life expectancy and total population for each continent where the average life expectancy is shorter than 72?' (True DB: world_1)\n",
      "  Query 16: 'List the date of each treatment, together with the first name of the professional who operated it.' (True DB: dog_kennels)\n",
      "  Query 17: 'Show all template ids and number of documents using each template.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 18: 'Who is the first student to register? List the first name, middle name and last name.' (True DB: student_transcripts_tracking)\n",
      "  Query 19: 'Show the name of the teacher for the math course.' (True DB: course_teach)\n",
      "  Query 20: 'Find the id and name of the museum that has the most staff members?' (True DB: museum_visit)\n",
      "  Query 21: 'What are flight numbers of flights departing from Airport \"APG\"?' (True DB: flight_2)\n",
      "  Query 22: 'What are the names of poker players in descending order of earnings?' (True DB: poker_player)\n",
      "  Query 23: 'What is the average earnings of poker players?' (True DB: poker_player)\n",
      "  Query 24: 'Which year had the most matches?' (True DB: wta_1)\n",
      "  Query 25: 'Find the names of stores whose number products is more than the average number of products.' (True DB: employee_hire_evaluation)\n",
      "  Query 26: 'What is the money rank of the tallest poker player?' (True DB: poker_player)\n",
      "  Query 27: 'What is the document id with least number of paragraphs?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 28: 'How many cars have a larger accelerate than the car with the largest horsepower?' (True DB: car_1)\n",
      "  Query 29: 'What is the program id and the summary of the degree that has the most students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 30: 'What is the number of nations that use English and Dutch?' (True DB: world_1)\n",
      "  Query 31: 'What is the document id, template id and description for document named \"Robbin CV\"?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 32: 'What are the codes of countries where Spanish is spoken by the largest percentage of people?' (True DB: world_1)\n",
      "  Query 33: 'What is the last name of the student who has a cat that is 3 years old?' (True DB: pets_1)\n",
      "  Query 34: 'What are the first name and last name of the professionals who have done treatment with cost below average?' (True DB: dog_kennels)\n",
      "  Query 35: 'What is average life expectancy in the countries where English is not the official language?' (True DB: world_1)\n",
      "  Query 36: 'What is the average weight of cars each year?' (True DB: car_1)\n",
      "  Query 37: 'Find the first name and age of students who have a pet.' (True DB: pets_1)\n",
      "  Query 38: 'List all singer names in concerts in year 2014.' (True DB: concert_singer)\n",
      "  Query 39: 'Return the names of cities that have a population between 160000 and 900000 .' (True DB: world_1)\n",
      "  Query 40: 'Which city and country is the Alton airport at?' (True DB: flight_2)\n",
      "  Query 41: 'find the names of museums which have more staff than the minimum staff number of all museums opened after 2010.' (True DB: museum_visit)\n",
      "  Query 42: 'Tell me the age of the oldest dog.' (True DB: dog_kennels)\n",
      "  Query 43: 'How many orchestras does each record company manage?' (True DB: orchestra)\n",
      "  Query 44: 'Which distinctive models are produced by maker with the full name General Motors or weighing more than 3500?' (True DB: car_1)\n",
      "  Query 45: 'What are the names of players who won in both 2013 and 2016?' (True DB: wta_1)\n",
      "  Query 46: 'Give the flight numbers of flights leaving from APG.' (True DB: flight_2)\n",
      "  Query 47: 'What is the average edispl for all volvos?' (True DB: car_1)\n",
      "  Query 48: 'Show the names of conductors and the orchestras they have conducted.' (True DB: orchestra)\n",
      "  Query 49: 'What is the average and maximum age for each pet type?' (True DB: pets_1)\n",
      "  Query 50: 'What are the death and injury situations caused by the ship with tonnage 't'?' (True DB: battle_death)\n",
      "  Query 51: 'List the arrival date and the departure date for all the dogs.' (True DB: dog_kennels)\n",
      "  Query 52: 'What is the average age of all the dogs?' (True DB: dog_kennels)\n",
      "  Query 53: 'What are years of founding for orchestras that have had more than a single performance?' (True DB: orchestra)\n",
      "  Query 54: 'Find the number of pets whose weight is heavier than 10.' (True DB: pets_1)\n",
      "  Query 55: 'List the email, cell phone and home phone of all the professionals.' (True DB: dog_kennels)\n",
      "  Query 56: 'What are all different template ids used for documents, and how many times were each of them used?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 57: 'What are the regions that use English or Dutch?' (True DB: world_1)\n",
      "  Query 58: 'Return the different descriptions for templates that have been used in a document.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 59: 'List pairs of the owner's first name and the dogs's name.' (True DB: dog_kennels)\n",
      "  Query 60: 'What is the number of cartoones written by Joseph Kuhr?' (True DB: tvshow)\n",
      "  Query 61: 'List the names of conductors in ascending order of age.' (True DB: orchestra)\n",
      "  Query 62: 'Find the first name and gender of student who have more than one pet.' (True DB: pets_1)\n",
      "  Query 63: 'Show the names of students who have a grade higher than 5 and have at least 2 friends.' (True DB: network_1)\n",
      "  Query 64: 'Count the number of distinct store locations.' (True DB: employee_hire_evaluation)\n",
      "  Query 65: 'What is the code of airport that has the highest number of flights?' (True DB: flight_2)\n",
      "  Query 66: 'What is the name of the series that has the episode \"A Love of a Lifetime\"?' (True DB: tvshow)\n",
      "  Query 67: 'Show the names of singers and the total sales of their songs.' (True DB: singer)\n",
      "  Query 68: 'Find the number of orchestras whose record format is \"CD\" or \"DVD\".' (True DB: orchestra)\n",
      "  Query 69: 'How many poker players are there?' (True DB: poker_player)\n",
      "  Query 70: 'How many matches were played in each year?' (True DB: wta_1)\n",
      "  Query 71: 'Find the first names of owners living in Virginia and the names of dogs they own.' (True DB: dog_kennels)\n",
      "  Query 72: 'Show paragraph details for paragraph with text 'Korea ' .' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 73: 'Count the number of friends Kyle has.' (True DB: network_1)\n",
      "  Query 74: 'What are the ids and names of all countries that either have more than 3 car makers or produce fiat model ?' (True DB: car_1)\n",
      "  Query 75: 'Return the names of the 3 countries with the fewest people.' (True DB: world_1)\n",
      "  Query 76: 'What are the name, population, and life expectancy of the largest Asian country by land?' (True DB: world_1)\n",
      "  Query 77: 'Which country has the most of TV Channels? List the country and number of TV Channels it has.' (True DB: tvshow)\n",
      "  Query 78: 'Find the type and weight of the youngest pet.' (True DB: pets_1)\n",
      "  Query 79: 'What are the country codes for countries that do not speak English?' (True DB: world_1)\n",
      "  Query 80: 'What are the airline names and abbreviations for airlines in the USA?' (True DB: flight_2)\n",
      "  Query 81: 'Which are the car makers which produce at least 2 models and more than 3 car makers ? List the id and the maker .' (True DB: car_1)\n",
      "  Query 82: 'How many matches were played in 2013 or 2016?' (True DB: wta_1)\n",
      "  Query 83: 'Show all template type codes and the number of documents using each type.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 84: 'Find the make and production time of the cars that were produced in the earliest year?' (True DB: car_1)\n",
      "  Query 85: 'How many cartoons were written by \"Joseph Kuhr\"?' (True DB: tvshow)\n",
      "  Query 86: 'What are the names of countries that speak more than 2 languages, as well as how many languages they speak?' (True DB: world_1)\n",
      "  Query 87: 'Give me all the information about hiring.' (True DB: employee_hire_evaluation)\n",
      "  Query 88: 'Find the average age of students who do not have any pet .' (True DB: pets_1)\n",
      "  Query 89: 'What are the names of conductors who have conducted orchestras founded after the year 2008?' (True DB: orchestra)\n",
      "  Query 90: 'How many car models are produced by each maker ? Only list the count and the maker full name .' (True DB: car_1)\n",
      "  Query 91: 'Find the year that has the most number of matches.' (True DB: wta_1)\n",
      "  Query 92: 'What are the different models created by either the car maker General Motors or weighed more than 3500?' (True DB: car_1)\n",
      "  Query 93: 'What are the names and release years for all the songs of the youngest singer?' (True DB: concert_singer)\n",
      "  Query 94: 'Find the id of students who do not have a cat pet.' (True DB: pets_1)\n",
      "  Query 95: 'List the title of all  Cartoons showed on TV Channel with series name \"Sky Radio\".' (True DB: tvshow)\n",
      "  Query 96: 'Return the id and type code of the template that is used for the greatest number of documents.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 97: 'Return the different names of cities that are in Asia and for which Chinese is the official language.' (True DB: world_1)\n",
      "  Query 98: 'List all document ids with at least two paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 99: 'Which address holds the most number of students currently? List the address id and all lines.' (True DB: student_transcripts_tracking)\n",
      "  Query 100: 'Show ids for all templates not used by any document.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 101: 'List the vote ids, phone numbers and states of all votes.' (True DB: voter_1)\n",
      "  Query 102: 'Show the stadium names without any concert.' (True DB: concert_singer)\n",
      "  Query 103: 'find the id, name and age for visitors who visited some museums more than once.' (True DB: museum_visit)\n",
      "  Query 104: 'Show the document id with paragraph text 'Brazil' and 'Ireland'.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 105: 'Which shops' number products is above the average? Give me the shop names.' (True DB: employee_hire_evaluation)\n",
      "  Query 106: 'What is the zip code of the address in the city Port Chelsea?' (True DB: student_transcripts_tracking)\n",
      "  Query 107: 'List the title of all cartoon directed by \"Ben Jones\" or \"Brandon Vietti\".' (True DB: tvshow)\n",
      "  Query 108: 'What are the template ids of any templates used in more than a single document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 109: 'What are the names and ranks of the three youngest winners across all matches?' (True DB: wta_1)\n",
      "  Query 110: 'Give the nationality that is most common across all people.' (True DB: poker_player)\n",
      "  Query 111: 'What is the name and capacity for the stadium with the highest average attendance?' (True DB: concert_singer)\n",
      "  Query 112: 'What is the total surface area of the continents Asia and Europe?' (True DB: world_1)\n",
      "  Query 113: 'What are the first names and country codes for players who won both the WTA Championships and the Australian Open?' (True DB: wta_1)\n",
      "  Query 114: 'Give me the id, role and email of the professionals who did not perform any treatment on dogs.' (True DB: dog_kennels)\n",
      "  Query 115: 'What is the average life expectancy in African countries that are republics?' (True DB: world_1)\n",
      "  Query 116: 'What is the name of country that has the shortest life expectancy in Asia?' (True DB: world_1)\n",
      "  Query 117: 'What are the ids of the students who do not own cats as pets?' (True DB: pets_1)\n",
      "  Query 118: 'What is the semester which most student registered in? Show both the name and the id.' (True DB: student_transcripts_tracking)\n",
      "  Query 119: 'What is the name of the conductor who has worked the greatest number of years?' (True DB: orchestra)\n",
      "  Query 120: 'List each language and the number of TV Channels using it.' (True DB: tvshow)\n",
      "  Query 121: 'Return the type code of the template type with the description \"Book\".' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 122: 'How many singers are from each country?' (True DB: concert_singer)\n",
      "  Query 123: 'What are the birth years and citizenships of the singers?' (True DB: singer)\n",
      "  Query 124: 'List the Episode of all  TV series showed on TV Channel with series name \"Sky Radio\".' (True DB: tvshow)\n",
      "  Query 125: 'What is the code of the country with the most players?' (True DB: wta_1)\n",
      "  Query 126: 'Which year has most number of concerts?' (True DB: concert_singer)\n",
      "  Query 127: 'Return the lowest version number, along with its corresponding template type code.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 128: 'What is the number of continents?' (True DB: car_1)\n",
      "  Query 129: 'What is the charge amount of the most expensive charge type?' (True DB: dog_kennels)\n",
      "  Query 130: 'What are the different models for the cards produced after 1980?' (True DB: car_1)\n",
      "  Query 131: 'List top 3 highest Rating  TV series. List the TV series's Episode and Rating.' (True DB: tvshow)\n",
      "  Query 132: 'What are the names and areas of countries with the top 5 largest area?' (True DB: world_1)\n",
      "  Query 133: 'How many owners temporarily do not have any dogs?' (True DB: dog_kennels)\n",
      "  Query 134: 'Compute the average age of all the dogs.' (True DB: dog_kennels)\n",
      "  Query 135: 'Show names for all stadiums except for stadiums having a concert in year 2014.' (True DB: concert_singer)\n",
      "  Query 136: 'What is the TV Channel of TV series with Episode \"A Love of a Lifetime\"? List the TV Channel's series name.' (True DB: tvshow)\n",
      "  Query 137: 'What are the minimum and maximum number of products across all the shops?' (True DB: employee_hire_evaluation)\n",
      "  Query 138: 'what are all the addresses including line 1 and line 2?' (True DB: student_transcripts_tracking)\n",
      "  Query 139: 'What are the names and ids of all countries with at least one car maker?' (True DB: car_1)\n",
      "  Query 140: 'Find the average and maximum age for each type of pet.' (True DB: pets_1)\n",
      "  Query 141: 'What is the sname of every sing that does not have any song?' (True DB: singer)\n",
      "  Query 142: 'What are the names of all courses that have some students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 143: 'Please show the most common citizenship of singers.' (True DB: singer)\n",
      "  Query 144: 'List the name of teachers whose hometown is not `` Little Lever Urban District '' .' (True DB: course_teach)\n",
      "  Query 145: 'How many courses in total are listed?' (True DB: student_transcripts_tracking)\n",
      "  Query 146: 'Find the production code and channel of the most recently aired cartoon .' (True DB: tvshow)\n",
      "  Query 147: 'Which country does Airline \"JetBlue Airways\" belong to?' (True DB: flight_2)\n",
      "  Query 148: 'What is the number of the cars with horsepower more than 150?' (True DB: car_1)\n",
      "  Query 149: 'Show all distinct template type codes for all templates.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 150: 'List the number of different series names and contents in the TV Channel table.' (True DB: tvshow)\n",
      "  Query 151: 'How many museums were opened after 2013 or before 2008?' (True DB: museum_visit)\n",
      "  Query 152: 'Return the template type description of the template type with the code AD.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 153: 'On average, when were the transcripts printed?' (True DB: student_transcripts_tracking)\n",
      "  Query 154: 'List the record company shared by the most number of orchestras.' (True DB: orchestra)\n",
      "  Query 155: 'List the names of employees and sort in ascending order of age.' (True DB: employee_hire_evaluation)\n",
      "  Query 156: 'How many dog pets are raised by female students?' (True DB: pets_1)\n",
      "  Query 157: 'What is the number of car models created by the car maker American Motor Company?' (True DB: car_1)\n",
      "  Query 158: 'Return the names and template ids for documents that contain the letter w in their description.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 159: 'Which template type code is used by most number of documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 160: 'For model volvo, how many cylinders does the car with the least accelerate have?' (True DB: car_1)\n",
      "  Query 161: 'For students who have pets , how many pets does each student have ? list their ids instead of names .' (True DB: pets_1)\n",
      "  Query 162: 'Which student has enrolled for the most times in any program? List the id, first name, middle name, last name, the number of enrollments and student id.' (True DB: student_transcripts_tracking)\n",
      "  Query 163: 'List the area codes in which voters voted both for the contestant 'Tabatha Gehling' and the contestant 'Kelly Clauss'.' (True DB: voter_1)\n",
      "  Query 164: 'Give the airline with abbreviation 'UAL'.' (True DB: flight_2)\n",
      "  Query 165: 'Describe the section h.' (True DB: student_transcripts_tracking)\n",
      "  Query 166: 'Find the number of professionals who have ever treated dogs.' (True DB: dog_kennels)\n",
      "  Query 167: 'How many available features are there in total?' (True DB: real_estate_properties)\n",
      "  Query 168: 'What is the number of carsw ith over 6 cylinders?' (True DB: car_1)\n",
      "  Query 169: 'List the name and tonnage ordered by in descending alphaetical order for the names.' (True DB: battle_death)\n",
      "  Query 170: 'List the names of the dogs of the rarest breed and the treatment dates of them.' (True DB: dog_kennels)\n",
      "  Query 171: 'How many high schoolers are there?' (True DB: network_1)\n",
      "  Query 172: 'What is the average grade of students who have friends?' (True DB: network_1)\n",
      "  Query 173: 'How much does each charge type costs? List both charge type and amount.' (True DB: dog_kennels)\n",
      "  Query 174: 'What is the average age for all students who do not own any pets ?' (True DB: pets_1)\n",
      "  Query 175: 'How many conductors are there?' (True DB: orchestra)\n",
      "  Query 176: 'Find the highest rank of losers in all matches.' (True DB: wta_1)\n",
      "  Query 177: 'Show the student IDs and numbers of friends corresponding to each.' (True DB: network_1)\n",
      "  Query 178: 'What is the model of the car with the smallest amount of horsepower?' (True DB: car_1)\n",
      "  Query 179: 'Which regions speak Dutch or English?' (True DB: world_1)\n",
      "  Query 180: 'What are the citizenships that are shared by singers with a birth year before 1945 and after 1955?' (True DB: singer)\n",
      "  Query 181: 'Return the number of flights departing from Aberdeen.' (True DB: flight_2)\n",
      "  Query 182: 'How many concerts are there in year 2014 or 2015?' (True DB: concert_singer)\n",
      "  Query 183: 'Return the number of flights.' (True DB: flight_2)\n",
      "  Query 184: 'What are each owner's first name, last name, and the size of their dog?' (True DB: dog_kennels)\n",
      "  Query 185: 'What is the id and weight of every pet who is older than 1?' (True DB: pets_1)\n",
      "  Query 186: 'Show the names of high school students and their corresponding number of friends.' (True DB: network_1)\n",
      "  Query 187: 'What are the names of all cartoons directed by Ben Jones?' (True DB: tvshow)\n",
      "  Query 188: 'find the names of loser and winner who played in the match with greatest number of minutes.' (True DB: wta_1)\n",
      "  Query 189: 'What are the names and ids of every course with less than 2 sections?' (True DB: student_transcripts_tracking)\n",
      "  Query 190: 'Find the average age of losers and winners of all matches.' (True DB: wta_1)\n",
      "  Query 191: 'Show the names of singers that have more than one song.' (True DB: singer)\n",
      "  Query 192: 'Which semesters do not have any student enrolled? List the semester name.' (True DB: student_transcripts_tracking)\n",
      "  Query 193: 'What are the names of documents that use templates with the code BK?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 194: 'Show the name of teachers aged either 32 or 33?' (True DB: course_teach)\n",
      "  Query 195: 'List the number of all matches who played in years of 2013 or 2016.' (True DB: wta_1)\n",
      "  Query 196: 'Find the first name of students who have cat or dog pet.' (True DB: pets_1)\n",
      "  Query 197: 'Show all template type codes and number of templates for each.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 198: 'What are the titles of the cartoons sorted alphabetically?' (True DB: tvshow)\n",
      "  Query 199: 'What is the name of the conductor who has conducted the most orchestras?' (True DB: orchestra)\n",
      "  Query 200: 'What is the name of the shop that is hiring the largest number of employees?' (True DB: employee_hire_evaluation)\n",
      "  Query 201: 'Show all the grades of the high schoolers.' (True DB: network_1)\n",
      "  Query 202: 'What is the number of distinct continents where Chinese is spoken?' (True DB: world_1)\n",
      "  Query 203: 'What is Weekly Rank of TV series with Episode \"A Love of a Lifetime\"?' (True DB: tvshow)\n",
      "  Query 204: 'Find the name of the makers that produced some cars in the year of 1970?' (True DB: car_1)\n",
      "  Query 205: 'What are the contestant numbers and names of the contestants who had at least two votes?' (True DB: voter_1)\n",
      "  Query 206: 'For each shop, return the number of employees working there and the name of the shop.' (True DB: employee_hire_evaluation)\n",
      "  Query 207: 'What are the ids, names, and descriptions for all documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 208: 'What is the most common singer citizenship ?' (True DB: singer)\n",
      "  Query 209: 'List the names and birth dates of people in ascending alphabetical order of name.' (True DB: poker_player)\n",
      "  Query 210: 'Find the id, last name and cell phone of the professionals who live in the state of Indiana or have performed more than two treatments.' (True DB: dog_kennels)\n",
      "  Query 211: 'Return the money rank of the player with the greatest earnings.' (True DB: poker_player)\n",
      "  Query 212: 'Which makers designed more than 3 car models? List full name and the id.' (True DB: car_1)\n",
      "  Query 213: 'Which continent speaks the most languages?' (True DB: world_1)\n",
      "  Query 214: 'What is the average number of injuries caused each time?' (True DB: battle_death)\n",
      "  Query 215: 'What are the different template type codes?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 216: 'Find the name of the employee who got the highest one time bonus.' (True DB: employee_hire_evaluation)\n",
      "  Query 217: 'What is the id and type code for the template used by the most documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 218: 'Find the major and age of students who do not have a cat pet.' (True DB: pets_1)\n",
      "  Query 219: 'Find the name of airports which do not have any flight in and out.' (True DB: flight_2)\n",
      "  Query 220: 'Count the number of dogs that went through a treatment.' (True DB: dog_kennels)\n",
      "  Query 221: 'How many airlines do we have?' (True DB: flight_2)\n",
      "  Query 222: 'What is the continent name which Anguilla belongs to?' (True DB: world_1)\n",
      "  Query 223: 'What is the number of car models that are produced by each maker and what is the id and full name of each maker?' (True DB: car_1)\n",
      "  Query 224: 'Show me the cost of the most recently performed treatment.' (True DB: dog_kennels)\n",
      "  Query 225: 'How many TV Channel using language English?' (True DB: tvshow)\n",
      "  Query 226: 'Show the citizenship shared by singers with birth year before 1945 and after 1955.' (True DB: singer)\n",
      "  Query 227: 'What are the names and id of courses having at most 2 sections?' (True DB: student_transcripts_tracking)\n",
      "  Query 228: 'What are names of countries with the top 3 largest population?' (True DB: world_1)\n",
      "  Query 229: 'List the first name and birth date of all players from the country with code USA.' (True DB: wta_1)\n",
      "  Query 230: 'What are the names of the singers and number of concerts for each person?' (True DB: concert_singer)\n",
      "  Query 231: 'Find the states where both owners and professionals live.' (True DB: dog_kennels)\n",
      "  Query 232: 'What is the name of the visitor who visited both a museum opened before 2009 and a museum opened after 2011?' (True DB: museum_visit)\n",
      "  Query 233: 'What are airport names at City 'Aberdeen'?' (True DB: flight_2)\n",
      "  Query 234: 'What are all the makers and models?' (True DB: car_1)\n",
      "  Query 235: 'What is the maximum number of times that a course shows up in different transcripts and what is that course's enrollment id?' (True DB: student_transcripts_tracking)\n",
      "  Query 236: 'List document IDs, document names, and document descriptions for all documents.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 237: 'What are the names of high schoolers who have a grade of over 5 and have 2 or more friends?' (True DB: network_1)\n",
      "  Query 238: 'What is the number of employees from each city?' (True DB: employee_hire_evaluation)\n",
      "  Query 239: 'List names of conductors in descending order of years of work.' (True DB: orchestra)\n",
      "  Query 240: 'How many 'United Airlines' flights depart from Airport 'AHD'?' (True DB: flight_2)\n",
      "  Query 241: 'Which airlines have departing flights from both APG and CVO airports?' (True DB: flight_2)\n",
      "  Query 242: 'How many shops are there in each location?' (True DB: employee_hire_evaluation)\n",
      "  Query 243: 'What are the names , themes , and number of singers for every concert ?' (True DB: concert_singer)\n",
      "  Query 244: 'Of all the contestants who got voted, what is the contestant number and name of the contestant who got least votes?' (True DB: voter_1)\n",
      "  Query 245: 'What is the date and id of the transcript with at least 2 courses listed?' (True DB: student_transcripts_tracking)\n",
      "  Query 246: 'Give the names of nations that speak both English and French.' (True DB: world_1)\n",
      "  Query 247: 'Count the number of countries in Asia.' (True DB: world_1)\n",
      "  Query 248: 'Find all airlines that have flights from both airports 'APG' and 'CVO'.' (True DB: flight_2)\n",
      "  Query 249: 'Find the abbreviation and country of the airline that has fewest number of flights?' (True DB: flight_2)\n",
      "  Query 250: 'Show the hometowns shared by at least two teachers.' (True DB: course_teach)\n",
      "  Query 251: 'What are the details for the paragraph that includes the text 'Korea ' ?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 252: 'Count the number of likes for each student id.' (True DB: network_1)\n",
      "  Query 253: 'What are the African countries that have a  population less than any country in Asia?' (True DB: world_1)\n",
      "  Query 254: 'Tell me the number of dogs that have not received any treatment .' (True DB: dog_kennels)\n",
      "  Query 255: 'Count the number of countries for which Spanish is the predominantly spoken language.' (True DB: world_1)\n",
      "  Query 256: 'Which professionals have done at least two types of treatments? List the professional id and cell phone.' (True DB: dog_kennels)\n",
      "  Query 257: 'Which grade has the most high schoolers?' (True DB: network_1)\n",
      "  Query 258: 'What are the Package Options of the TV Channels whose series names are Sky Radio?' (True DB: tvshow)\n",
      "  Query 259: 'What is the name of each teacher and what course they teach?' (True DB: course_teach)\n",
      "  Query 260: 'What is the language spoken by the largest percentage of people in each country?' (True DB: world_1)\n",
      "  Query 261: 'What are the names of the winner and loser who played in the longest match?' (True DB: wta_1)\n",
      "  Query 262: 'Count the number of different nationalities.' (True DB: poker_player)\n",
      "  Query 263: 'Show the name of the conductor that has conducted the most number of orchestras.' (True DB: orchestra)\n",
      "  Query 264: 'How many documents do we have?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 265: 'Show the names of conductors that have conducted more than one orchestras.' (True DB: orchestra)\n",
      "  Query 266: 'Count the number of employees for each city.' (True DB: employee_hire_evaluation)\n",
      "  Query 267: 'What are the names of the teachers who teach at least two courses?' (True DB: course_teach)\n",
      "  Query 268: 'How many different templates do all document use?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 269: 'How many total tours were there for each ranking date?' (True DB: wta_1)\n",
      "  Query 270: 'How is the math course described?' (True DB: student_transcripts_tracking)\n",
      "  Query 271: 'What is the record company used by the greatest number of orchestras?' (True DB: orchestra)\n",
      "  Query 272: 'Show ids of all students who do not have any friends.' (True DB: network_1)\n",
      "  Query 273: 'For each semester, what is the name and id of the one with the most students registered?' (True DB: student_transcripts_tracking)\n",
      "  Query 274: 'What is the name and id of the department with the most number of degrees ?' (True DB: student_transcripts_tracking)\n",
      "  Query 275: 'which countries' tv channels are not playing any cartoon written by Todd Casey?' (True DB: tvshow)\n",
      "  Query 276: 'What is the document id and name with greatest number of paragraphs?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 277: 'What are the names of poker players, ordered ascending by the number of final tables they have made?' (True DB: poker_player)\n",
      "  Query 278: 'List the section_name in reversed lexicographical order.' (True DB: student_transcripts_tracking)\n",
      "  Query 279: 'What is the accelerate of the car make amc hornet sportabout (sw)?' (True DB: car_1)\n",
      "  Query 280: 'What is the first, middle, and last name of the first student to register?' (True DB: student_transcripts_tracking)\n",
      "  Query 281: 'How many cartoons did each director create?' (True DB: tvshow)\n",
      "  Query 282: 'What is the average rank for winners in all matches?' (True DB: wta_1)\n",
      "  Query 283: 'Show all document ids and the number of paragraphs in each document. Order by document id.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 284: 'Find the manager name and district of the shop whose number of products is the largest.' (True DB: employee_hire_evaluation)\n",
      "  Query 285: 'Show names of teachers and the number of courses they teach.' (True DB: course_teach)\n",
      "  Query 286: 'List the emails of the professionals who live in the state of Hawaii or the state of Wisconsin.' (True DB: dog_kennels)\n",
      "  Query 287: 'what are the different names of the singers that have sales more than 300000?' (True DB: singer)\n",
      "  Query 288: 'What are the descriptions for all the math courses?' (True DB: student_transcripts_tracking)\n",
      "  Query 289: 'What are the ids of documents that have 2 or more paragraphs?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 290: 'What major is every student who does not own a cat as a pet, and also how old are they?' (True DB: pets_1)\n",
      "  Query 291: 'What is the average attendance of shows?' (True DB: orchestra)\n",
      "  Query 292: 'Show all document names using templates with template type code BK.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 293: 'find the number of distinct country codes of all players.' (True DB: wta_1)\n",
      "  Query 294: 'How many friends does each student have?' (True DB: network_1)\n",
      "  Query 295: 'Which distinct car models are the produced after 1980?' (True DB: car_1)\n",
      "  Query 296: 'What are the population and life expectancies in Brazil?' (True DB: world_1)\n",
      "  Query 297: 'What is the first name and country code of the oldest player?' (True DB: wta_1)\n",
      "  Query 298: 'Please show the name of the conductor that has conducted orchestras founded after 2008.' (True DB: orchestra)\n",
      "  Query 299: 'What are flight numbers of flights departing from City \"Aberdeen \"?' (True DB: flight_2)\n",
      "  Query 300: 'What are the distinct states and create time of all votes?' (True DB: voter_1)\n",
      "  Query 301: 'Which continent has the most diverse languages?' (True DB: world_1)\n",
      "  Query 302: 'How many unique languages are spoken in the world?' (True DB: world_1)\n",
      "  Query 303: 'What is the description of the department whose name has the substring the computer?' (True DB: student_transcripts_tracking)\n",
      "  Query 304: 'How many car makers are there in france?' (True DB: car_1)\n",
      "  Query 305: 'Find the package choice and series name of the TV channel that has high definition TV.' (True DB: tvshow)\n",
      "  Query 306: 'which countries' tv channels are playing some cartoon written by Todd Casey?' (True DB: tvshow)\n",
      "  Query 307: 'Find the kind of program which most number of students are enrolled in?' (True DB: student_transcripts_tracking)\n",
      "  Query 308: 'What are the country codes of countries where people use languages other than English?' (True DB: world_1)\n",
      "  Query 309: 'What are the first, middle, and last names for everybody enrolled in a Bachelors program?' (True DB: student_transcripts_tracking)\n",
      "  Query 310: 'For a volvo model, how many cylinders does the version with least accelerate have?' (True DB: car_1)\n",
      "  Query 311: 'What is the phone number of the man with the first name Timmothy and the last name Ward?' (True DB: student_transcripts_tracking)\n",
      "  Query 312: 'When did the episode \"A Love of a Lifetime\" air?' (True DB: tvshow)\n",
      "  Query 313: 'What are different nationalities of people and the corresponding number of people from each nation?' (True DB: poker_player)\n",
      "  Query 314: 'How much surface area do the countires in the Carribean cover together?' (True DB: world_1)\n",
      "  Query 315: 'List the Episode of all TV series sorted by rating.' (True DB: tvshow)\n",
      "  Query 316: 'For the countries founded before 1930, what is the total number of distinct official languages?' (True DB: world_1)\n",
      "  Query 317: 'What are the names and birth dates of people, ordered by their names in alphabetical order?' (True DB: poker_player)\n",
      "  Query 318: 'What is the total number of languages used in Aruba?' (True DB: world_1)\n",
      "  Query 319: 'What is the hometown of the youngest teacher?' (True DB: course_teach)\n",
      "  Query 320: 'Return the names of the contestants whose names contain the substring 'Al' .' (True DB: voter_1)\n",
      "  Query 321: 'Return the number of flights arriving in Aberdeen.' (True DB: flight_2)\n",
      "  Query 322: 'What is the most commmon hometowns for teachers?' (True DB: course_teach)\n",
      "  Query 323: 'Find the program which most number of students are enrolled in. List both the id and the summary.' (True DB: student_transcripts_tracking)\n",
      "  Query 324: 'What are the first names of all players, and their total ranking points?' (True DB: wta_1)\n",
      "  Query 325: 'How many different loser names are there?' (True DB: wta_1)\n",
      "  Query 326: 'For each hometown, how many teachers are there?' (True DB: course_teach)\n",
      "  Query 327: 'What model has the most different versions?' (True DB: car_1)\n",
      "  Query 328: 'How many United Airlines flights go to City 'Aberdeen'?' (True DB: flight_2)\n",
      "  Query 329: 'find the code of the country where has the greatest number of players.' (True DB: wta_1)\n",
      "  Query 330: 'What's the name of the course with most number of enrollments?' (True DB: student_transcripts_tracking)\n",
      "  Query 331: 'What are each professional's first name and description of the treatment they have performed?' (True DB: dog_kennels)\n",
      "  Query 332: 'How many continents are there?' (True DB: car_1)\n",
      "  Query 333: 'Find the number of players for each hand type.' (True DB: wta_1)\n",
      "  Query 334: 'What are the names of airports in Aberdeen?' (True DB: flight_2)\n",
      "  Query 335: 'How many people live in countries that do not speak English?' (True DB: world_1)\n",
      "  Query 336: 'What is the series name of the TV Channel that shows the cartoon \"The Rise of the Blue Beetle\"?' (True DB: tvshow)\n",
      "  Query 337: 'List the names of poker players ordered by the final tables made in ascending order.' (True DB: poker_player)\n",
      "  Query 338: 'How many official languages are spoken in Afghanistan?' (True DB: world_1)\n",
      "  Query 339: 'What are the names of the sections in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n",
      "  Query 340: 'Return the average earnings across all poker players.' (True DB: poker_player)\n",
      "  Query 341: 'What are the names, countries, and ages for every singer in descending order of age?' (True DB: concert_singer)\n",
      "  Query 342: 'What is the id of the pet owned by the student whose last name is 'Smith'?' (True DB: pets_1)\n",
      "  Query 343: 'Count the number of flights departing from 'APG'.' (True DB: flight_2)\n",
      "  Query 344: 'What are the names of the high schoolers and how many friends does each have?' (True DB: network_1)\n",
      "  Query 345: 'What is the minimum weight of the car with 8 cylinders produced in 1974 ?' (True DB: car_1)\n",
      "  Query 346: 'Return the first name, last name and email of the owners living in a state whose name contains the substring 'North'.' (True DB: dog_kennels)\n",
      "  Query 347: 'How many continents speak Chinese?' (True DB: world_1)\n",
      "  Query 348: 'What are 3 most highly rated episodes in the TV series table and what were those ratings?' (True DB: tvshow)\n",
      "  Query 349: 'Show ids for all templates that are used by more than one document.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 350: 'How many transcripts are released?' (True DB: student_transcripts_tracking)\n",
      "  Query 351: 'Which model of the car has the minimum horsepower?' (True DB: car_1)\n",
      "  Query 352: 'What are the arriving date and the departing date of the dogs who have gone through a treatment?' (True DB: dog_kennels)\n",
      "  Query 353: 'What is total bonus given in all evaluations?' (True DB: employee_hire_evaluation)\n",
      "  Query 354: 'What is the average, minimum, and maximum age of all singers from France?' (True DB: concert_singer)\n",
      "  Query 355: 'Which shop has the most employees? Give me the shop name.' (True DB: employee_hire_evaluation)\n",
      "  Query 356: 'What are the names of conductors who have conducted at more than one orchestra?' (True DB: orchestra)\n",
      "  Query 357: 'Which professionals live in a city containing the substring 'West'? List his or her role, street, city and state.' (True DB: dog_kennels)\n",
      "  Query 358: 'What is the horsepower of the car with the largest accelerate?' (True DB: car_1)\n",
      "  Query 359: 'What is the TV Channel that shows the cartoon \"The Rise of the Blue Beetle!\"? List the TV Channel's series name.' (True DB: tvshow)\n",
      "  Query 360: 'Find the average weight for each pet type.' (True DB: pets_1)\n",
      "  Query 361: 'What is the official language spoken in the country whose head of state is Beatrix?' (True DB: world_1)\n",
      "  Query 362: 'What is the total number of airlines?' (True DB: flight_2)\n",
      "  Query 363: 'List the contestant numbers and names, ordered by contestant name descending.' (True DB: voter_1)\n",
      "  Query 364: 'What is the name of the country with the most car makers?' (True DB: car_1)\n",
      "  Query 365: 'What is the maximum accelerate for all the different cylinders?' (True DB: car_1)\n",
      "  Query 366: 'What is the air date of TV series with Episode \"A Love of a Lifetime\"?' (True DB: tvshow)\n",
      "  Query 367: 'Give the name, population, and head of state for the country that has the largest area.' (True DB: world_1)\n",
      "  Query 368: 'find the id of tv channels that do not play any cartoon directed by Ben Jones.' (True DB: tvshow)\n",
      "  Query 369: 'What is the total population of Gelderland district?' (True DB: world_1)\n",
      "  Query 370: 'What are flight numbers of flights arriving at Airport \"APG\"?' (True DB: flight_2)\n",
      "  Query 371: 'Return the names of conductors that do not have the nationality \"USA\".' (True DB: orchestra)\n",
      "  Query 372: 'What are the names of nations speak both English and French?' (True DB: world_1)\n",
      "  Query 373: 'Give the name of the student with the most likes.' (True DB: network_1)\n",
      "  Query 374: 'Which languages are spoken by only one country in republic governments?' (True DB: world_1)\n",
      "  Query 375: 'How many states are there?' (True DB: voter_1)\n",
      "  Query 376: 'Which city has most number of departing flights?' (True DB: flight_2)\n",
      "  Query 377: 'What are the first names of every student who has a cat or dog as a pet?' (True DB: pets_1)\n",
      "  Query 378: 'List the names of teachers in ascending order of age.' (True DB: course_teach)\n",
      "  Query 379: 'How many degrees does the engineering department offer?' (True DB: student_transcripts_tracking)\n",
      "  Query 380: 'Return the owner id, first name and last name of the owner who has the most dogs.' (True DB: dog_kennels)\n",
      "  Query 381: 'Find the minimum grade of students who have no friends.' (True DB: network_1)\n",
      "  Query 382: 'How many flights does airline 'JetBlue Airways' have?' (True DB: flight_2)\n",
      "  Query 383: 'How many courses are there?' (True DB: student_transcripts_tracking)\n",
      "  Query 384: 'Give the language that is spoken in the most countries.' (True DB: world_1)\n",
      "  Query 385: 'Find the number of owners who do not own any dogs at this moment.' (True DB: dog_kennels)\n",
      "  Query 386: 'What is the birth date of the poker player with the lowest earnings?' (True DB: poker_player)\n",
      "  Query 387: 'Show different citizenship of singers and the number of singers of each citizenship.' (True DB: singer)\n",
      "  Query 388: 'Which cities are in European countries where English is not the official language?' (True DB: world_1)\n",
      "  Query 389: 'What is the smallest weight of the car produced with 8 cylinders on 1974 ?' (True DB: car_1)\n",
      "  Query 390: 'Which professionals live in the state of Indiana or have done treatment on more than 2 treatments? List his or her id, last name and cell phone.' (True DB: dog_kennels)\n",
      "  Query 391: 'How many airlines are from USA?' (True DB: flight_2)\n",
      "  Query 392: 'Find the name and rank of the 3 youngest winners across all matches.' (True DB: wta_1)\n",
      "  Query 393: 'What are the different government forms and what is the total population of each for government forms that have an average life expectancy greater than 72?' (True DB: world_1)\n",
      "  Query 394: 'What are the countries that are not playing cartoons written by Todd Casey?' (True DB: tvshow)\n",
      "  Query 395: 'Which professional did not operate any treatment on dogs? List the professional's id, role and email.' (True DB: dog_kennels)\n",
      "  Query 396: 'Which grades have 4 or more high schoolers?' (True DB: network_1)\n",
      "  Query 397: 'List the final tables made and the best finishes of poker players.' (True DB: poker_player)\n",
      "  Query 398: 'What are the names of poker players?' (True DB: poker_player)\n",
      "  Query 399: 'Find the first name and country code of the oldest player.' (True DB: wta_1)\n",
      "  Query 400: 'What is the first, middle, and last name of the earliest school graduate?' (True DB: student_transcripts_tracking)\n",
      "  Query 401: 'Return the ids of templates that have the code PP or PPT.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 402: 'List the name of singers whose citizenship is not \"France\".' (True DB: singer)\n",
      "  Query 403: 'Give average earnings of poker players who are taller than 200.' (True DB: poker_player)\n",
      "  Query 404: 'What are the first names of all players, and their average rankings?' (True DB: wta_1)\n",
      "  Query 405: 'How many players are from each country?' (True DB: wta_1)\n",
      "  Query 406: 'Find the names of the visitors whose membership level is higher than 4, and order the results by the level from high to low.' (True DB: museum_visit)\n",
      "  Query 407: 'Find the name and membership level of the visitors whose membership level is higher than 4, and sort by their age from old to young.' (True DB: museum_visit)\n",
      "  Query 408: 'Find the number of pets for each student who has any pet and student id.' (True DB: pets_1)\n",
      "  Query 409: 'What is the count of singers?' (True DB: singer)\n",
      "  Query 410: 'What are the create dates, states, and phone numbers of the votes that were for the contestant named 'Tabatha Gehling'?' (True DB: voter_1)\n",
      "  Query 411: 'How many different departments offer degrees?' (True DB: student_transcripts_tracking)\n",
      "  Query 412: 'Give the airport code and airport name corresonding to the city Anthony.' (True DB: flight_2)\n",
      "  Query 413: 'What are the countries that have greater surface area than any country in Europe?' (True DB: world_1)\n",
      "  Query 414: 'What is the earliest date of a transcript release, and what details can you tell me?' (True DB: student_transcripts_tracking)\n",
      "  Query 415: 'List the last name of the owner owning the youngest dog.' (True DB: dog_kennels)\n",
      "  Query 416: 'Show the number of high schoolers for each grade.' (True DB: network_1)\n",
      "  Query 417: 'What are the names of high schoolers who have 3 or more friends?' (True DB: network_1)\n",
      "  Query 418: 'What is the full name of each car maker, along with its id and how many models it produces?' (True DB: car_1)\n",
      "  Query 419: 'What are the ids and names of each document, as well as the number of paragraphs in each?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 420: 'What is the department description for the one whose name has the word computer?' (True DB: student_transcripts_tracking)\n",
      "  Query 421: 'How many ships ended up being 'Captured'?' (True DB: battle_death)\n",
      "  Query 422: 'How many different series and contents are listed in the TV Channel table?' (True DB: tvshow)\n",
      "  Query 423: 'Find the average number of staff working for the museums that were open before 2009.' (True DB: museum_visit)\n",
      "  Query 424: 'What is the abbreviation of the airilne has the fewest flights and what country is it in?' (True DB: flight_2)\n",
      "  Query 425: 'What is the name and directors of all the cartoons that are ordered by air date?' (True DB: tvshow)\n",
      "  Query 426: 'Give the flight numbers of flights arriving in Aberdeen.' (True DB: flight_2)\n",
      "  Query 427: 'What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?' (True DB: car_1)\n",
      "  Query 428: 'Show the stadium name and the number of concerts in each stadium.' (True DB: concert_singer)\n",
      "  Query 429: 'Show all countries and the number of singers in each country.' (True DB: concert_singer)\n",
      "  Query 430: 'Which abbreviation corresponds to Jetblue Airways?' (True DB: flight_2)\n",
      "  Query 431: 'Give the mean life expectancy of countries in which English is not the official language.' (True DB: world_1)\n",
      "  Query 432: 'What is the document id with 1 to 2 paragraphs?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 433: 'How many departments offer any degree?' (True DB: student_transcripts_tracking)\n",
      "  Query 434: 'What are the codes of the countries that do not speak English and whose government forms are not Republic?' (True DB: world_1)\n",
      "  Query 435: 'What language is predominantly spoken in Aruba?' (True DB: world_1)\n",
      "  Query 436: 'how many cars were produced in 1980?' (True DB: car_1)\n",
      "  Query 437: 'Show the years in which orchestras that have given more than one performance are founded.' (True DB: orchestra)\n",
      "  Query 438: 'Give the ids of documents that have between one and two paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 439: 'How many employees are there?' (True DB: employee_hire_evaluation)\n",
      "  Query 440: 'In which years cars were produced weighing no less than 3000 and no more than 4000 ?' (True DB: car_1)\n",
      "  Query 441: 'What is name of the country that speaks the largest number of languages?' (True DB: world_1)\n",
      "  Query 442: 'Show all template type codes and descriptions.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 443: 'Count the number of conductors.' (True DB: orchestra)\n",
      "  Query 444: 'What is the name of the semester with no students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 445: 'What are the names and descriptions for all the sections?' (True DB: student_transcripts_tracking)\n",
      "  Query 446: 'What are the names of the singers whose birth years are either 1948 or 1949?' (True DB: singer)\n",
      "  Query 447: 'How many dogs have an age below the average?' (True DB: dog_kennels)\n",
      "  Query 448: 'How many different store locations are there?' (True DB: employee_hire_evaluation)\n",
      "  Query 449: 'Find the number of visitors who did not visit any museum opened after 2010.' (True DB: museum_visit)\n",
      "  Query 450: 'List the name, date and result of each battle.' (True DB: battle_death)\n",
      "  Query 451: 'How much does the most expensive charge type costs?' (True DB: dog_kennels)\n",
      "  Query 452: 'List all song names by singers above the average age.' (True DB: concert_singer)\n",
      "  Query 453: 'Count the number of poker players.' (True DB: poker_player)\n",
      "  Query 454: 'For each singer name, what is the total sales for their songs?' (True DB: singer)\n",
      "  Query 455: 'When is the first transcript released? List the date and details.' (True DB: student_transcripts_tracking)\n",
      "  Query 456: 'How many dogs have not gone through any treatment?' (True DB: dog_kennels)\n",
      "  Query 457: 'For the cars with 4 cylinders, which model has the largest horsepower?' (True DB: car_1)\n",
      "  Query 458: 'What are the names of poker players whose earnings is higher than 300000?' (True DB: poker_player)\n",
      "  Query 459: 'How many distinct nationalities are there?' (True DB: poker_player)\n",
      "  Query 460: 'How many dogs went through any treatments?' (True DB: dog_kennels)\n",
      "  Query 461: 'What is the first name of the student whose permanent address is different from his or her current one?' (True DB: student_transcripts_tracking)\n",
      "  Query 462: 'find id of the tv channels that from the countries where have more than two tv channels.' (True DB: tvshow)\n",
      "  Query 463: 'How many distinct countries do players come from?' (True DB: wta_1)\n",
      "  Query 464: 'Give the flight numbers of flights landing at APG.' (True DB: flight_2)\n",
      "  Query 465: 'Count the number of templates.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 466: 'What is the code of airport that has fewest number of flights?' (True DB: flight_2)\n",
      "  Query 467: 'List the first name of all the professionals along with the description of the treatment they have done.' (True DB: dog_kennels)\n",
      "  Query 468: 'How many countries speak both English and Dutch?' (True DB: world_1)\n",
      "  Query 469: 'How many models does each car maker produce? List maker full name, id and the number.' (True DB: car_1)\n",
      "  Query 470: 'What are the first names of the students who live in Haiti permanently or have the cell phone number 09700166582 ?' (True DB: student_transcripts_tracking)\n",
      "  Query 471: 'Count the number of paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 472: 'What is the average horsepower for all cars produced before 1980 ?' (True DB: car_1)\n",
      "  Query 473: 'How many languages are spoken in Aruba?' (True DB: world_1)\n",
      "  Query 474: 'Find the name and age of the visitor who bought the most tickets at once.' (True DB: museum_visit)\n",
      "  Query 475: 'What are the name, independence year, and surface area of the country with the smallest population?' (True DB: world_1)\n",
      "  Query 476: 'Give the names of countries with English and French as official languages.' (True DB: world_1)\n",
      "  Query 477: 'Show all template type codes with less than three templates.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 478: 'What are the opening year and staff number of the museum named Plaza Museum?' (True DB: museum_visit)\n",
      "  Query 479: 'What is the first name, country code, and birth date of the player with the most winner rank points across all matches?' (True DB: wta_1)\n",
      "  Query 480: 'Return the grade for the high schooler named Kyle.' (True DB: network_1)\n",
      "  Query 481: 'What are the names and descriptions of all the sections?' (True DB: student_transcripts_tracking)\n",
      "  Query 482: 'What are the first names and birth dates of players from the USA?' (True DB: wta_1)\n",
      "  Query 483: 'Which model has the most version(make) of cars?' (True DB: car_1)\n",
      "  Query 484: 'Find the id and cell phone of the professionals who operate two or more types of treatments.' (True DB: dog_kennels)\n",
      "  Query 485: 'Which airlines have at least 10 flights?' (True DB: flight_2)\n",
      "  Query 486: 'What are the emails of the professionals living in either the state of Hawaii or the state of Wisconsin?' (True DB: dog_kennels)\n",
      "  Query 487: 'What is the content of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Query 488: 'Count the number of matches.' (True DB: wta_1)\n",
      "  Query 489: 'What is the name of the different car makers who produced a car in 1970?' (True DB: car_1)\n",
      "  Query 490: 'What is the last transcript release date?' (True DB: student_transcripts_tracking)\n",
      "  Query 491: 'What are the names of all European countries with at least 3 manufacturers?' (True DB: car_1)\n",
      "  Query 492: 'Find the number of flights landing in the city of Aberdeen or Abilene.' (True DB: flight_2)\n",
      "  Query 493: 'What are the average ages of losers and winners across matches?' (True DB: wta_1)\n",
      "  Query 494: 'Find the city with the largest population that uses English.' (True DB: world_1)\n",
      "  Query 495: 'For each citizenship, how many singers are from that country?' (True DB: singer)\n",
      "  Query 496: 'What is the ship id and name that caused most total injuries?' (True DB: battle_death)\n",
      "  Query 497: 'What is the name of the winner with the most rank points who participated in the Australian Open tournament?' (True DB: wta_1)\n",
      "  Query 498: 'Give the names of poker players who have earnings above 300000.' (True DB: poker_player)\n",
      "  Query 499: 'List singer names and number of concerts for each singer.' (True DB: concert_singer)\n",
      "  Query 500: 'How many paragraphs for the document with name 'Summer Show'?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 501: 'Show the names of all high schoolers in grade 10.' (True DB: network_1)\n",
      "  Query 502: 'Which dogs are owned by someone who lives in Virginia? List the owner's first name and the dog's name.' (True DB: dog_kennels)\n",
      "  Query 503: 'Count the number of orchestras that have CD or DVD as their record format.' (True DB: orchestra)\n",
      "  Query 504: 'What are the names of the teachers and the courses they teach in ascending alphabetical order by the name of the teacher?' (True DB: course_teach)\n",
      "  Query 505: 'What is the total population and average area of countries in the continent of North America whose area is bigger than 3000 ?' (True DB: world_1)\n",
      "  Query 506: 'What are the name and results of the battles when the bulgarian commander is not 'Boril'' (True DB: battle_death)\n",
      "  Query 507: 'What are the ids of high school students who do not have friends?' (True DB: network_1)\n",
      "  Query 508: 'How many countries exist?' (True DB: car_1)\n",
      "  Query 509: 'List the name of singers in ascending order of net worth.' (True DB: singer)\n",
      "  Query 510: 'What are the names of conductors, ordered by age?' (True DB: orchestra)\n",
      "  Query 511: 'Which template type code has most number of templates?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 512: 'What is the episode for the TV series named \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Query 513: 'Tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.' (True DB: dog_kennels)\n",
      "  Query 514: 'Show the ids of high schoolers who have friends and are also liked by someone else.' (True DB: network_1)\n",
      "  Query 515: 'How many flights do we have?' (True DB: flight_2)\n",
      "  Query 516: 'Find the weight of the youngest dog.' (True DB: pets_1)\n",
      "  Query 517: 'Which airline has abbreviation 'UAL'?' (True DB: flight_2)\n",
      "  Query 518: 'Find the total amount of bonus given in all the evaluations.' (True DB: employee_hire_evaluation)\n",
      "  Query 519: 'What is minimum and maximum share of TV series?' (True DB: tvshow)\n",
      "  Query 520: 'Give the total surface area covered by countries in Asia or Europe.' (True DB: world_1)\n",
      "  Query 521: 'What are the arriving date and the departing date of all the dogs?' (True DB: dog_kennels)\n",
      "  Query 522: 'Give the name, year of independence, and surface area of the country that has the lowest population.' (True DB: world_1)\n",
      "  Query 523: 'Which countries have greater area than that of any country in Europe?' (True DB: world_1)\n",
      "  Query 524: 'Count the number of templates of the type CV.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 525: 'What is the model for the car with a weight smaller than the average?' (True DB: car_1)\n",
      "  Query 526: 'List the names of teachers who have not been arranged to teach courses.' (True DB: course_teach)\n",
      "  Query 527: 'What is the description for the section named h?' (True DB: student_transcripts_tracking)\n",
      "  Query 528: 'Count the number of United Airlines flights arriving in ASY Airport.' (True DB: flight_2)\n",
      "  Query 529: 'What is the average expected life expectancy for countries in the region of Central Africa?' (True DB: world_1)\n",
      "  Query 530: 'List the most common hometown of teachers.' (True DB: course_teach)\n",
      "  Query 531: 'Count the number of documents that use the PPT template type.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 532: 'What is the airport code of the airport with the most flights?' (True DB: flight_2)\n",
      "  Query 533: 'What are the maximum and minimum values of area codes?' (True DB: voter_1)\n",
      "  Query 534: 'What are the names of the people who teach math courses?' (True DB: course_teach)\n",
      "  Query 535: 'How many car models were produced by the maker with full name American Motor Company?' (True DB: car_1)\n",
      "  Query 536: 'Find the number of shops in each location.' (True DB: employee_hire_evaluation)\n",
      "  Query 537: 'Give the names of countries that are in Europe and have a population equal to 80000.' (True DB: world_1)\n",
      "  Query 538: 'Return the different document ids along with the number of paragraphs corresponding to each, ordered by id.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 539: 'Give the number of Jetblue Airways flights.' (True DB: flight_2)\n",
      "  Query 540: 'What are the cities whose population is between 160000 and 900000?' (True DB: world_1)\n",
      "  Query 541: 'What are the names of conductors whose nationalities are not \"USA\"?' (True DB: orchestra)\n",
      "  Query 542: 'Return the number of United Airlines flights leaving from AHD Airport.' (True DB: flight_2)\n",
      "  Query 543: 'Which language is spoken by the largest number of countries?' (True DB: world_1)\n",
      "  Query 544: 'How many countries has more than 2 car makers ?' (True DB: car_1)\n",
      "  Query 545: 'find the package option of the tv channel that do not have any cartoon directed by Ben Jones.' (True DB: tvshow)\n",
      "  Query 546: 'What are flight numbers of Airline \"United Airlines\"?' (True DB: flight_2)\n",
      "  Query 547: 'What are airlines that have some flight departing from airport 'AHD'?' (True DB: flight_2)\n",
      "  Query 548: 'List the name of singers that do not have any song.' (True DB: singer)\n",
      "  Query 549: 'Which owner has paid for the most treatments on his or her dogs? List the owner id and last name.' (True DB: dog_kennels)\n",
      "  Query 550: 'What is the first and second line for all addresses?' (True DB: student_transcripts_tracking)\n",
      "  Query 551: 'What is the id, line 1, and line 2 of the address with the most students?' (True DB: student_transcripts_tracking)\n",
      "  Query 552: 'For all of the 4 cylinder cars, which model has the most horsepower?' (True DB: car_1)\n",
      "  Query 553: 'What are the locations and names of all stations with capacity between 5000 and 10000?' (True DB: concert_singer)\n",
      "  Query 554: 'How many different forms of governments are there in Africa?' (True DB: world_1)\n",
      "  Query 555: 'What is the pixel aspect ratio and country of origin for all TV channels that do not use English?' (True DB: tvshow)\n",
      "  Query 556: 'How many flights land in Aberdeen or Abilene?' (True DB: flight_2)\n",
      "  Query 557: 'Return the average attendance across all shows.' (True DB: orchestra)\n",
      "  Query 558: 'What are the names of all stadiums that did not have a concert in 2014?' (True DB: concert_singer)\n",
      "  Query 559: 'Find the number of cartoons directed by each of the listed directors.' (True DB: tvshow)\n",
      "  Query 560: 'Find the model of the car whose weight is below the average weight.' (True DB: car_1)\n",
      "  Query 561: 'What is the date and id of the transcript with the least number of results?' (True DB: student_transcripts_tracking)\n",
      "  Query 562: 'Which city has the most frequent destination airport?' (True DB: flight_2)\n",
      "  Query 563: 'How many high schoolers are there in grade 9 or 10?' (True DB: network_1)\n",
      "  Query 564: 'What are the names of all the countries that became independent after 1950?' (True DB: world_1)\n",
      "  Query 565: 'What is Kyle's id?' (True DB: network_1)\n",
      "  Query 566: 'What are the different template type codes, and how many documents use each type?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 567: 'What are the names of the employees who never received any evaluation?' (True DB: employee_hire_evaluation)\n",
      "  Query 568: 'Find the number of concerts happened in the stadium with the highest capacity .' (True DB: concert_singer)\n",
      "  Query 569: 'List the names of all winners who played in both 2013 and 2016.' (True DB: wta_1)\n",
      "  Query 570: 'What is maximum and minimum death toll caused each time?' (True DB: battle_death)\n",
      "  Query 571: 'How many players are there?' (True DB: wta_1)\n",
      "  Query 572: 'What are the different template type codes, and how many templates correspond to each?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 573: 'Which unique cities are in Asian countries where Chinese is the official language ?' (True DB: world_1)\n",
      "  Query 574: 'What are the id and names of the countries which have more than 3 car makers or produce the 'fiat' model?' (True DB: car_1)\n",
      "  Query 575: 'What is the name and country of origin of every singer who has a song with the word 'Hey' in its title?' (True DB: concert_singer)\n",
      "  Query 576: 'Show name, country, age for all singers ordered by age from the oldest to the youngest.' (True DB: concert_singer)\n",
      "  Query 577: 'Return the names of all the poker players.' (True DB: poker_player)\n",
      "  Query 578: 'How many people live in Gelderland district?' (True DB: world_1)\n",
      "  Query 579: 'What is the total surface area of the countries in the Caribbean region?' (True DB: world_1)\n",
      "  Query 580: 'Return the names of the 3 most populated countries.' (True DB: world_1)\n",
      "  Query 581: 'Find the first name of students who have both cat and dog pets .' (True DB: pets_1)\n",
      "  Query 582: 'What is the language that is used by the largest number of Asian nations?' (True DB: world_1)\n",
      "  Query 583: 'What are all distinct countries where singers above age 20 are from?' (True DB: concert_singer)\n",
      "  Query 584: 'Which airlines have a flight with source airport AHD?' (True DB: flight_2)\n",
      "  Query 585: 'Find the names of employees who never won any award in the evaluation.' (True DB: employee_hire_evaluation)\n",
      "  Query 586: 'Return the country codes for countries that do not speak English.' (True DB: world_1)\n",
      "  Query 587: 'Find the number of distinct name of losers.' (True DB: wta_1)\n",
      "  Query 588: 'Find the number of cities in each district whose population is greater than the average population of cities?' (True DB: world_1)\n",
      "  Query 589: 'How many friends does the high school student Kyle have?' (True DB: network_1)\n",
      "  Query 590: 'What are the manager name and district of the shop that sells the largest number of products?' (True DB: employee_hire_evaluation)\n",
      "  Query 591: 'List all airline names and their abbreviations in \"USA\".' (True DB: flight_2)\n",
      "  Query 592: 'Sort all the shops by number products in descending order, and return the name, location and district of each shop.' (True DB: employee_hire_evaluation)\n",
      "  Query 593: 'How many templates do we have?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 594: 'List the name and date the battle that has lost the ship named 'Lettice' and the ship named 'HMS Atalanta'' (True DB: battle_death)\n",
      "  Query 595: 'What are the different models wthat are lighter than 3500 but were not built by the Ford Motor Company?' (True DB: car_1)\n",
      "  Query 596: 'How many people are there of each nationality?' (True DB: poker_player)\n",
      "  Query 597: 'What is the average age of the dogs who have gone through any treatments?' (True DB: dog_kennels)\n",
      "  Query 598: 'What is the zip code for Port Chelsea?' (True DB: student_transcripts_tracking)\n",
      "  Query 599: 'Which region is the city Kabul located in?' (True DB: world_1)\n",
      "  Query 600: 'What is the series name and country of all TV channels that are playing cartoons directed by Ben Jones and cartoons directed by Michael Chang?' (True DB: tvshow)\n",
      "  Query 601: 'How many different degrees are offered?' (True DB: student_transcripts_tracking)\n",
      "  Query 602: 'How many contestants did not get voted?' (True DB: voter_1)\n",
      "  Query 603: 'Show different hometown of teachers and the number of teachers from each hometown.' (True DB: course_teach)\n",
      "  Query 604: 'List the names of orchestras that have no performance.' (True DB: orchestra)\n",
      "  Query 605: 'What are the names of nations where both English and French are official languages?' (True DB: world_1)\n",
      "  Query 606: 'How many 'United Airlines' flights go to Airport 'ASY'?' (True DB: flight_2)\n",
      "  Query 607: 'How many flights depart from City Aberdeen?' (True DB: flight_2)\n",
      "  Query 608: 'How many different types of pet are there?' (True DB: pets_1)\n",
      "  Query 609: 'find the number of players for each country.' (True DB: wta_1)\n",
      "  Query 610: 'Find the codes of countries that have more than 50 players.' (True DB: wta_1)\n",
      "  Query 611: 'What are the names of all high schoolers in grade 10?' (True DB: network_1)\n",
      "  Query 612: 'What is the lowest grade of students who do not have any friends?' (True DB: network_1)\n",
      "  Query 613: 'Return the names and surface areas of the 5 largest countries.' (True DB: world_1)\n",
      "  Query 614: 'How many cities in each district have a population that is above the average population across all cities?' (True DB: world_1)\n",
      "  Query 615: 'Show distinct names of singers that have songs with sales more than 300000.' (True DB: singer)\n",
      "  Query 616: 'What are the ids of all tv channels that have more than 2 TV channels?' (True DB: tvshow)\n",
      "  Query 617: 'What are all the course names of the courses which ever have students enrolled in?' (True DB: student_transcripts_tracking)\n",
      "  Query 618: 'What are the names of students who have 2 or more likes?' (True DB: network_1)\n",
      "  Query 619: 'For each continent, list its id, name, and how many countries it has?' (True DB: car_1)\n",
      "  Query 620: 'What is the total population and maximum GNP in Asia?' (True DB: world_1)\n",
      "  Query 621: 'How many professionals have performed any treatment to dogs?' (True DB: dog_kennels)\n",
      "  Query 622: 'Find the total number of matches.' (True DB: wta_1)\n",
      "  Query 623: 'Find the name and rank points of the winner who won the most times.' (True DB: wta_1)\n",
      "  Query 624: 'What are the names of the dogs for which the owner has not spend more than 1000 for treatment ?' (True DB: dog_kennels)\n",
      "  Query 625: 'What is the count of the car models produced in the United States?' (True DB: car_1)\n",
      "  Query 626: 'How many TV Channels use the English language?' (True DB: tvshow)\n",
      "  Query 627: 'What is the official language used in the country the name of whose head of state is Beatrix.' (True DB: world_1)\n",
      "  Query 628: 'Return the template type code of the template that is used by a document named Data base.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 629: 'What are the package options of all tv channels that are not playing any cartoons directed by Ben Jones?' (True DB: tvshow)\n",
      "  Query 630: 'How many people live in Asia, and what is the largest GNP among them?' (True DB: world_1)\n",
      "  Query 631: 'What are the number of votes from state 'NY' or 'CA'?' (True DB: voter_1)\n",
      "  Query 632: 'Who owns the youngest dog? Give me his or her last name.' (True DB: dog_kennels)\n",
      "  Query 633: 'Show all template type codes that are not used by any document.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 634: 'What is the average miles per gallon(mpg) of the cars with 4 cylinders?' (True DB: car_1)\n",
      "  Query 635: 'What are  the different countries with singers above age 20?' (True DB: concert_singer)\n",
      "  Query 636: 'How many different winners both participated in the WTA Championships and were left handed?' (True DB: wta_1)\n",
      "  Query 637: 'What is the title of all the cartools that are on the TV Channel with the series name \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Query 638: 'Which shops run with no employees? Find the shop names' (True DB: employee_hire_evaluation)\n",
      "  Query 639: 'What is the number of makers of care in France?' (True DB: car_1)\n",
      "  Query 640: 'What is the name of the breed with the most dogs?' (True DB: dog_kennels)\n",
      "  Query 641: 'What are the dog name, age and weight of the dogs that were abandoned? Note that 1 stands for yes, and 0 stands for no in the tables.' (True DB: dog_kennels)\n",
      "  Query 642: 'What are the names and ids of all makers with more than 3 models?' (True DB: car_1)\n",
      "  Query 643: 'How many countries have a republic as their form of government?' (True DB: world_1)\n",
      "  Query 644: 'How many flights depart from City 'Aberdeen' and have destination City 'Ashley'?' (True DB: flight_2)\n",
      "  Query 645: 'What are the names of students who have no friends?' (True DB: network_1)\n",
      "  Query 646: 'What is last date created of votes from the state 'CA'?' (True DB: voter_1)\n",
      "  Query 647: 'Find the first name and country code of the player who did the most number of tours.' (True DB: wta_1)\n",
      "  Query 648: 'What are each owner's first name and their dogs's name?' (True DB: dog_kennels)\n",
      "  Query 649: 'What is the produdction code and channel of the most recent cartoon ?' (True DB: tvshow)\n",
      "  Query 650: 'Count the number of documents.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 651: 'Show the name and the release year of the song by the youngest singer.' (True DB: concert_singer)\n",
      "  Query 652: 'Find the id and weight of all pets whose age is older than 1.' (True DB: pets_1)\n",
      "  Query 653: 'Show name of all students who have some friends and also are liked by someone else.' (True DB: network_1)\n",
      "  Query 654: 'What is the number of countries with more than 2 car makers ?' (True DB: car_1)\n",
      "  Query 655: 'Which employee received the biggest bonus? Give me the employee name.' (True DB: employee_hire_evaluation)\n",
      "  Query 656: 'Find the series name and country of the tv channel that is playing some cartoons directed by Ben Jones and Michael Chang?' (True DB: tvshow)\n",
      "  Query 657: 'Count the number of United Airlines flights that arrive in Aberdeen.' (True DB: flight_2)\n",
      "  Query 658: 'What are the song titles and singer names?' (True DB: singer)\n",
      "  Query 659: 'Which airlines have departures from CVO but not from APG airports?' (True DB: flight_2)\n",
      "  Query 660: 'What are the country code and first name of the players who won in both tourney WTA Championships and Australian Open?' (True DB: wta_1)\n",
      "  Query 661: 'What are the orchestras that do not have any performances?' (True DB: orchestra)\n",
      "  Query 662: 'What are the codes of template types that have fewer than 3 templates?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 663: 'What are the names of the singers that have more than one songs?' (True DB: singer)\n",
      "  Query 664: 'Please show the record formats of orchestras in ascending order of count.' (True DB: orchestra)\n",
      "  Query 665: 'What are the names of high schoolers who have likes, and how many likes does each have?' (True DB: network_1)\n",
      "  Query 666: 'What is the average horsepower of the cars before 1980?' (True DB: car_1)\n",
      "  Query 667: 'What is the number of distinct languages used around the world?' (True DB: world_1)\n",
      "  Query 668: 'What airline serves the most flights?' (True DB: flight_2)\n",
      "  Query 669: 'What are the maximum and minimum share of performances whose type is not \"Live final\".' (True DB: orchestra)\n",
      "  Query 670: 'List the name of the conductor with the most years of work.' (True DB: orchestra)\n",
      "  Query 671: 'Which district has both stores with less than 3000 products and stores with more than 10000 products?' (True DB: employee_hire_evaluation)\n",
      "  Query 672: 'What is the money rank of the poker player with the highest earnings?' (True DB: poker_player)\n",
      "  Query 673: 'What are the distinct template type descriptions for the templates ever used by any document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 674: 'Who are enrolled in 2 degree programs in one semester? List the first name, middle name and last name and the id.' (True DB: student_transcripts_tracking)\n",
      "  Query 675: 'Give the country codes for countries in which people speak langauges that are not English.' (True DB: world_1)\n",
      "  Query 676: 'Find the average rank of winners in all matches.' (True DB: wta_1)\n",
      "  Query 677: 'How many professionals did not operate any treatment on dogs?' (True DB: dog_kennels)\n",
      "  Query 678: 'What is the template type descriptions for template type code \"AD\".' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 679: 'What is the weekly rank for the episode \"A Love of a Lifetime\"?' (True DB: tvshow)\n",
      "  Query 680: 'What are the ids of students who both have friends and are liked?' (True DB: network_1)\n",
      "  Query 681: 'Return the record companies of orchestras, sorted descending by the years in which they were founded.' (True DB: orchestra)\n",
      "  Query 682: 'For each language, list the number of TV Channels that use it.' (True DB: tvshow)\n",
      "  Query 683: 'Find the first name of the students who permanently live in the country Haiti or have the cell phone number 09700166582 .' (True DB: student_transcripts_tracking)\n",
      "  Query 684: 'Find the distinct breed type and size type combinations for dogs.' (True DB: dog_kennels)\n",
      "  Query 685: 'Which language is the most popular on the Asian continent?' (True DB: world_1)\n",
      "  Query 686: 'Count the number of flights into ATO.' (True DB: flight_2)\n",
      "  Query 687: 'How many official languages does Afghanistan have?' (True DB: world_1)\n",
      "  Query 688: 'How many flights fly from Aberdeen to Ashley?' (True DB: flight_2)\n",
      "  Query 689: 'Which city has most number of arriving flights?' (True DB: flight_2)\n",
      "  Query 690: 'Among the cars that do not have the minimum horsepower , what are the make ids and names of all those with less than 4 cylinders ?' (True DB: car_1)\n",
      "  Query 691: 'What is the first name and country code of the player with the most tours?' (True DB: wta_1)\n",
      "  Query 692: 'Show different citizenships and the maximum net worth of singers of each citizenship.' (True DB: singer)\n",
      "  Query 693: 'What is the template type code for template type description \"Book\".' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 694: 'What are the paragraph texts for the document with the name 'Customer reviews'?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 695: 'Show the names of high schoolers who have likes, and numbers of likes for each.' (True DB: network_1)\n",
      "  Query 696: 'What grade is Kyle in?' (True DB: network_1)\n",
      "  Query 697: 'Show the names of high schoolers who have at least 3 friends.' (True DB: network_1)\n",
      "  Query 698: 'What is the name and capacity of the stadium with the most concerts after 2013 ?' (True DB: concert_singer)\n",
      "  Query 699: 'Return the number of airlines in the USA.' (True DB: flight_2)\n",
      "  Query 700: 'Find all airlines that have flights from airport 'CVO' but not from 'APG'.' (True DB: flight_2)\n",
      "  Query 701: 'Return the name, location and district of all shops in descending order of number of products.' (True DB: employee_hire_evaluation)\n",
      "  Query 702: 'What other details can you tell me about students in reverse alphabetical order?' (True DB: student_transcripts_tracking)\n",
      "  Query 703: 'Where is the youngest teacher from?' (True DB: course_teach)\n",
      "  Query 704: 'Which airline has most number of flights?' (True DB: flight_2)\n",
      "  Query 705: 'Find the average age of the dogs who went through treatments.' (True DB: dog_kennels)\n",
      "  Query 706: 'What is the average age of the visitors whose membership level is not higher than 4?' (True DB: museum_visit)\n",
      "  Query 707: 'Return the maximum and minimum shares for performances that do not have the type \"Live final\".' (True DB: orchestra)\n",
      "  Query 708: 'Give me the description of the treatment type whose total cost is the lowest.' (True DB: dog_kennels)\n",
      "  Query 709: 'How many likes does Kyle have?' (True DB: network_1)\n",
      "  Query 710: 'Show me all grades that have at least 4 students.' (True DB: network_1)\n",
      "  Query 711: 'Give me Brazil’s population and life expectancies.' (True DB: world_1)\n",
      "  Query 712: 'What is the average GNP and total population in all nations whose government is US territory?' (True DB: world_1)\n",
      "  Query 713: 'Show all paragraph ids and texts for the document with name 'Welcome to NY'.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 714: 'What are the names of conductors as well as the corresonding orchestras that they have conducted?' (True DB: orchestra)\n",
      "  Query 715: 'What is the country with the most number of TV Channels and how many does it have?' (True DB: tvshow)\n",
      "  Query 716: 'What are the age and hometown of teachers?' (True DB: course_teach)\n",
      "  Query 717: 'Find the name of the shops that do not hire any employee.' (True DB: employee_hire_evaluation)\n",
      "  Query 718: 'Which first names are used for professionals or owners but are not used as dog names?' (True DB: dog_kennels)\n",
      "  Query 719: 'Count the number of dogs of an age below the average.' (True DB: dog_kennels)\n",
      "  Query 720: 'What are the id, role, and first name of the professionals who have performed two or more treatments?' (True DB: dog_kennels)\n",
      "  Query 721: 'How many times at most can a course enrollment result show in different transcripts? Also show the course enrollment id.' (True DB: student_transcripts_tracking)\n",
      "  Query 722: 'Count the number of different nationalities of conductors.' (True DB: orchestra)\n",
      "  Query 723: 'How many flights arriving in Aberdeen city?' (True DB: flight_2)\n",
      "  Query 724: 'List the dog name, age and weight of the dogs who have been abandoned? 1 stands for yes, and 0 stands for no.' (True DB: dog_kennels)\n",
      "  Query 725: 'What is the abbreviation of Airline \"JetBlue Airways\"?' (True DB: flight_2)\n",
      "  Query 726: 'What are the final tables made and best finishes for all poker players?' (True DB: poker_player)\n",
      "  Query 727: 'What are the names of cities in Europe for which English is not the official language?' (True DB: world_1)\n",
      "  Query 728: 'List the first and last name of all players who are left / L hand in the order of birth date.' (True DB: wta_1)\n",
      "  Query 729: 'How many likes correspond to each student id?' (True DB: network_1)\n",
      "  Query 730: 'How many templates have template type code CV?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 731: 'What the smallest version number and its template type code?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 732: 'What is the maximum number of final tables made among poker players with earnings less than 200000?' (True DB: poker_player)\n",
      "  Query 733: 'What is the name of the museum that had no visitor yet?' (True DB: museum_visit)\n",
      "  Query 734: 'Show names of teachers and the courses they are arranged to teach.' (True DB: course_teach)\n",
      "  Query 735: 'Which airports do not have departing or arriving flights?' (True DB: flight_2)\n",
      "  Query 736: 'What are the names of the teachers ordered by ascending age?' (True DB: course_teach)\n",
      "  Query 737: 'What is the number of cars with more than 4 cylinders?' (True DB: car_1)\n",
      "  Query 738: 'list all cartoon titles and their directors ordered by their air date' (True DB: tvshow)\n",
      "  Query 739: 'Return the id and name of the document with the most paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 740: 'What is all the information about hiring?' (True DB: employee_hire_evaluation)\n",
      "  Query 741: 'What are the earnings of poker players, ordered descending by value?' (True DB: poker_player)\n",
      "  Query 742: 'Find the number of employees hired in each shop; show the shop name as well.' (True DB: employee_hire_evaluation)\n",
      "  Query 743: 'Show the names and grades of each high schooler.' (True DB: network_1)\n",
      "  Query 744: 'Show location and name for all stadiums with a capacity between 5000 and 10000.' (True DB: concert_singer)\n",
      "  Query 745: 'Which Asian countries have a population that is larger than any country in Africa?' (True DB: world_1)\n",
      "  Query 746: 'What is the total number of singers?' (True DB: concert_singer)\n",
      "  Query 747: 'In 1980, how many cars were made?' (True DB: car_1)\n",
      "  Query 748: 'Give the total population and average surface area corresponding to countries in North America that have a surface area greater than 3000 .' (True DB: world_1)\n",
      "  Query 749: 'List each charge type and its amount.' (True DB: dog_kennels)\n",
      "  Query 750: 'Which owner has paid the largest amount of money in total for their dogs? Show the owner id and zip code.' (True DB: dog_kennels)\n",
      "  Query 751: 'What are the ids for templates that are not used in any documents?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 752: 'What is the name of the singer with the largest net worth?' (True DB: singer)\n",
      "  Query 753: 'What is the maximum and minimum share for the TV series?' (True DB: tvshow)\n",
      "  Query 754: 'Which breed do the most dogs have? Give me the breed name.' (True DB: dog_kennels)\n",
      "  Query 755: 'What is the average weight and year for each year?' (True DB: car_1)\n",
      "  Query 756: 'What are the names of people who do not play poker?' (True DB: poker_player)\n",
      "  Query 757: 'What is the average and maximum capacities for all stadiums ?' (True DB: concert_singer)\n",
      "  Query 758: 'List the first and last name of all players in the order of birth date.' (True DB: wta_1)\n",
      "  Query 759: 'For each stadium, how many concerts play there?' (True DB: concert_singer)\n",
      "  Query 760: 'Show names of teachers and the courses they are arranged to teach in ascending alphabetical order of the teacher's name.' (True DB: course_teach)\n",
      "  Query 761: 'Show the stadium name and capacity with most number of concerts in year 2014 or after.' (True DB: concert_singer)\n",
      "  Query 762: 'What is the name of the course with the most students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 763: 'Return the codes of countries that do not speak English and do not have Republics for governments.' (True DB: world_1)\n",
      "  Query 764: 'Return the name of the airport with code 'AKO'.' (True DB: flight_2)\n",
      "  Query 765: 'What are the notes of the death events which has substring 'East'?' (True DB: battle_death)\n",
      "  Query 766: 'What are the different first names and ages of the students who do have pets?' (True DB: pets_1)\n",
      "  Query 767: 'What is the mobile phone number of the student named Timmothy Ward ?' (True DB: student_transcripts_tracking)\n",
      "  Query 768: 'What are the countries where either English or Dutch is the official language ?' (True DB: world_1)\n",
      "  Query 769: 'Which owners live in the state whose name contains the substring 'North'? List his first name, last name and email.' (True DB: dog_kennels)\n",
      "  Query 770: 'What is the name and capacity for the stadium with highest average attendance?' (True DB: concert_singer)\n",
      "  Query 771: 'Find the semester when both Master students and Bachelor students got enrolled in.' (True DB: student_transcripts_tracking)\n",
      "  Query 772: 'What are the number of concerts that occurred in the stadium with the largest capacity ?' (True DB: concert_singer)\n",
      "  Query 773: 'How many different addresses do the students currently live?' (True DB: student_transcripts_tracking)\n",
      "  Query 774: 'Which department offers the most number of degrees? List department name and id.' (True DB: student_transcripts_tracking)\n",
      "  Query 775: 'What are the ids of the TV channels that do not have any cartoons directed by Ben Jones?' (True DB: tvshow)\n",
      "  Query 776: 'What is the name of each continent and how many car makers are there in each one?' (True DB: car_1)\n",
      "  Query 777: 'Show the names of students who have at least 2 likes.' (True DB: network_1)\n",
      "  Query 778: 'Which of the countries has the most car makers? List the country name.' (True DB: car_1)\n",
      "  Query 779: 'What is the first name of every student who has a dog but does not have a cat?' (True DB: pets_1)\n",
      "  Query 780: 'Which models are lighter than 3500 but not built by the 'Ford Motor Company'?' (True DB: car_1)\n",
      "  Query 781: 'Give the code of the airport with the least flights.' (True DB: flight_2)\n",
      "  Query 782: 'Return the names of poker players sorted by their earnings descending.' (True DB: poker_player)\n",
      "  Query 783: 'Return the id of the document with the fewest paragraphs.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 784: 'What are the names of the countries that are in the continent of Europe and have a population of 80000?' (True DB: world_1)\n",
      "  Query 785: 'Which language is the most popular in Aruba?' (True DB: world_1)\n",
      "  Query 786: 'What is the id of the semester that had both Masters and Bachelors students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 787: 'How many concerts occurred in 2014 or 2015?' (True DB: concert_singer)\n",
      "  Query 788: 'What country is Jetblue Airways affiliated with?' (True DB: flight_2)\n",
      "  Query 789: 'What is the Package Option of TV Channel with serial name \"Sky Radio\"?' (True DB: tvshow)\n",
      "  Query 790: 'What are the countries that have cartoons on TV that were written by Todd Casey?' (True DB: tvshow)\n",
      "  Query 791: 'List the language used least number of TV Channel. List language and number of TV Channel.' (True DB: tvshow)\n",
      "  Query 792: 'What are the names of the teachers whose courses have not been arranged?' (True DB: course_teach)\n",
      "  Query 793: 'Return the number of likes that the high schooler named Kyle has.' (True DB: network_1)\n",
      "  Query 794: 'List the airport code and name in the city of Anthony.' (True DB: flight_2)\n",
      "  Query 795: 'Find the name of tourney that has more than 10 matches.' (True DB: wta_1)\n",
      "  Query 796: 'What region does Angola belong to and what is its population?' (True DB: world_1)\n",
      "  Query 797: 'What are the id, name and membership level of visitors who have spent the largest amount of money in total in all museum tickets?' (True DB: museum_visit)\n",
      "  Query 798: 'Find the government form name and total population for each government form whose average life expectancy is longer than 72.' (True DB: world_1)\n",
      "  Query 799: 'Return the names of friends of the high school student Kyle.' (True DB: network_1)\n",
      "  Query 800: 'Which countries in europe have at least 3 car manufacturers?' (True DB: car_1)\n",
      "  Query 801: 'What are the ids, version numbers, and type codes for each template?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 802: 'What are the names of the contestants whose names are not 'Jessie Alloway'' (True DB: voter_1)\n",
      "  Query 803: 'What are the names of high schoolers who both have friends and are liked?' (True DB: network_1)\n",
      "  Query 804: 'What is the airport name for airport 'AKO'?' (True DB: flight_2)\n",
      "  Query 805: 'Find the name of the winner who has the highest rank points and participated in the Australian Open tourney.' (True DB: wta_1)\n",
      "  Query 806: 'Which countries have either English or Dutch as an official language?' (True DB: world_1)\n",
      "  Query 807: 'How many car models are produced in the usa?' (True DB: car_1)\n",
      "  Query 808: 'What is the average, minimum, and maximum age for all French singers?' (True DB: concert_singer)\n",
      "  Query 809: 'What are the Asian countries which have a population larger than that of any country in Africa?' (True DB: world_1)\n",
      "  Query 810: 'How many countries does each continent have? List the continent id, continent name and the number of countries.' (True DB: car_1)\n",
      "  Query 811: 'What are the codes of countries with more than 50 players?' (True DB: wta_1)\n",
      "  Query 812: 'What are the names of the singers who are not French citizens?' (True DB: singer)\n",
      "  Query 813: 'Which professionals have done at least two treatments? List the professional's id, role, and first name.' (True DB: dog_kennels)\n",
      "  Query 814: 'Show the record companies shared by orchestras founded before 2003 and after 2003.' (True DB: orchestra)\n",
      "  Query 815: 'Find the number of distinct type of pets.' (True DB: pets_1)\n",
      "  Query 816: 'Find the cities that have more than one employee under age 30.' (True DB: employee_hire_evaluation)\n",
      "  Query 817: 'What is the name of the high schooler who has the greatest number of likes?' (True DB: network_1)\n",
      "  Query 818: 'Show names of all high school students who do not have any friends.' (True DB: network_1)\n",
      "  Query 819: 'What languages are only used by a single country with a republic government?' (True DB: world_1)\n",
      "  Query 820: 'What is the average earnings of poker players with height higher than 200?' (True DB: poker_player)\n",
      "  Query 821: 'How much does the car accelerate that makes amc hornet sportabout (sw)?' (True DB: car_1)\n",
      "  Query 822: 'Show the date of the transcript which shows the least number of results, also list the id.' (True DB: student_transcripts_tracking)\n",
      "  Query 823: 'How many documents are using the template with type code 'PPT'?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 824: 'Which model saves the most gasoline? That is to say, have the maximum miles per gallon.' (True DB: car_1)\n",
      "  Query 825: 'Find number of pets owned by students who are older than 20.' (True DB: pets_1)\n",
      "  Query 826: 'What are the students' first names who have both cats and dogs as pets?' (True DB: pets_1)\n",
      "  Query 827: 'Please show the different record companies and the corresponding number of orchestras.' (True DB: orchestra)\n",
      "  Query 828: 'Count the number of paragraphs in the document named 'Summer Show'.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 829: 'What are the distinct battle names which are between bulgarian commander 'Kaloyan' and latin commander 'Baldwin I'?' (True DB: battle_death)\n",
      "  Query 830: 'What is the age and hometown of every teacher?' (True DB: course_teach)\n",
      "  Query 831: 'What is the car model with the highest mpg ?' (True DB: car_1)\n",
      "  Query 832: 'Show all paragraph texts for the document \"Customer reviews\".' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 833: 'What are airlines that have flights arriving at airport 'AHD'?' (True DB: flight_2)\n",
      "  Query 834: 'What are the ids and names of the battles that led to more than 10 people killed in total.' (True DB: battle_death)\n",
      "  Query 835: 'How many cars have more than 4 cylinders?' (True DB: car_1)\n",
      "  Query 836: 'What is the feature type name of feature AirCon?' (True DB: real_estate_properties)\n",
      "  Query 837: 'How many type of governments are in Africa?' (True DB: world_1)\n",
      "  Query 838: 'Find the id of the pet owned by student whose last name is ‘Smith’.' (True DB: pets_1)\n",
      "  Query 839: 'Find all airlines that have at least 10 flights.' (True DB: flight_2)\n",
      "  Query 840: 'Which dogs are of the rarest breed? Show their names and treatment dates.' (True DB: dog_kennels)\n",
      "  Query 841: 'How many singers do we have?' (True DB: concert_singer)\n",
      "  Query 842: 'What are the makers and models?' (True DB: car_1)\n",
      "  Query 843: 'Find the total number of tours for each ranking date.' (True DB: wta_1)\n",
      "  Query 844: 'How many degrees does the engineering department have?' (True DB: student_transcripts_tracking)\n",
      "  Query 845: 'What are the names of people who are not from Russia?' (True DB: poker_player)\n",
      "  Query 846: 'How many transcripts are listed?' (True DB: student_transcripts_tracking)\n",
      "  Query 847: 'Find the first name, country code and birth date of the winner who has the highest rank points in all matches.' (True DB: wta_1)\n",
      "  Query 848: 'find the minimum and maximum number of products of all stores.' (True DB: employee_hire_evaluation)\n",
      "  Query 849: 'How many pets have a greater weight than 10?' (True DB: pets_1)\n",
      "  Query 850: 'Show names of teachers that teach at least two courses.' (True DB: course_teach)\n",
      "  Query 851: 'What are the different ids and names of the battles that lost any 'Brig' type shipes?' (True DB: battle_death)\n",
      "  Query 852: 'Give the names of the nations that were founded after 1950.' (True DB: world_1)\n",
      "  Query 853: 'What are the full names of all left handed players, in order of birth date?' (True DB: wta_1)\n",
      "  Query 854: 'What are the region and population of Angola?' (True DB: world_1)\n",
      "  Query 855: 'How many cars has over 6 cylinders?' (True DB: car_1)\n",
      "  Query 856: 'What is the first, middle, and last name, along with the id and number of enrollments, for the student who enrolled the most in any program?' (True DB: student_transcripts_tracking)\n",
      "  Query 857: 'What are the names and grades for each high schooler?' (True DB: network_1)\n",
      "  Query 858: 'What are flight numbers of flights arriving at City \"Aberdeen\"?' (True DB: flight_2)\n",
      "  Query 859: 'Show countries where a singer above age 40 and a singer below 30 are from.' (True DB: concert_singer)\n",
      "  Query 860: 'What are the names of the nations with the 3 lowest populations?' (True DB: world_1)\n",
      "  Query 861: 'What is the document name and template id for document with description with the letter 'w' in it?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 862: 'How many teachers are there?' (True DB: course_teach)\n",
      "  Query 863: 'How much does the most recent treatment cost?' (True DB: dog_kennels)\n",
      "  Query 864: 'List all cartoon directed by \"Ben Jones\".' (True DB: tvshow)\n",
      "  Query 865: 'Show the names of all of the high schooler Kyle's friends.' (True DB: network_1)\n",
      "  Query 866: 'What is the maximum capacity and the average of all stadiums ?' (True DB: concert_singer)\n",
      "  Query 867: 'What is the content of the series Sky Radio?' (True DB: tvshow)\n",
      "  Query 868: 'What are the names of the singers who performed in a concert in 2014?' (True DB: concert_singer)\n",
      "  Query 869: 'How many flights have destination ATO?' (True DB: flight_2)\n",
      "  Query 870: 'Which employee received the most awards in evaluations? Give me the employee name.' (True DB: employee_hire_evaluation)\n",
      "  Query 871: 'What are the major record formats of orchestras, sorted by their frequency?' (True DB: orchestra)\n",
      "  Query 872: 'What are the ids of documents that contain the paragraph text 'Brazil' and 'Ireland'?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 873: 'Return the type code of the template type that the most templates belong to.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 874: 'Give the name of the nation that uses the greatest amount of languages.' (True DB: world_1)\n",
      "  Query 875: 'How many paragraphs in total?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 876: 'Return the code of the template type that is most commonly used in documents.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 877: 'What is the year that had the most concerts?' (True DB: concert_singer)\n",
      "  Query 878: 'What are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?' (True DB: concert_singer)\n",
      "  Query 879: 'What is the area code in which the most voters voted?' (True DB: voter_1)\n",
      "  Query 880: 'Show names, results and bulgarian commanders of the battles with no ships lost in the 'English Channel'.' (True DB: battle_death)\n",
      "  Query 881: 'What is the number of cars with a horsepower greater than 150?' (True DB: car_1)\n",
      "  Query 882: 'What are the cost and treatment type description of each treatment?' (True DB: dog_kennels)\n",
      "  Query 883: 'What are the ids and makers of all car makers that produce at least 2 models and make more than 3 cars?' (True DB: car_1)\n",
      "  Query 884: 'How many different nationalities do conductors have?' (True DB: orchestra)\n",
      "  Query 885: 'Return the codes of countries for which Spanish is the predominantly spoken language.' (True DB: world_1)\n",
      "  Query 886: 'Count the number of different templates used for documents.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 887: 'What are the different continents and the total popuation and average life expectancy corresponding to each, for continents that have an average life expectancy less than 72?' (True DB: world_1)\n",
      "  Query 888: 'Find the total ranking points for each player and their first name.' (True DB: wta_1)\n",
      "  Query 889: 'How long is the people’s average life expectancy in Central Africa?' (True DB: world_1)\n",
      "  Query 890: 'Find the last name of the students who currently live in the state of North Carolina but have not registered in any degree program.' (True DB: student_transcripts_tracking)\n",
      "  Query 891: 'List the cost of each treatment and the corresponding treatment type description.' (True DB: dog_kennels)\n",
      "  Query 892: 'How many high schoolers are in each grade?' (True DB: network_1)\n",
      "  Query 893: 'What are the ids and texts of paragraphs in the document titled 'Welcome to NY'?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 894: 'For each citizenship, what is the maximum net worth?' (True DB: singer)\n",
      "  Query 895: 'What is the average edispl of the cars of model volvo?' (True DB: car_1)\n",
      "  Query 896: 'How many different degree names are offered?' (True DB: student_transcripts_tracking)\n",
      "  Query 897: 'Show the name of singers whose birth year is either 1948 or 1949?' (True DB: singer)\n",
      "  Query 898: 'Which airlines have less than 200 flights?' (True DB: flight_2)\n",
      "  Query 899: 'How many singers are there?' (True DB: singer)\n",
      "  Query 900: 'What are the names of properties that are either houses or apartments with more than 1 room?' (True DB: real_estate_properties)\n",
      "  Query 901: 'What are the type codes and descriptions for all template types?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 902: 'What is the total count of teachers?' (True DB: course_teach)\n",
      "  Query 903: 'What are the names of conductors, sorted descending by the number of years they have worked?' (True DB: orchestra)\n",
      "  Query 904: 'Find the number of left handed winners who participated in the WTA Championships.' (True DB: wta_1)\n",
      "  Query 905: 'Return the ids corresponding to templates with the description 'Presentation'.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 906: 'What region is Kabul in?' (True DB: world_1)\n",
      "  Query 907: 'Show all document ids, names and the number of paragraphs in each document.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 908: 'What is the best rank of losers across all matches?' (True DB: wta_1)\n",
      "  Query 909: 'How many airports do we have?' (True DB: flight_2)\n",
      "  Query 910: 'What are the ids of templates with template type code PP or PPT?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 911: 'How many visitors below age 30 are there?' (True DB: museum_visit)\n",
      "  Query 912: 'Show the name and theme for all concerts and the number of singers in each concert.' (True DB: concert_singer)\n",
      "  Query 913: 'List the maximum weight and type for each type of pet.' (True DB: pets_1)\n",
      "  Query 914: 'Return the name of the high school student with the most friends.' (True DB: network_1)\n",
      "  Query 915: 'What is the most populace city that speaks English?' (True DB: world_1)\n",
      "  Query 916: 'Give the city and country for the Alton airport.' (True DB: flight_2)\n",
      "  Query 917: 'List the names of people that are not poker players.' (True DB: poker_player)\n",
      "  Query 918: 'Return the document id, template id, and description for the document with the name Robbin CV.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 919: 'Show names of people whose nationality is not \"Russia\".' (True DB: poker_player)\n",
      "  Query 920: 'How much does the youngest dog weigh?' (True DB: pets_1)\n",
      "  Query 921: 'What are the template ids with template type description \"Presentation\".' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 922: 'Find the arriving date and the departing date of the dogs that received a treatment.' (True DB: dog_kennels)\n",
      "  Query 923: 'What is the description of the treatment type that costs the least money in total?' (True DB: dog_kennels)\n",
      "  Query 924: 'What are the id and name of the museum visited most times?' (True DB: museum_visit)\n",
      "  Query 925: 'Return the birth date of the poker player with the lowest earnings.' (True DB: poker_player)\n",
      "  Query 926: 'What are the record companies of orchestras in descending order of years in which they were founded?' (True DB: orchestra)\n",
      "  Query 927: 'What are the record companies that are used by both orchestras founded before 2003 and those founded after 2003?' (True DB: orchestra)\n",
      "  Query 928: 'Which owner owns the most dogs? List the owner id, first name and last name.' (True DB: dog_kennels)\n",
      "  Query 929: 'What are the package options and the name of the series for the TV Channel that supports high definition TV?' (True DB: tvshow)\n",
      "  Query 930: 'How many countries are listed?' (True DB: car_1)\n",
      "  Query 931: 'Find the name, population and expected life length of asian country with the largest area?' (True DB: world_1)\n",
      "  Query 932: 'How many players are there for each hand type?' (True DB: wta_1)\n",
      "  Query 933: 'What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?' (True DB: car_1)\n",
      "  Query 934: 'Show the ID of the high schooler named Kyle.' (True DB: network_1)\n",
      "  Query 935: 'What is the name of the singer who is worth the most?' (True DB: singer)\n",
      "  Query 936: 'What type of pet is the youngest animal, and how much does it weigh?' (True DB: pets_1)\n",
      "  Query 937: 'What are the names of the stadiums without any concerts?' (True DB: concert_singer)\n",
      "  Query 938: 'What is the age of the oldest dog?' (True DB: dog_kennels)\n",
      "  Query 939: 'how many countries are in Asia?' (True DB: world_1)\n",
      "  Query 940: 'What is the total number of countries where Spanish is spoken by the largest percentage of people?' (True DB: world_1)\n",
      "  Query 941: 'Return the nationalities for which there are two or more people.' (True DB: poker_player)\n",
      "  Query 942: 'Show the date and id of the transcript with at least 2 course results.' (True DB: student_transcripts_tracking)\n",
      "  Query 943: 'Find the maximum weight for each type of pet. List the maximum weight and pet type.' (True DB: pets_1)\n",
      "  Query 944: 'What is the total number of people living in the nations that do not use English?' (True DB: world_1)\n",
      "  Query 945: 'Count the number of high schoolers in grades 9 or 10.' (True DB: network_1)\n",
      "  Query 946: 'Which African countries have a smaller population than that of any country in Asia?' (True DB: world_1)\n",
      "  Query 947: 'What are the different years in which there were cars produced that weighed less than 4000 and also cars that weighted more than 3000 ?' (True DB: car_1)\n",
      "  Query 948: 'What are the towns from which at least two teachers come from?' (True DB: course_teach)\n",
      "  Query 949: 'Return the grade that has the greatest number of high schoolers.' (True DB: network_1)\n",
      "  Query 950: 'Find the districts in which there are both shops selling less than 3000 products and shops selling more than 10000 products.' (True DB: employee_hire_evaluation)\n",
      "  Query 951: 'What are the names of singers ordered by ascending net worth?' (True DB: singer)\n",
      "  Query 952: 'What are the names of tournaments that have more than 10 matches?' (True DB: wta_1)\n",
      "  Query 953: 'How many pets are owned by students that have an age greater than 20?' (True DB: pets_1)\n",
      "  Query 954: 'What are the first, middle, and last names, along with the ids, of all students who enrolled in 2 degree programs in one semester?' (True DB: student_transcripts_tracking)\n",
      "  Query 955: 'Find all airlines that have fewer than 200 flights.' (True DB: flight_2)\n",
      "  Query 956: 'What are the different addresses that have students living there?' (True DB: student_transcripts_tracking)\n",
      "  Query 957: 'What are the email, cell phone and home phone of each professional?' (True DB: dog_kennels)\n",
      "  Query 958: 'What are the names of the teachers and how many courses do they teach?' (True DB: course_teach)\n",
      "  Query 959: 'What are the languages used by the least number of TV Channels and how many channels use it?' (True DB: tvshow)\n",
      "  Query 960: 'What is the degree summary name that has the most number of students enrolled?' (True DB: student_transcripts_tracking)\n",
      "  Query 961: 'What are the population, name and leader of the country with the largest area?' (True DB: world_1)\n",
      "  Query 962: 'Find the owner id and zip code of the owner who spent the most money in total for his or her dogs.' (True DB: dog_kennels)\n",
      "  Query 963: 'Whose permanent address is different from his or her current address? List his or her first name.' (True DB: student_transcripts_tracking)\n",
      "  Query 964: 'Find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.' (True DB: concert_singer)\n",
      "  Query 965: 'What is the maximum accelerate for different number of cylinders?' (True DB: car_1)\n",
      "  Query 966: 'What is the horsepower of the car with the greatest accelerate?' (True DB: car_1)\n",
      "  Query 967: 'Find the number of dog pets that are raised by female students (with sex F).' (True DB: pets_1)\n",
      "  Query 968: 'How many battles did not lose any ship with tonnage '225'?' (True DB: battle_death)\n",
      "  Query 969: 'Find the average grade of all students who have some friends.' (True DB: network_1)\n",
      "  Query 970: 'What are all of the episodes ordered by ratings?' (True DB: tvshow)\n",
      "  Query 971: 'Find the number of professionals who have not treated any dogs.' (True DB: dog_kennels)\n",
      "  Query 972: 'What is the largest amount of horsepower for the models with 3 cylinders and what make is it?' (True DB: car_1)\n",
      "  Query 973: 'What is the grade of each high schooler?' (True DB: network_1)\n",
      "  Query 974: 'How many different results are there for the battles?' (True DB: battle_death)\n",
      "  Query 975: 'Return the number of  airports.' (True DB: flight_2)\n",
      "  Query 976: 'Find the last name of the student who has a cat that is age 3.' (True DB: pets_1)\n",
      "  Query 977: 'List the title of all cartoons in alphabetical order.' (True DB: tvshow)\n",
      "  Query 978: 'What are all the song names by singers who are older than average?' (True DB: concert_singer)\n",
      "  Query 979: 'What is the version number and template type code for the template with version number later than 5?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 980: 'How many car makers are there in each continents? List the continent name and the count.' (True DB: car_1)\n",
      "  Query 981: 'Which professionals have operated a treatment that costs less than the average? Give me theor first names and last names.' (True DB: dog_kennels)\n",
      "  Query 982: 'What are the codes of template types that are not used for any document?' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 983: 'How many flights depart from 'APG'?' (True DB: flight_2)\n",
      "  Query 984: 'Sort employee names by their age in ascending order.' (True DB: employee_hire_evaluation)\n",
      "  Query 985: 'Give the mean GNP and total population of nations which are considered US territory.' (True DB: world_1)\n",
      "  Query 986: 'Which continent is Anguilla in?' (True DB: world_1)\n",
      "  Query 987: 'List the earnings of poker players in descending order.' (True DB: poker_player)\n",
      "  Query 988: 'What is the maximum horsepower and the make of the car models with 3 cylinders?' (True DB: car_1)\n",
      "  Query 989: 'What are the country codes of the different countries, and what are the languages spoken by the greatest percentage of people for each?' (True DB: world_1)\n",
      "  Query 990: 'find the name of employee who was awarded the most times in the evaluation.' (True DB: employee_hire_evaluation)\n",
      "  Query 991: 'How many countries have governments that are republics?' (True DB: world_1)\n",
      "  Query 992: 'When was the last transcript released?' (True DB: student_transcripts_tracking)\n",
      "  Query 993: 'Find the role, street, city and state of the professionals living in a city that contains the substring 'West'.' (True DB: dog_kennels)\n",
      "  Query 994: 'Return the version numbers and template type codes of templates with a version number greater than 5.' (True DB: cre_Doc_Template_Mgt)\n",
      "  Query 995: 'Which flight numbers correspond to United Airlines flights?' (True DB: flight_2)\n",
      "  Query 996: 'What are the names of the teachers whose hometown is not `` Little Lever Urban District '' ?' (True DB: course_teach)\n",
      "  Query 997: 'Show titles of songs and names of singers.' (True DB: singer)\n",
      "  Query 998: 'What are the average and maximum number of tickets bought in all visits?' (True DB: museum_visit)\n",
      "  Query 999: 'What is the first name and gender of the all the students who have more than one pet?' (True DB: pets_1)\n",
      "  Query 1000: 'Count the number of employees' (True DB: employee_hire_evaluation)\n",
      "  Query 1001: 'Which dogs have not cost their owner more than 1000 for treatment ? List the dog names .' (True DB: dog_kennels)\n",
      "  Query 1002: 'Return the country name and the numbers of languages spoken for each country that speaks at least 3 languages.' (True DB: world_1)\n",
      "  Query 1003: 'Who is enrolled in a Bachelor degree program? List the first name, middle name, last name.' (True DB: student_transcripts_tracking)\n",
      "  Query 1004: 'What are all the possible breed type and size type combinations?' (True DB: dog_kennels)\n",
      "  Query 1005: 'Who is the earliest graduate of the school? List the first name, middle name and last name.' (True DB: student_transcripts_tracking)\n",
      "  Query 1006: 'What are the titles of all cartoons directed by Ben Jones or Brandon Vietti?' (True DB: tvshow)\n",
      "  Query 1007: 'What is the name of the winner who has won the most matches, and how many rank points does this player have?' (True DB: wta_1)\n",
      "  Query 1008: 'What are the countries having at least one car maker? List name and id.' (True DB: car_1)\n",
      "  Query 1009: 'Find the first names that are used for professionals or owners but are not used as dog names.' (True DB: dog_kennels)\n",
      "  Query 1010: 'Which states have both owners and professionals living there?' (True DB: dog_kennels)\n",
      "  Query 1011: 'What is the name of the high schooler who has the greatest number of friends?' (True DB: network_1)\n",
      "  Query 1012: 'What are the nationalities that are shared by at least two people?' (True DB: poker_player)\n",
      "  Query 1013: 'What is the total number of unique official languages spoken in the countries that are founded before 1930?' (True DB: world_1)\n",
      "  Query 1014: 'What is the average transcript date?' (True DB: student_transcripts_tracking)\n",
      "  Query 1015: 'Which cities do more than one employee under age 30 come from?' (True DB: employee_hire_evaluation)\n",
      "  Query 1016: 'What are the last name of the students who live in North Carolina but have not registered in any degree programs?' (True DB: student_transcripts_tracking)\n",
      "  Query 1017: 'What are the full names of all players, sorted by birth date?' (True DB: wta_1)\n",
      "  Query 1018: 'What are the birth year and citizenship of singers?' (True DB: singer)\n",
      "  Query 1019: 'Find the number of matches happened in each year.' (True DB: wta_1)\n",
      "  Query 1020: 'Which city is the most frequent source airport?' (True DB: flight_2)\n",
      "  Query 1021: 'What is the total ticket expense of the visitors whose membership level is 1?' (True DB: museum_visit)\n",
      "  Query 1022: 'what is the name and nation of the singer who have a song having 'Hey' in its name?' (True DB: concert_singer)\n",
      "  Query 1023: 'Find the average ranking for each player and their first name.' (True DB: wta_1)\n",
      "  Query 1024: 'List all the student details in reversed lexicographical order.' (True DB: student_transcripts_tracking)\n",
      "  Query 1025: 'What is the average miles per gallon of all the cards with 4 cylinders?' (True DB: car_1)\n",
      "  Query 1026: 'Which airlines have a flight with destination airport AHD?' (True DB: flight_2)\n",
      "  Query 1027: 'What are the names of the countries with no car makers?' (True DB: car_1)\n",
      "  Query 1028: 'Find the total number of players.' (True DB: wta_1)\n",
      "  Query 1029: 'What is the average weight for each type of pet?' (True DB: pets_1)\n",
      "  Query 1030: 'Give the name of the country in Asia with the lowest life expectancy.' (True DB: world_1)\n",
      "  Query 1031: 'Give the average life expectancy for countries in Africa which are republics?' (True DB: world_1)\n",
      "  Query 1032: 'Return the money rank of the poker player with the greatest height.' (True DB: poker_player)\n",
      "  Query 1033: 'Give the flight numbers of flights leaving from Aberdeen.' (True DB: flight_2)\n",
      "  Query 1034: 'Among the cars with more than lowest horsepower, which ones do not have more than 3 cylinders? List the car makeid and make name.' (True DB: car_1)\n",
      "\n",
      "Each of the 1034 selected queries will be evaluated against all 0 available Spider database schemas.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEach of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(selected_nl_queries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m selected queries will be evaluated against all \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(candidate_schemas_for_evaluation)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m available Spider database schemas.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidate_schemas_for_evaluation:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "TEXT_QUERIES_FILE = \"/raid/infolab/gaurav/Llama_Spider_A100_Project/all_queries.txt\"\n",
    "\n",
    "if not os.path.exists(TEXT_QUERIES_FILE):\n",
    "    raise FileNotFoundError(f\"Cannot find '{TEXT_QUERIES_FILE}' – make sure it’s in your working directory or update the path.\")\n",
    "\n",
    "selected_nl_queries = []\n",
    "pattern = re.compile(r\"Test Query\\s+\\d+:\\s+'(.+)'\\s+\\(True DB:\\s*([^)]+)\\)\")\n",
    "\n",
    "with open(TEXT_QUERIES_FILE, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        line = line.strip()\n",
    "        if not line.startswith(\"Test Query\"):\n",
    "            continue\n",
    "\n",
    "        m = pattern.match(line)\n",
    "        if not m:\n",
    "            print(f\"Warning: could not parse line:\\n  {line}\")\n",
    "            continue\n",
    "\n",
    "        question_text = m.group(1)\n",
    "        true_db_id    = m.group(2)\n",
    "\n",
    "        selected_nl_queries.append({\n",
    "            \"question\": question_text,\n",
    "            \"db_id\":    true_db_id\n",
    "        })\n",
    "\n",
    "if len(selected_nl_queries) == 0:\n",
    "    raise ValueError(f\"No queries were parsed from '{TEXT_QUERIES_FILE}'. Check your file’s format.\")\n",
    "\n",
    "print(f\"Loaded {len(selected_nl_queries)} queries from '{TEXT_QUERIES_FILE}':\")\n",
    "for i, q in enumerate(selected_nl_queries, 1):\n",
    "    print(f\"  Query {i}: '{q['question']}' (True DB: {q['db_id']})\")\n",
    "\n",
    "\n",
    "candidate_schemas_for_evaluation = all_db_schemas_sql_strings\n",
    "print(f\"\\nEach of the {len(selected_nl_queries)} selected queries will be evaluated against all {len(candidate_schemas_for_evaluation)} available Spider database schemas.\")\n",
    "\n",
    "if not candidate_schemas_for_evaluation:\n",
    "    raise ValueError(\"No candidate schemas available for evaluation. This indicates an issue with schema loading or conversion in Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac0d7cb-81c6-487c-b796-ba1594a76912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured experiment project directory exists: '/raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1'\n",
      "Experiment results will be saved to: /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_queries_llama3.1_8B-instruct-prompt_codeS_synthetic_data_all_DB.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "LOCAL_EXPERIMENT_BASE_DIR = \"/raid/infolab/gaurav/Llama_Spider_A100_Project/\"\n",
    "\n",
    "EXPERIMENT_RUN_NAME = \"randomQ_allDBs_run1\" \n",
    "EXPERIMENT_PROJECT_DIR = os.path.join(LOCAL_EXPERIMENT_BASE_DIR, EXPERIMENT_RUN_NAME)\n",
    "\n",
    "try:\n",
    "    os.makedirs(EXPERIMENT_PROJECT_DIR, exist_ok=True)\n",
    "    print(f\"Ensured experiment project directory exists: '{EXPERIMENT_PROJECT_DIR}'\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory {EXPERIMENT_PROJECT_DIR}: {e}\")\n",
    "    EXPERIMENT_PROJECT_DIR = \".\" \n",
    "\n",
    "\n",
    "RESULTS_FILENAME = \"spider_queries_llama3.1_8B-instruct-prompt_codeS_synthetic_data_all_DB.json\"\n",
    "EXPERIMENT_RESULTS_FILE = os.path.join(EXPERIMENT_PROJECT_DIR, RESULTS_FILENAME)\n",
    "\n",
    "print(f\"Experiment results will be saved to: {EXPERIMENT_RESULTS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e29bb982-09ab-4d61-9888-a306afab0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function 'get_one_zero_token_ids' defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell defining get_one_zero_token_ids\n",
    "\n",
    "def get_one_zero_token_ids(tokenizer_arg):\n",
    "    \"\"\"\n",
    "    Determines the single token IDs for the characters '1' and '0'.\n",
    "    It's crucial these are single tokens for the logit logic to work.\n",
    "    \"\"\"\n",
    "    # Llama 3 tokenizer handles single digits with leading spaces well.\n",
    "    one_token_id = tokenizer_arg.encode(\" 1\", add_special_tokens=False)\n",
    "    zero_token_id = tokenizer_arg.encode(\" 0\", add_special_tokens=False)\n",
    "\n",
    "    if len(one_token_id) == 1 and len(zero_token_id) == 1:\n",
    "        print(\"Using ' 1' and ' 0' (with leading space) for token IDs.\")\n",
    "        return one_token_id[0], zero_token_id[0]\n",
    "    \n",
    "    # Fallback in case the model prefers no space (less common for instruction models)\n",
    "    one_token_id_no_space = tokenizer_arg.encode(\"1\", add_special_tokens=False)\n",
    "    zero_token_id_no_space = tokenizer_arg.encode(\"0\", add_special_tokens=False)\n",
    "\n",
    "    if len(one_token_id_no_space) == 1 and len(zero_token_id_no_space) == 1:\n",
    "        print(\"Using '1' and '0' (no leading space) for token IDs.\")\n",
    "        return one_token_id_no_space[0], zero_token_id_no_space[0]\n",
    "        \n",
    "    else:\n",
    "        # If neither works, there's a problem with the tokenizer for this task.\n",
    "        print(f\"ERROR: Could not determine reliable single token IDs for '1' or '0'.\")\n",
    "        print(f\"Tokenization of ' 1': {one_token_id}\")\n",
    "        print(f\"Tokenization of ' 0': {zero_token_id}\")\n",
    "        print(f\"Tokenization of '1': {one_token_id_no_space}\")\n",
    "        print(f\"Tokenization of '0': {zero_token_id_no_space}\")\n",
    "        raise ValueError(\"Unstable tokenization for '1'/'0'. Cannot proceed.\")\n",
    "\n",
    "print(\"Helper function 'get_one_zero_token_ids' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3beb68b-141a-4791-a467-ab1456a8ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using '1' and '0' (no leading space) for token IDs.\n",
      "ONE_TOKEN_ID: 16 ('1')\n",
      "ZERO_TOKEN_ID: 15 ('0')\n"
     ]
    }
   ],
   "source": [
    "# This cell defines the global token IDs for '1' and '0'\n",
    "if 'tokenizer' in globals() and tokenizer is not None:\n",
    "    try:\n",
    "        ONE_TOKEN_ID, ZERO_TOKEN_ID = get_one_zero_token_ids(tokenizer)\n",
    "        print(f\"ONE_TOKEN_ID: {ONE_TOKEN_ID} ('{tokenizer.decode([ONE_TOKEN_ID])}')\")\n",
    "        print(f\"ZERO_TOKEN_ID: {ZERO_TOKEN_ID} ('{tokenizer.decode([ZERO_TOKEN_ID])}')\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error defining 1/0 token IDs: {e}\")\n",
    "else:\n",
    "    print(\"ERROR: 'tokenizer' is not defined. Cannot define token IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7608e9e0-7e71-4e2f-bd0e-85ca55dd0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core function 'get_schema_match_prediction' defined.\n"
     ]
    }
   ],
   "source": [
    "import torch # Ensure torch is imported\n",
    "\n",
    "# --- Core function to get P(1) and the binary decision ---\n",
    "def get_schema_match_prediction(model_arg, tokenizer_arg, system_prompt_arg, user_prompt_content_arg, one_token_id_arg, zero_token_id_arg, max_length=model.config.max_position_embeddings):\n",
    "    \"\"\"\n",
    "    Gets the model's prediction (1 or 0) and the probability score for that decision.\n",
    "    Returns a tuple: (binary_decision, probability_of_one)\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_arg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_content_arg}\n",
    "    ]\n",
    "\n",
    "    prompt_for_model = tokenizer_arg.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # print(prompt_for_model)\n",
    "\n",
    "    inputs = tokenizer_arg(\n",
    "        prompt_for_model,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length - 10\n",
    "    )\n",
    "    inputs = {k: v.to(model_arg.device) for k, v in inputs.items()}\n",
    "\n",
    "    if inputs['input_ids'].shape[1] >= max_length - 10:\n",
    "         print(f\"Warning: Prompt for query was truncated. Length: {inputs['input_ids'].shape[1]}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_arg(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # Get the logits for the very next token to be generated\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        \n",
    "        # Get the specific logits for the '1' and '0' tokens\n",
    "        logit_one = next_token_logits[:, one_token_id_arg].item()\n",
    "        logit_zero = next_token_logits[:, zero_token_id_arg].item()\n",
    "\n",
    "    # --- Make the decision based on which logit is higher ---\n",
    "    binary_decision = 1 if logit_one > logit_zero else 0\n",
    "\n",
    "    # --- Calculate the probability using the softmax function on the two logits ---\n",
    "    # This correctly converts the logits into a probability score for '1'\n",
    "    max_logit = max(logit_one, logit_zero)\n",
    "    exp_one = torch.exp(torch.tensor(logit_one - max_logit))\n",
    "    exp_zero = torch.exp(torch.tensor(logit_zero - max_logit))\n",
    "    \n",
    "    prob_one = exp_one / (exp_one + exp_zero)\n",
    "    \n",
    "    return (binary_decision, prob_one.item())\n",
    "\n",
    "print(\"Core function 'get_schema_match_prediction' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803de059-9514-4d09-b14e-b5e21e1ae14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM_PROMPT and USER_PROMPT_TEMPLATE have been customized for schemas with representative values.\n"
     ]
    }
   ],
   "source": [
    "# --- Prompt Configuration for Binary (1/0) Output (Corrected & Customized for Value HINTS) ---\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert system that determines if a natural language question can be answered using ONLY the provided database schema.\n",
    "The schema includes sample values for some columns; treat these as HINTS to understand the column's content, not as a complete list.\n",
    "Your task is to respond with a single character: '1' if the question is answerable, or '0' if it is not.\n",
    "Do not provide any explanations or other text. Just '1' or '0'.\n",
    "\"\"\"\n",
    "\n",
    "# This template's examples teach the model how to correctly interpret the 'values' field as a hint.\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "# Now, you are provided by the schema followed by some questions that can be answered by the following schema:\n",
    "\n",
    "[Schema:\n",
    "{schema_string}\n",
    "]\n",
    "\n",
    "# Task: Can the following question be answered using the above schema? Respond with 1 (Yes) or 0 (No).\n",
    "Q: {nl_query}\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "print(\"SYSTEM_PROMPT and USER_PROMPT_TEMPLATE have been customized for schemas with representative values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37250ba8-97bf-47db-9329-2a265c5de7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found existing results file. Loading progress from '/raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_queries_llama3.1_8B-instruct-prompt_codeS_synthetic_data_all_DB.json'\n",
      "Loaded results for 1034 queries. Resuming...\n",
      "\n",
      "--- Starting Experiment: 1034 Queries vs. 166 Schemas ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710c368a24554d1fb9133bf92fc427f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NL Queries:   0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Loop Finished ---\n",
      "\n",
      "Processed a total of 1034 unique queries.\n",
      "Final results successfully saved to /raid/infolab/gaurav/Llama_Spider_A100_Project/randomQ_allDBs_run1/spider_queries_llama3.1_8B-instruct-prompt_codeS_synthetic_data_all_DB.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# This dictionary will hold all results.\n",
    "experiment_all_query_results = []\n",
    "\n",
    "# --- 1. Resume from Previous Run (if applicable) ---\n",
    "if os.path.exists(EXPERIMENT_RESULTS_FILE):\n",
    "    print(f\"INFO: Found existing results file. Loading progress from '{EXPERIMENT_RESULTS_FILE}'\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'r') as f:\n",
    "            experiment_all_query_results = json.load(f)\n",
    "        print(f\"Loaded results for {len(experiment_all_query_results)} queries. Resuming...\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"WARNING: Results file '{EXPERIMENT_RESULTS_FILE}' is corrupted. Starting from scratch.\")\n",
    "        experiment_all_query_results = []\n",
    "\n",
    "# Create a set of already completed query IDs for quick checking\n",
    "completed_query_ids = {res['experiment_query_id'] for res in experiment_all_query_results}\n",
    "\n",
    "# --- 2. Define the Schemas to be Used in the Experiment ---\n",
    "# This is the key change: ensure we are using the new CODES-style prompts.\n",
    "# We also add a check to make sure the prompts were actually generated.\n",
    "if 'all_db_schemas_codes_style_prompts' in globals() and all_db_schemas_codes_style_prompts:\n",
    "    candidate_schemas_for_evaluation = all_db_schemas_codes_style_prompts\n",
    "else:\n",
    "    raise NameError(\"The 'all_db_schemas_codes_style_prompts' variable is not defined. Please run the prompt generation cell first.\")\n",
    "\n",
    "\n",
    "# --- 3. Start the Main Experiment Loop ---\n",
    "print(f\"\\n--- Starting Experiment: {len(selected_nl_queries)} Queries vs. {len(candidate_schemas_for_evaluation)} Schemas ---\")\n",
    "\n",
    "# Outer loop: Iterate through each NL query\n",
    "for query_idx, nl_query_info in enumerate(tqdm(selected_nl_queries, desc=\"Processing NL Queries\")):\n",
    "    current_nl_query_text = nl_query_info['question']\n",
    "    true_db_id_for_query = nl_query_info['db_id']\n",
    "    \n",
    "    # Create a unique ID for this query instance to handle resuming runs\n",
    "    # Using 'query_idx' ensures a stable ID across runs\n",
    "    experiment_query_id = f\"spider_dev_q{query_idx}_idx{query_idx}\"\n",
    "\n",
    "    # Skip if this query has already been processed in a previous run\n",
    "    if experiment_query_id in completed_query_ids:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Query {query_idx + 1}/{len(selected_nl_queries)} (ID: {experiment_query_id}): '{current_nl_query_text}' (True DB: {true_db_id_for_query})\")\n",
    "\n",
    "    # This list will store the results for the current query against all schemas\n",
    "    predictions_for_current_query = []\n",
    "\n",
    "    # Inner loop: Iterate through each candidate database schema\n",
    "    for candidate_db_id, candidate_schema_prompt in tqdm(candidate_schemas_for_evaluation.items(), desc=f\"  DBs for Q:{experiment_query_id[:20]}\", leave=False):\n",
    "        user_prompt_content = USER_PROMPT_TEMPLATE.format(\n",
    "            schema_string=candidate_schema_prompt, # Use the new prompt\n",
    "            nl_query=current_nl_query_text\n",
    "        )\n",
    "        \n",
    "        # Default values in case of an error during model inference\n",
    "        binary_decision = -1 \n",
    "        p_one_score = -1.0\n",
    "\n",
    "        try:\n",
    "            # Call the model to get the prediction (1 or 0) and the probability\n",
    "            binary_decision, p_one_score = get_schema_match_prediction(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                SYSTEM_PROMPT,\n",
    "                user_prompt_content,\n",
    "                ONE_TOKEN_ID,\n",
    "                ZERO_TOKEN_ID\n",
    "            )\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"    ERROR: Exception during model inference for Query ID '{experiment_query_id}' with DB '{candidate_db_id}'.\")\n",
    "            print(f\"    Exception type: {type(e).__name__}, Message: {e}\")\n",
    "\n",
    "        # Store the results for this specific query-schema pair\n",
    "        predictions_for_current_query.append({\n",
    "            'candidate_db_id': candidate_db_id,\n",
    "            'decision': binary_decision,\n",
    "            'p_one_score': p_one_score\n",
    "        })\n",
    "\n",
    "    # After scoring all candidates, sort them by the probability of being answerable (p_one_score)\n",
    "    ranked_databases_for_query = sorted(predictions_for_current_query, key=lambda x: x['p_one_score'], reverse=True)\n",
    "\n",
    "    # Store the comprehensive result for this single NL query\n",
    "    experiment_all_query_results.append({\n",
    "        'experiment_query_id': experiment_query_id,\n",
    "        'nl_query_text': current_nl_query_text,\n",
    "        'true_db_id': true_db_id_for_query,\n",
    "        'ranked_databases_with_predictions': ranked_databases_for_query \n",
    "    })\n",
    "\n",
    "    # --- 4. Periodic Saving of Results ---\n",
    "    # Save intermediate results to the JSON file to avoid data loss on long runs\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "            json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: Could not save intermediate results: {e}\")\n",
    "\n",
    "# --- 5. Final Save After Loop Completion ---\n",
    "print(\"\\n--- Experiment Loop Finished ---\\n\")\n",
    "if experiment_all_query_results:\n",
    "    print(f\"Processed a total of {len(experiment_all_query_results)} unique queries.\")\n",
    "    # Final save to ensure the very last entry is written correctly\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'w') as f_out:\n",
    "            json.dump(experiment_all_query_results, f_out, indent=2)\n",
    "        print(f\"Final results successfully saved to {EXPERIMENT_RESULTS_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save the final results: {e}\")\n",
    "else:\n",
    "    print(\"No results were generated. Check logs for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8262e333-9885-4932-b1fe-3de3dbd0d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using in-memory experiment_all_query_results for evaluation.\n",
      "\n",
      "--- Evaluation: Recall@K ---\n",
      "Evaluated on 1034 queries.\n",
      "Recall@1: 74.56%\n",
      "Recall@3: 90.72%\n",
      "Recall@5: 94.58%\n",
      "Recall@10: 98.07%\n",
      "Saved evaluation results to 'recall_k_results_context_lamma-3.1-8B-instruct-prompt-codeS_synthetic_data_all_DB.json'\n",
      "\n",
      "--- Sample Detailed Query Results (Top 5 Queries) ---\n",
      "\n",
      "Query 1: 'How many 'United Airlines' flights go to Airport 'ASY'?' (True DB: flight_2)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "\n",
      "Query 2: 'What are the name of the countries where there is not a single car maker?' (True DB: car_1)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "\n",
      "Query 3: 'What are the date and the operating professional's first name of each treatment?' (True DB: dog_kennels)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "\n",
      "Query 4: 'List each owner's first name, last name, and the size of his for her dog.' (True DB: dog_kennels)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n",
      "\n",
      "Query 5: 'Find the first name and age of students who have a dog but do not have a cat as a pet.' (True DB: pets_1)\n",
      "  Top Ranked Databases (with P(Yes) scores):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path where the evaluation summary (Recall@K results) will be saved\n",
    "EVAL_RESULTS_SAVE_PATH = \"recall_k_results_context_lamma-3.1-8B-instruct-prompt-codeS_synthetic_data_all_DB.json\"\n",
    "\n",
    "# --- 4.1. Define Recall@K Calculation Function ---\n",
    "def calculate_recall_at_k_metric(all_query_results_list, k_values_list):\n",
    "    \"\"\"\n",
    "    Calculates Recall@K for a list of K values.\n",
    "    Each item in all_query_results_list should be a dictionary with:\n",
    "        'true_db_id': The ground truth database ID for the query.\n",
    "        'ranked_databases_with_scores': A list of {'candidate_db_id': id, 'p_yes_score': score},\n",
    "                                         sorted by score in descending order.\n",
    "    \"\"\"\n",
    "    recall_counts = {k: 0 for k in k_values_list}  # Stores how many times true_db was in top K\n",
    "    total_valid_queries = 0  # Queries for which we have a true_db_id\n",
    "\n",
    "    if not all_query_results_list:\n",
    "        return {k: 0.0 for k in k_values_list}, 0\n",
    "\n",
    "    for query_result in all_query_results_list:\n",
    "        true_db = query_result.get('true_db_id')\n",
    "        ranked_dbs_info = query_result.get('ranked_databases_with_predictions')\n",
    "\n",
    "        if true_db is None or ranked_dbs_info is None:\n",
    "            print(f\"Warning: Skipping query result due to missing 'true_db_id' or 'ranked_databases_with_scores': \"\n",
    "                  f\"{query_result.get('experiment_query_id', 'Unknown Query')}\")\n",
    "            continue  # Skip if essential information is missing\n",
    "\n",
    "        total_valid_queries += 1\n",
    "        # Extract just the DB IDs from the ranked list\n",
    "        ranked_db_ids_only = [item['candidate_db_id'] for item in ranked_dbs_info]\n",
    "\n",
    "        for k in k_values_list:\n",
    "            # Get the top K predicted database IDs\n",
    "            top_k_predicted_dbs = ranked_db_ids_only[:k]\n",
    "            if true_db in top_k_predicted_dbs:\n",
    "                recall_counts[k] += 1\n",
    "\n",
    "    # Calculate final recall percentages\n",
    "    recall_percentages = {}\n",
    "    if total_valid_queries > 0:\n",
    "        for k in k_values_list:\n",
    "            recall_percentages[k] = (recall_counts[k] / total_valid_queries) * 100.0  # As percentage\n",
    "    else:\n",
    "        recall_percentages = {k: 0.0 for k in k_values_list}\n",
    "\n",
    "    return recall_percentages, total_valid_queries\n",
    "\n",
    "\n",
    "# --- 4.2. Perform Evaluation ---\n",
    "# Load results if this cell is run in a new session and experiment_all_query_results isn't in memory\n",
    "# (assuming results were saved to EXPERIMENT_RESULTS_FILE)\n",
    "loaded_results_for_eval = None\n",
    "if 'experiment_all_query_results' in globals() and experiment_all_query_results:\n",
    "    print(\"Using in-memory experiment_all_query_results for evaluation.\")\n",
    "    loaded_results_for_eval = experiment_all_query_results\n",
    "elif os.path.exists(EXPERIMENT_RESULTS_FILE):\n",
    "    print(f\"Loading results from {EXPERIMENT_RESULTS_FILE} for evaluation...\")\n",
    "    try:\n",
    "        with open(EXPERIMENT_RESULTS_FILE, 'r') as f_in:\n",
    "            loaded_results_for_eval = json.load(f_in)\n",
    "        print(f\"Successfully loaded {len(loaded_results_for_eval)} results from file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results from file for evaluation: {e}\")\n",
    "else:\n",
    "    print(\"No results available in memory or in the specified results file for evaluation.\")\n",
    "\n",
    "if loaded_results_for_eval:\n",
    "    K_VALUES_TO_EVALUATE = [1, 3, 5, 10]  # Define the K values you care about\n",
    "    recall_scores_map, num_queries_evaluated = calculate_recall_at_k_metric(\n",
    "        loaded_results_for_eval, K_VALUES_TO_EVALUATE\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Evaluation: Recall@K ---\")\n",
    "    print(f\"Evaluated on {num_queries_evaluated} queries.\")\n",
    "    for k_val, recall_val in recall_scores_map.items():\n",
    "        print(f\"Recall@{k_val}: {recall_val:.2f}%\")\n",
    "\n",
    "    # --- 4.2.1. Save evaluation results to a JSON file ---\n",
    "    try:\n",
    "        eval_summary = {\n",
    "            \"num_queries_evaluated\": num_queries_evaluated,\n",
    "            \"recall_scores\": recall_scores_map\n",
    "        }\n",
    "        with open(EVAL_RESULTS_SAVE_PATH, 'w') as fout:\n",
    "            json.dump(eval_summary, fout, indent=2)\n",
    "        print(f\"Saved evaluation results to '{EVAL_RESULTS_SAVE_PATH}'\")\n",
    "    except Exception as save_err:\n",
    "        print(f\"Error saving evaluation results: {save_err}\")\n",
    "\n",
    "    # --- 4.3. Optional: Print Detailed Results for a Few Queries ---\n",
    "    print(\"\\n--- Sample Detailed Query Results (Top 5 Queries) ---\")\n",
    "    for i, res in enumerate(loaded_results_for_eval[:5]):  # Show for first 5 queries\n",
    "        print(f\"\\nQuery {i+1}: '{res.get('nl_query_text', '<no text>')}' (True DB: {res.get('true_db_id')})\")\n",
    "        print(\"  Top Ranked Databases (with P(Yes) scores):\")\n",
    "        for rank, db_info in enumerate(res.get('ranked_databases_with_scores', [])[:5]):  # Show top 5 ranked DBs\n",
    "            is_true_db_char = \"*\" if db_info['candidate_db_id'] == res['true_db_id'] else \" \"\n",
    "            print(f\"    {rank+1}. {db_info['candidate_db_id']}{is_true_db_char} \"\n",
    "                  f\"(Score: {db_info['p_yes_score']:.4f})\")\n",
    "else:\n",
    "    print(\"Cannot perform evaluation as no results were loaded or generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_spider_env)",
   "language": "python",
   "name": "llama_spider_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
